<article class="post-321759 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-321759">
<header class="entry-header">
<h1 class="entry-title">Journaling or write-ahead logging</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Journaling</strong>, or <strong>write-ahead logging</strong> is a sophisticated solution to the problem of  in operating systems. Inspired by database management systems, this method first writes down a summary of the actions to be performed into a “log” before actually writing them to the disk. Hence the name, “write-ahead logging”. In the case of a crash, the OS can simply check this log and pick up from where it left off. This saves multiple disk scans to fix inconsistency, as is the case with FSCK.</p>
<p>Good examples of systems that implement data journaling include Linux ext3 and ext4 file systems, and Windows NTFS.</p>
<p><strong>Data Journaling:</strong><br/>
A log is stored in a simple data structure called the journal. The figure below shows its structure, which comprises of three components.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-321315 post type-post status-publish format-standard hentry category-operating-systems tag-linux-command" id="post-321315">
<header class="entry-header">
<h1 class="entry-title">File System Consistency Checker (FSCK)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>File system inconsistency is a major issue in operating systems. FSCK is one of the standard solutions adopted.</p>
<p><strong>File System Consistency Checker (FSCK):</strong><br/>
FSCK is one approach still used by older Linux-based systems to find and repair inconsistencies. It is not a complete solution and may still have inodes pointing to garbage data. The major focus is to make the <strong>metadata</strong> internally consistent.</p>
<p>The following are the checks that FSCK performs to achieve consistency:</p>
<ul>
<li><strong>Superblock Checks:</strong><br/>
FSCK performs a sanity check to see if the file size is greater than the number of blocks allocated. In this case, it tries to find the suspect superblock and use an alternate copy instead.</li>
<li><strong>Free Block Checks:</strong><br/>
FSCK also scans inodes to ensure that blocks in inodes are marked allocated.</li>
<li><strong>Inode State Checks:</strong><br/>
FSCK checks inodes for corruption. Corrupted inodes are simply cleared.</li>
<li><strong>Inode Link Checks:</strong><br/>
FSCK counts the number of links to an inode, and modifies the inode count. If an allocated inode has no directory or file referring to it, FSCK moves it to the lost and found directory.</li>
<li><strong>Duplicate Pointers:</strong><br/>
FSCK checks duplicate pointers. For example, if two inodes have pointers to the same data block, one of the inode can be deleted.</li>
<li><strong>Bad Blocks:</strong><br/>
A bad pointer is simply one that points to a memory address which is out of range. In this case, FSCK deletes the pointer.</li>
<li><strong>Directory Checks:</strong><br/>
FSCK makes sure the directory format is correct, e.g. they should start with “.” and “..”.</li>
</ul>
<p><strong>Advantages of FSCK:</strong></p>
<ul>
<li>It requires little overhead space.</li>
</ul>
<p><strong>Disadvantages of FSCK:</strong></p>
<ul>
<li>Scanning the disk, again and again, is slow and infeasible for large disk sizes.</li>
<li>It requires a heavy understanding and prior knowledge of the file system. As file systems continue to evolve, it is difficult to keep track of each and every nuance.</li>
</ul>
<p><strong>fsck Command in Linux:</strong><br/>
The fsck command in Linux allows us to manually check for file system inconsistencies. Below is the sample usage of the command.</p>
<pre>sudo fsck /dev/sda2</pre>
<p>The above command simply checks the file system mounted onto the /dev/sda2 partition. If the file system may have some inconsistencies, fsck prompts us with possible actions.</p>
<pre>fsck.fat 4.1 (2017-01-24) </pre>
<p>0x41: Dirty bit is set. Fs was not properly unmounted and some data may be corrupt: Remove dirty bit, and No action.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-316680 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems tag-operating-systems-memory-management" id="post-316680">
<header class="entry-header">
<h1 class="entry-title">Cache Memory Design</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
A detailed discussion of the cache style is given in this article. The key elements are concisely summarized here. we are going to see that similar style problems should be self-addressed in addressing storage and cache style. They represent the subsequent categories: Cache size, Block size, Mapping function, Replacement algorithm, and Write policy. These are explained as following below.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-315903 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems category-techtips" id="post-315903">
<header class="entry-header">
<h1 class="entry-title">How to test all Linux distributions without downloading them?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>There are many Linux distribution available to use but finding perfect distribution is very difficult. You have to download almost 2GB of the file for each distribution and during testing, you don’t find anything good. What if you could test a Linux distribution without actually downloading it and setting up a VMware or wasting a lot of time in installing it as a primary Operating system? <strong></strong> is the website which provides you the facility to test more than 700 versions with 225 Operating systems. It has each and every Operating system with all different versions.</p>
<p><img alt="" class="alignnone size-full wp-image-1120550" src="https://media.geeksforgeeks.org/wp-content/uploads/20190620235853/distrointro.png"/></p>
<h3 align="center">How to use Distrotest.net?</h3>
<p>Distrotest.net works on a service based website where you can choose among a variety of different Linux distributions to test. Just choose your distribution from the A-Z list and start your system. The website provides all the features of the operating system, including install, partition and everything like you do in your actual system. After choosing your desired Operating system you enter in a queue where you are given a slot number and you have to wait a little bit till your turn comes. The slots are given due to many users running systems and makes server loaded. Sometimes heavy usage kills the website and servers go offline but in a few hours, this issue is fixed. Also if you face any issue in the website you can contact their support.</p>
<p><img alt="" class="alignnone size-full wp-image-1120600" src="https://media.geeksforgeeks.org/wp-content/uploads/20190621003801/systart.png"/></p>
<h3 align="center">Problems Faced While Using distrotest.net</h3>
<p>Using distrotest.net is very easy but there are some problems which you can face while using it:</p>
<ol>
<li><strong>Slow system</strong>: The Operating system launched in the server runs very slow. After moving your cursor you may need to wait for a second for the response which kills a lot of time.</li>
<li><strong>Waiting Queue:</strong> Once you tab “system start” you enter a queue in which you are given a number, and no one knows how much time will it take till the other users shut down systems, however, for each user there is a time limit of 30 Minutes.<br/>
<img alt="" class="alignnone size-full wp-image-1121612" src="https://media.geeksforgeeks.org/wp-content/uploads/20190621154605/DISTPROB.png"/></li>
<li><strong>Server offline:</strong> when there is more traffic and heavy usage, the servers can go offline, but the support tries to fix the issue soon.<br/>
<img alt="" class="alignnone size-full wp-image-1121615" src="https://media.geeksforgeeks.org/wp-content/uploads/20190621155007/prob.png"/></li>
<p>A great project has some problems but those problems soon get a solution. If you face any problems or if you have any suggestion you can always reach their support and they are happy to help. Below are some screenshots of the system that I tried while writing this article:</p>
<p><img alt="" class="alignnone size-full wp-image-1121643" src="https://media.geeksforgeeks.org/wp-content/uploads/20190621160451/test2.png"/></p>
<p><img alt="" class="alignnone size-full wp-image-1121644" src="https://media.geeksforgeeks.org/wp-content/uploads/20190621160511/sparky-test.png"/></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-314559 post type-post status-publish format-standard hentry category-operating-systems category-python tag-python-utility" id="post-314559">
<header class="entry-header">
<h1 class="entry-title">Python | How to lock Critical Sections</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>This article aims how to lock the threads and critical sections in the given program to avoid race conditions. So, using Lock object in the <em>threading library</em> to make mutable objects safe to use by multiple threads.</p>
<p><strong>Code #1 : </strong></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-314190 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-314190">
<header class="entry-header">
<h1 class="entry-title">Interprocess Communication in Distributed Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Interprocess Communication</b> is a process of exchanging the data between two or more independent process in a distributed environment is called as Interprocess communication. Interprocess communication on the internet provides both Datagram and stream communication.</p>
<p><strong>Examples Of Interprocess Communication:</strong> </p>
<ol>
<li>N number of applications can communicate with the X server through network protocols.
</li>
<li>Servers like Apache spawn child processes to handle requests.
</li>
<li>Pipes are a form of IPC: grep foo file | sort
</li>
</ol>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-313557 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-313557">
<header class="entry-header">
<h1 class="entry-title">Difference between Volatile Memory and Non-Volatile Memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Volatile Memory:</b><br/>
It is that the quite hardware that stores information quickly. it’s additionally referred as temporary memory. The information within the volatile memory is hold on solely till the ability is provided to the system, once the system is turned off the information gift within the volatile memory is deleted mechanically.  and  are the common example of the volatile memory. It’s quite quick and economical in nature and may be accessed apace. </p>
<p><b>Non-Volatile Memory:</b><br/>
It is the type of memory in which data or information remains keep within the memory albeit power is completed.  is the most common example of non-volatile memory. it’s not that a lot of economical and quick in nature as compare to volatile memory however stores information for the longer amount. Non-volatile memory is slow concerning accessing. All such information that must be hold on for good or for a extended amount is hold on in non-volatile memory. Non-volatile memory has a huge impact on a system’s storage capacity.</p>
<p>Let’s see that the difference between volatile and non-volatile memory:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Volatile Memory</th>
<th>Non-Volatile Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>Volatile memory is the type of memory in which data isn’t keep in memory as before long as power is gone.</td>
<td>Non-volatile memory is the type of memory in which data or information remains keep within the memory albeit power is completed.</td>
</tr>
<tr>
<td>2.</td>
<td>Volatile memory is not a permanent memory.</td>
<td>Non-volatile memory is a permanent memory.</td>
</tr>
<tr>
<td>3.</td>
<td>It is faster than non-volatile memory.</td>
<td>It is slow than volatile memory.</td>
</tr>
<tr>
<td>4.</td>
<td><b>RAM</b> is the example of volatile memory.</td>
<td><b>ROM</b> is the example of non-volatile memory.</td>
</tr>
<tr>
<td>5.</td>
<td>In volatile memory, data can be easily transferred in comparison of non-volatile memory.</td>
<td>In non-volatile memory, data can not be easily transferred in comparison of volatile memory.</td>
</tr>
<tr>
<td>6.</td>
<td>Volatile memory can read and write.</td>
<td>Non-volatile memory can’t write, it only read.</td>
</tr>
<tr>
<td>7.</td>
<td>Volatile memory has less storage.</td>
<td>Non-volatile memory has more storage than volatile memory.</td>
</tr>
<tr>
<td>8.</td>
<td>In volatile memory, the program’s data are stored which are currently in process by the CPU.</td>
<td>In non-volatile memory, any kind of data which has to be saved permanently are stored.</td>
</tr>
<tr>
<td>9.</td>
<td>Volatile memory is more costly per unit size.</td>
<td>Non-volatile memory is less costly per unit size.</td>
</tr>
<tr>
<td>10.</td>
<td>Volatile memory has a huge impact on the system’s performance.</td>
<td>Non-volatile memory has a huge impact on a system’s storage capacity.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312924 post type-post status-publish format-standard hentry category-operating-systems" id="post-312924">
<header class="entry-header">
<h1 class="entry-title">Comparison on using Java for an Operating System instead of C</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p> is a managed language which offers memory safety.<br/>
In Java, pointers do not exist, so we cannot do pointer arithmetic on a function pointer. An application can invoke a method defined in a class through the class object. In Java, we cannot do unsafe typecast of an object to overwrite the method pointer with something else. An out of bound array access throws a runtime exception in Java, so return address corruption is not possible.</p>
<p>Now, let us look at some important aspects of an Operating System implemented through Java.</p>
<ul>
<li><strong>Memory isolation:</strong><br/>
In Java, memory can only be accessed via objects. A Java application cannot access memory outside an object. The virtual memory is not abstracted to the application. Due to these reasons, we do not need additional hardware support (segmentation/page tables) for process allocation. There is no need for page tables or privilege rings. The kernel is itself a Java process, so both kernel and untrusted applications execute in ring-0.</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-313014 post type-post status-publish format-standard hentry category-operating-systems" id="post-313014">
<header class="entry-header">
<h1 class="entry-title">Read-Copy Update (RCU)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A <b>Lock Primitive</b> which is widely used in Linux kernel is read-copy update (RCU) lock. It is a synchronization mechanism which was added to the Linux Kernel in October 2002. It has achieved improvements by enabling reads to occur simultaneously with updates. It supports concurrency between multiple readers and a single updater. There are no overheads in the RCU’s read-side primitive. It is one of the safest data structure designed to operate safely during simultaneous access because it uses cache line and memory efficiently. </p>
<p><b>Read-Copy Update (CPU)</b> locks have a lock-free read-critical section. RCU locks work for workloads where a writer is compatible with the lock-free readers. Preemption is not allowed in the read critical section.</p>
<p>Consider the following code:</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-313219 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-313219">
<header class="entry-header">
<h1 class="entry-title">Difference between Blu-ray and DVD</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Blu-ray:</b><br/>
Blu-ray could be a high definition storage device which might hold a bigger space for storing as compared to different optical storage devices. it had been principally devised to store high definition videos, and this wasn’t doable within the previous DVD technology. Blu-ray will store the large quantity of information as compared to different disk formats, and therefore the reason behind this can be the less gap between the information layer on the disk and therefore the optical device. </p>
<p>It generates tighter focus, less distortion Associate in smaller pits (and tracks) as an outcome of putting the optical device nearer to the disk. the utmost space for storing of Blu-ray is twenty five GB on one facet. The Blu-ray name is originated by adding blue and optical “ray” and this as a result of it uses blue-violet optical device rather than a red optical device. because the blue laser’s wavelength is shorter, which helps for achieving the higher bit density.</p>
<p><b>DVD:</b><br/>
DVD stands for <b>Digital Versatile</b> Disk provides another for the videotape utilized in tape recorder (Video container Recorder) and fixed storage utilized in computer because the videodisc will acquire seven times larger quantity of the info relative to CD. </p>
<p>It renders videos with wonderful image quality and random access. A videodisc is constructed from a similar material because the CD however the method and therefore the layers area unit completely different, it’s used from each of the edges like 2 CDs area unit projected along. In DVD, RS-PC and EFMplus are used as the error correction codes.</p>
<p>Let’s see that the difference b/w DVD and Blu-ray:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Blu-ray</th>
<th>DVD</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>The single layer size of Blu-ray is 25 GB.</td>
<td>While the single layer size of DVD is 4.7 GB.</td>
</tr>
<tr>
<td>2.</td>
<td>In Blu-ray, the recording or metal layer is situated closer to the reading mechanism’s objective lens.</td>
<td>While in DVD, the recording or metal layer is situated in middle of disk.</td>
</tr>
<tr>
<td>3.</td>
<td>There are double layers of pits in blu-ray.</td>
<td>While there are also double layers of pits in DVD.</td>
</tr>
<tr>
<td>4.</td>
<td>In blu-ray, there is 0.30 micrometer space between the spiral’s loops.</td>
<td>While in DVD, there is 0.74 micrometer space between the spiral’s loops.</td>
</tr>
<tr>
<td>5.</td>
<td>It holds the 0.15 micrometer space between the pits.</td>
<td>While it holds the 0.4 micrometer space between the pits.</td>
</tr>
<tr>
<td>6.</td>
<td>In blu-ray, picket code is used as the correction code.</td>
<td>While In DVD, RS-PC and EFMplus are used as the error correction codes.</td>
</tr>
<td>7.</td>
<td>In Blu-ray, the wavelength of laser in 405 nm.</td>
<td>While in DVD, the wavelength of laser is 650 nm.</td>
</tbody></table></div></article><hr style="border: 2px dashed black;" /><article class="post-313173 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-313173">
<header class="entry-header">
<h1 class="entry-title">Difference between CLI and GUI</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>CLI</b> is that the word form used for <b>Command Line Interface.</b> CLI permits users to put in writing commands associate degree exceedingly in terminal or console window to interact with an operating system. CLI is a platform or medium wherever users answer a visible prompt by writing a command and get the response from system, for this users have to be compelled to kind command or train of command for performing the task. CLI is suitable for the pricey computing wherever input exactitude is that the priority.</p>
<p><img alt="" class="aligncenter size-full wp-image-1108693" height="373" src="https://media.geeksforgeeks.org/wp-content/uploads/20190613133524/Untitled-Diagram-410.png" width="482"/></p>
<p><b>GUI</b> stands for <b>Graphical User Interface.</b>  GUI permits users to use the graphics to interact with an operating system. In graphical user interface, menus are provided such as : windows, scrollbars, buttons, wizards, painting pictures, alternative icons etc. It’s intuitive, simple to find out and reduces psychological feature load. In GUI, the information is shown or presented to the user in any form such as: plain text, videos, images, etc.</p>
<p><img alt="" class="aligncenter size-full wp-image-1108701" height="373" src="https://media.geeksforgeeks.org/wp-content/uploads/20190613134141/Untitled-Diagram-312.png" width="482"/></p>
<p>Let’s see that the difference between GUI and CLI:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>CLI</th>
<th>GUI</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>CLI is difficult to use.</td>
<td>Whereas it is easy to use.</td>
</tr>
<tr>
<td>2.</td>
<td>It consumes low memory.</td>
<td>While consumes more memory.</td>
</tr>
<tr>
<td>3.</td>
<td>In CLI we can obtain high precision.</td>
<td>While in it, low precision is obtained.</td>
</tr>
<tr>
<td>4.</td>
<td>CLI is faster than GUI.</td>
<td>The speed of GUI is slower than CLI.</td>
</tr>
<tr>
<td>5.</td>
<td>CLI operating system needs only keyboard.</td>
<td>While GUI operating system need both mouse and keyboard.</td>
</tr>
<tr>
<td>6.</td>
<td>CLI’s appearance can not be modified or changed.</td>
<td>While it’s appearance can be modified or changed.</td>
</tr>
<tr>
<td>7.</td>
<td>In CLI, input is entered only at command prompt.</td>
<td>While in GUI, input can be entered anywhere on the screen.</td>
</tr>
<tr>
<td>8.</td>
<td>In CLI, the information is shown or presented to the user in plain text and files.</td>
<td>While in GUI, the information is shown or presented to the user in any form such as: plain text, videos, images, etc.</td>
</tr>
<tr>
<td>9.</td>
<td>In CLI, there are no menus provided.</td>
<td>While in GUI, menus are provided.</td>
</tr>
<tr>
<td>10.</td>
<td>There are no graphics in CLI.</td>
<td>While in GUI, graphics are used.</td>
</tr>
<tr>
<td>11.</td>
<td>CLR do not use any pointing devices.</td>
<td>While it uses pointing devices for selecting and choosing items.</td>
</tr>
<tr>
<td>12.</td>
<td>In CLI, spelling mistakes and typing errors are not avoided.</td>
<td>Whereas in GUI, spelling mistakes and typing errors are avoided.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312744 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312744">
<header class="entry-header">
<h1 class="entry-title">Difference between PROM and EPROM</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>PROM</b> stands for <b>Programmable Read Only Memory</b> is the type of ROM is written only. It was meant to fulfil the requirement of a group of ROMs which may contain a selected memory content. It’s memory is written just the once and programmed electrically by the user at the time or when the initial chip fabrication. the required content file is equipped by the user and inserted within the machine referred to as storage coder. There exist a fuse at every programmable association and it’s blown once the association isn’t required.</p>
<p><b>EPROM</b> stands for <b>Erasable Programmable Read Only Memory</b> is also the type of ROM is read and written optically. To write associate EPROM, its storage cells should stay within the same initial state. EPROM provides reduced storage permanency as compared to PROM as a result of the EPROM is receptive to radiation and electrical noise. in the construction of EPROM, MOS transistors are used.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312523 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312523">
<header class="entry-header">
<h1 class="entry-title">Difference between RPC and RMI</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>RPC</b> stands for <b>Remote Procedure Call</b> which supports procedural programming. Tt’s almost like IPC mechanism wherever the software permits the processes to manage shared information Associated with an environment wherever completely different processes area unit death penalty on separate systems and essentially need message-based communication.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312864 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312864">
<header class="entry-header">
<h1 class="entry-title">Difference between CD and DVD</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>CD</b> stands for <b>Compact Disc</b> was the primary step towards the thought of digital coding of the info. It uses a novel methodology of coding within which a 14-bit code indicates a computer memory unit and this coding technique conjointly helps in error detection. it had been an acceptable replacement for the memory device because it offered the low-priced answer for storing a big quantity of knowledge.</p>
<p><b>DVD</b> stands for <b>Digital Versatile Disk</b> provides another for the videotape utilized in tape recorder (Video container Recorder) and fixed storage utilized in computer because the videodisc will acquire seven times larger quantity of the info relative to CD. It renders videos with wonderful image quality and random access. A videodisc is constructed from a similar material because the CD however the method and therefore the layers area unit completely different, it’s used from each of the edges like 2 CDs area unit projected along. In DVD, RS-PC and EFMplus are used as the error correction codes.</p>
<p>There are few differences between CD and DVD, which are given below:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>CD</th>
<th>DVD</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>The acquire size of CD is 700 MB.</td>
<td>While the acquire size of DVD is 4.7 GB to 17 GB.</td>
</tr>
<tr>
<td>2.</td>
<td>In CD, the recording or metal layer is situated on the top of disk.</td>
<td>While in DVD, the recording or metal layer is situated in middle of disk. </td>
</tr>
<tr>
<td>3.</td>
<td>There is only single pit layer in CD.</td>
<td>While there are double layers of pits in DVD.</td>
</tr>
<tr>
<td>4.</td>
<td>In CD, there is 1.6 micrometer space between the spiral’s loops.</td>
<td>While in DVD, there is 0.74 micrometer space between the spiral’s loops.</td>
</tr>
<tr>
<td>5.</td>
<td>A CD holds the 0.834 micrometer space between the pits.</td>
<td>While it holds the 0.4 micrometer space between the pits.</td>
</tr>
<tr>
<td>6.</td>
<td>In CD, CIRC and EFMP are used as the error correction codes.</td>
<td>While In DVD, RS-PC and EFMplus are used as the error correction codes.</td>
</tr>
<tr>
<td>7.</td>
<td>There can cause the damage in metal layer after the Removal of the adhesive labels, in CD.</td>
<td>While there is caused the imbalance in the spin after the Removal of the adhesive labels, in CD.</td>
</tr>
<tr>
<td>8.</td>
<td>In CD, the data transfer rate is 1.4 MB to 1.6 MB/sec.</td>
<td>While in DVD, the data transfer rate is 11 MB/sec.</td>
</tr>
<tr>
<td>9.</td>
<td>The channel bit length in Cd is 300 nanometer.</td>
<td>While the channel bit length in DVD is 113 nanometer which is less than CD’s channel bit length.</td>
</tr>
<tr>
<td>10.</td>
<td>The numeric aperture of CD is 0.45.</td>
<td>While the numeric aperture of DVD is 0.6.</td>
</tr>
<tr>
<td>11.</td>
<td>The thickness of CD is 1.2 mm.</td>
<td>While the thickness of DVD is 0.6 mm.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312303 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312303">
<header class="entry-header">
<h1 class="entry-title">Difference between Time Sharing OS and Real-Time OS</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – </p>
<p><b>Time sharing operating system</b> is usually  works on the concurrent execution ideas wherever multiple jobs area unit executes at identical (same) time through switch them oftentimes. In this operating system Switching method/function is available. This switching is incredibly quick in order that the users will move with every program whereas it’s running while not knowing that, the system is being shared.</p>
<p><b>Real Time operating system</b>, computation tasks are emphasized before its nominative point. Real time operating system is incredibly helpful for the temporal order applications, in different words wherever tasks ought to be accomplished inside a definite deadline. The time period in operation systems not solely need correct results however conjointly the timely results, which implies beside the correctness of the results it should be created in an exceedingly sure deadline otherwise the system can fail.</p>
<p>The main difference between time sharing and the real-time operating system is that, In time sharing OS, the response is provided to the user within a second. While in real time OS, the response is provided to the user within time constraint.</p>
<p>Let’s see that the difference between Time Sharing and Real-Time Operating System:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Time Sharing Operating System</th>
<th>Real-Time Operating System</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>In time sharing operating system, quick response is emphasized for a request.</td>
<td>While in real time operating system, computation tasks are emphasized before its nominative point.</td>
</tr>
<tr>
<td>2.</td>
<td>In this operating system <b>Switching</b> method/function is available.</td>
<td>While in this operating system <b>Switching</b> method/function is not available.</td>
</tr>
<tr>
<td>3.</td>
<td>In this operating system any modification in the program can be possible.</td>
<td>While in this modification does not take place.</td>
</tr>
<tr>
<td>4.</td>
<td>In this OS, computer resources are shared to the external.</td>
<td>But in this OS, computer resources are not shared to the external.</td>
</tr>
<tr>
<td>5.</td>
<td>It deals with more than processes or applications simultaneously.</td>
<td>Whereas it deals with only one process or application at a time.</td>
</tr>
<tr>
<td>6.</td>
<td>In this OS, the response is provided to the user within a second.</td>
<td>While in real time OS, the response is provided to the user within time constraint.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312349 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312349">
<header class="entry-header">
<h1 class="entry-title">Difference between Interrupt and Polling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>:</b><br/>
Interrupt is a hardware mechanism in which, the device notices the CPU that it requires its attention. Interrupt can take place at any time. So when CPU gets an interrupt signal trough the indication interrupt-request line, CPU stops the current process and respond to the interrupt by passing the control to interrupt handler which services device.</p>
<p><b>Polling:</b><br/>
In polling is not a hardware mechanism, its a protocol in which CPU steadily checks whether the device needs attention. Wherever device tells process unit that it desires hardware processing, in polling process unit keeps asking the I/O device whether or not it desires CPU processing. The CPU ceaselessly check every and each device hooked up thereto for sleuthing whether or not any device desires hardware attention. </p>
<p>Each device features a command-ready bit that indicates the standing of that device, i.e., whether or not it’s some command to be dead by hardware or not. If command bit is ready one, then it’s some command to be dead else if the bit is zero, then it’s no commands. </p>
<p>Let’s see that the difference between interrupt and polling:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Interrupt</th>
<th>Polling</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>In interrupt, the device notices the CPU that it requires its attention.</td>
<td>Whereas, in polling, CPU steadily checks whether the device needs attention.</td>
</tr>
<tr>
<td>2.</td>
<td>An interrupt is not a protocol, its a hardware mechanism.</td>
<td>Whereas it isn’t a hardware mechanism, its a protocol.</td>
</tr>
<tr>
<td>3.</td>
<td>In interrupt, the device is serviced by interrupt handler.</td>
<td>While in polling, the device is serviced by CPU.</td>
</tr>
<tr>
<td>4.</td>
<td>Interrupt can take place at any time.</td>
<td>Whereas CPU steadily ballots the device at regular or proper interval.</td>
</tr>
<tr>
<td>5.</td>
<td>In interrupt, interrupt request line is used as indication for indicating that device requires servicing.</td>
<td>While in polling, Command ready bit is used as indication for indicating that device requires servicing.</td>
</tr>
<tr>
<td>6.</td>
<td>In interrupts, processor is simply disturbed once any device interrupts it.</td>
<td>On the opposite hand, in polling, processor waste countless processor cycles by repeatedly checking the command-ready little bit of each device.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312250 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312250">
<header class="entry-header">
<h1 class="entry-title">Difference between Linux and Windows</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>:</b><br/>
Linux could be a free and open supply OS supported operating system standards. It provides programming interface still as programme compatible with operating system primarily based systems and provides giant selection applications. A UNIX operating system system additionally contains several severally developed parts, leading to UNIX operating system that is totally compatible and free from proprietary code.</p>
<p><b>Windows:</b><br/>
Windows may be a commissioned OS within which ASCII text file is inaccessible. it’s designed for the people with the angle of getting no programming information and for business and alternative industrial users. it’s terribly straightforward and simple to use.</p>
<p>The  distinction between Linux and Windows package is that Linux is completely freed from price whereas windows is marketable package and is expensive. Associate operating system could be a program meant to regulate the pc or computer hardware Associate  behave as an treater between user and hardware.</p>
<p>Linux is a open supply package wherever users will access the ASCII text file and might improve the code victimisation the system. On the opposite hand, in windows, users can’t access ASCII text file, and it’s a authorized OS.</p>
<p>Let’s see that the difference between Linux and windows:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Linux</th>
<th>Windows</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>Linux is a open source operating system.</td>
<td>While windows are the not the open source operating system.</td>
</tr>
<tr>
<td>2.</td>
<td>Linux is free of cost.</td>
<td>While it is costly.</td>
</tr>
<tr>
<td>3.</td>
<td>It’s file name case-sensitive.</td>
<td>While it’s file name is case-insensitive.</td>
</tr>
<tr>
<td>4.</td>
<td>In linux, monolithic kernel is used.</td>
<td>While in this, micro kernel is used.</td>
</tr>
<tr>
<td>5.</td>
<td>Linux is more efficient in comparison of windows.</td>
<td>While windows are less efficient.</td>
</tr>
<tr>
<td>6.</td>
<td>There is forward slash is used for Separating the directories.</td>
<td>While there is back slash is used for Separating the directories.</td>
</tr>
<tr>
<td>7.</td>
<td>Linux provides more security than windows.</td>
<td>While it provides less security than linux.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312444 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-312444">
<header class="entry-header">
<h1 class="entry-title">Multilevel Paging</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Multilevel Paging</b> is a paging scheme which consist of two or more levels of page tables in a hierarchical manner. It is also known as hierarchical paging. The entries of the level 1 page table are pointers to a level 2 page table and entries of the level 2 page tables are pointers to a level 3 page table and so on. The entries of the last level page table are stores actual frame information. Level 1 contain  single page table and address of that table is stored in PTBR (Page Table Base Register).</p>
<p><u>Virtual address:</u></p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-312272 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-312272">
<header class="entry-header">
<h1 class="entry-title">Difference between DOS and Windows</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>DOS and Windows square measure the various varieties of .</p>
<p>DOS stands for <b>Disk Operating System</b>. It is a smaller amount probably employed in the current state of affairs whereas windows may be a wide used in operation system. It consumes less memory and power than windows.</p>
<p><b>Window</b> has no full form but it is widely used operating system than DOS operating system. It consumes more memory and power than DOS operating system. </p>
<p>DOS and Windows square measure principally differentiated by the actual fact that DOS may be a single tasking, single user, interface primarily based OS developed within the year of 1979. On the opposite hand, all the windows version square measure multitasking, multiuser and graphical user interface primarily based OS.</p>
<p>Let’s see the difference between DOS and Windows:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>DOS</th>
<th>WINDOW</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>DOS is single tasking operating system.</td>
<td>While windows are multitasking operating systems.</td>
</tr>
<tr>
<td>2.</td>
<td>It consumes low power.</td>
<td>While windows consume high power.</td>
</tr>
<tr>
<td>3.</td>
<td>It consumes less memory in comparison of windows.</td>
<td>While it consumes more memory.</td>
</tr>
<tr>
<td>4.</td>
<td>DOS does not support networking.</td>
<td>While window supports networking.</td>
</tr>
<tr>
<td>5.</td>
<td>DOS is complex in terms of using.</td>
<td>Whereas it is  simple for using.</td>
</tr>
<tr>
<td>6.</td>
<td>DOS does not share time.</td>
<td>While window can share time.</td>
</tr>
<tr>
<td>7.</td>
<td>DOS is a command line operating system.</td>
<td>Whereas windows are the graphical operating systems.</td>
</tr>
<tr>
<td>8.</td>
<td>DOS operating system is less preferred than windows.</td>
<td>While windows are more preferred by the users in comparison of DOS.</td>
</tr>
<tr>
<td>9.</td>
<td>In DOS operating system multimedia is not supported such as: Games, movies,songs etc.</td>
<td>While windows support multimedia such as: Games, movies,songs etc.</td>
</tr>
<tr>
<td>10.</td>
<td>In DOS operation systems, operation are performed speedily than windows OS.</td>
<td>While in windows OS, operation are performed slowly than DOS OS.</td>
</tr>
<tr>
<td>11.</td>
<td>There is only one window opened at a time in DOS.</td>
<td>While in windows, multiple windows can be opened at a time.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-311660 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-311660">
<header class="entry-header">
<h1 class="entry-title">Difference between Mainframe and Minicomputer</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Mainframe Computers</b> and <b>Minicomputers</b> are the categories of a laptop wherever mainframe computers give rather more options than minicomputer and high capability for memory and process speed. </p>
<p>At the beginning, Mainframe Computers were made to produce responsibleness for dealing process and are primarily used as servers.<br/>
Whereas, Minicomputers are mid-size, tiny computers which individuals will use either individually or as a high-end device likewise.</p>
<p>Let’s see the difference between Mainframe Computer and Minicomputer:</p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>S.NO</th>
<th>Mainframe</th>
<th>Minicomputer</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>In mainframe computer, large size of disk is used.</td>
<td>While in minicomputer, small size of disk is used.</td>
</tr>
<tr>
<td>2.</td>
<td>Mainframe computers have large memory storage.</td>
<td>While minicomputers have small or less memory storage than mainframe computer.</td>
</tr>
<tr>
<td>3.</td>
<td>The processing speed of mainframe computer is faster than minicomputer.</td>
<td>While the processing speed of minicomputer is slower than mainframe computer.</td>
</tr>
<tr>
<td>4.</td>
<td>Mainframe computer is costlier than minicomputers.</td>
<td>Whereas supercomputers’s cost is less or it is Inexpensive.</td>
</tr>
<tr>
<td>5.</td>
<td>The first microcomputer was invented by the team leader Bill Pentz .</td>
<td>The first successful mainframe computer is invented by IBM.</td>
</tr>
<tr>
<td>6.</td>
<td>Mainframe computers support thousand or millions of users simultaneously.</td>
<td>Whereas minicomputers support hundreds of users at a time.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-309037 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-309037">
<header class="entry-header">
<h1 class="entry-title">Chandy-Misra-Haas’s Distributed Deadlock Detection Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Chandy-Misra-Haas’s distributed deadlock detection algorithm</strong> is an edge chasing algorithm to detect deadlock in distributed systems.</p>
<p>In edge chasing algorithm, a special message called <em>probe</em> is used in deadlock detection. A <em>probe</em> is a triplet <em>(i, j, k)</em> which denotes that process P<sub>i</sub> has initiated the deadlock detection and the message is being sent by the home site of process P<sub>j</sub> to the home site of process P<sub>k</sub>. </p>
<p>The probe message circulates along the edges of WFG to detect a cycle. When a blocked process receives the probe message, it forwards the probe message along its outgoing edges in WFG. A process P<sub>i</sub> declares the deadlock if probe messages initiated by process P<sub>i</sub> returns to itself.</p>
<p><strong>Other terminologies used in the algorithm:</strong></p>
<ol>
<li><b>Dependent process:</b><br/>
A process P<sub>i</sub> is said to be dependent on some other process P<sub>j</sub>, if there exists a sequence of processes P<sub>i</sub>, P<sub>i1</sub>, P<sub>i2</sub>, P<sub>i3</sub>…, P<sub>im</sub>, P<sub>j</sub> such that in the sequence, each process  except P<sub>j</sub> is blocked and  each process except P<sub>i</sub> holds a resource for which previous process in the sequence is waiting.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-308634 post type-post status-publish format-standard hentry category-c category-operating-systems category-stack tag-cyber-security tag-information-security" id="post-308634">
<header class="entry-header">
<h1 class="entry-title">Analyzing BufferOverflow with GDB</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Pre-requisite:</b> <a href="https://www.geeksforgeeks.org/gdb-step-by-step-introduction/">GDB (Step by Step Introduction)</a></p>
<p>A <strong><a href="https://www.geeksforgeeks.org/buffer-overflow-attack-with-example/">BufferOverflow</a></strong> often occurs when the content inside the defined variable is copied to another variable without doing <strong> Bound Checks</strong> or considering the size of the buffer. Let’s analyze buffer overflow with the help <a href="https://www.geeksforgeeks.org/gdb-step-by-step-introduction/">GNU Debugger (GDB)</a> which is inbuilt every Linux system.</p>
<p>The motive of this exercise is to get comfortable with debugging code and understand how does buffer overflow works in action.</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-306542 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems" id="post-306542">
<header class="entry-header">
<h1 class="entry-title">Difference between Process and Thread</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>:</b><br/>
Process means any program is in execution. Process control block controls the operation of any process. Process control block contains the information about processes for example: Process priority, process id, process state, CPU, register etc. A process can creates other processes which are known as <b>Child Processes</b>. Process takes more time to terminate and it is isolated means it does not share memory with any other process.</p>
<p><b>:</b><br/>
Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process. A thread have 3 states: running, ready, and blocked.</p>
<p>Thread takes less time to terminate as compared to process and like process threads do not isolate.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-306379 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-306379">
<header class="entry-header">
<h1 class="entry-title">Difference between System Software and Application Software</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>System Software:</b><br/>
System Software is the type of software which is the interface between application software and system. Low level languages are used to write the system software. System Software maintain the system resources and give the path for application software to run. An important thing is that without system software, system can not run. It is a general purpose software.</p>
<p><b>Application Software:</b><br/>
Application Software is he type of software which runs as per user request. It runs on the platform which is provide by system software. High level languages are used to write the application software. Its a specific purpose software.</p>
<p>The main difference between System Software and Application Software is that without system software, system can not run on the other hand without application software, system always runs.</p>
<p><center></center></p>
<table style="width:90%">
<tr>
<th>S.NO</th>
<th>System Software</th>
<th>Application Software</th>
</tr>
<tr>
<td>1.</td>
<td>System Software maintain the system resources and give the path for application software to run.</td>
<td>Application software is built for specific tasks.</td>
</tr>
<tr>
<td>2.</td>
<td>Low level languages are used to write the system software.</td>
<td>While high level languages are used to write the application software.</td>
</tr>
<tr>
<td>3.</td>
<td>Its a general purpose software.</td>
<td>While its a specific purpose software.</td>
</tr>
<tr>
<td>4.</td>
<td>Without system software, system can’t run.</td>
<td>While without application software system always runs.</td>
</tr>
<tr>
<td>5.</td>
<td>System software runs when system is turned on and stop when system is turned off.</td>
<td>While application software runs as per the user’s request.</td>
</tr>
<tr>
<td>6.</td>
<td>Example of system software are operating system, etc.</td>
<td>Example of application software are Photoshop, VLC player etc.</td>
</tr>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-306494 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems" id="post-306494">
<header class="entry-header">
<h1 class="entry-title">Difference between Multiprocessing and Multithreading</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Both <b>Multiprocessing</b> and <b>Multithreading</b> are used to increase the computing power of a system.</p>
<p><b>Multiprocessing:</b><br/>
Multiprocessing is a system that has more than one or two processors. In Multiprocessing, CPUs are added for increasing computing speed of the system. Because of Multiprocessing, There are many processes are executed simultaneously. Multiprocessing are classified into two categories:</p>
<pre><b>1.</b> Symmetric Multiprocessing

<b>2.</b> Asymmetric Multiprocessing </pre>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-305707 post type-post status-publish format-standard hentry category-computer-organization-architecture category-difference-between category-gate-cs category-operating-systems" id="post-305707">
<header class="entry-header">
<h1 class="entry-title">Difference between Virtual memory and Cache memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>:</b><br/>
Cache memory increases the accessing speed of CPU. It is not a technique its a memory unit means a storage device. in cache memory, Recently used data are copied. Whenever the program is ready to executed it is fetched from main memory and copied to the cache memory if its copy is already present in cache memory than the program is directly executed.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-305726 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-305726">
<header class="entry-header">
<h1 class="entry-title">Difference between Supercomputer and Mainframe Computer</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Supercomputers:</b><br/>
Supercomputers are the largest in size and the most costly computers in the world. Seymour Cray invent the Supercomputer. Super computers are used for large and complex mathematical computations. Supercomputer’s speed is more than Mainframe computers so they can execute billions of instructions or floating point instructions within a second.</p>
<p><b>Mainframe Computers:</b><br/>
Mainframe Computers are less costly, small in size and slower in speed than the super computers. are used as a storage for large database and serve as a maximum number of users simultaneously. The first successful mainframe computer is invented by IBM. Mainframe computer’s speed is comparatively less than Supercomputers. In this millions of instructions are executed simultaneously.</p>
<p>Let’s see the difference between Supercomputer and Mainframe Computer:</p>
<p><center></center></p>
<table style="width:90%">
<tr>
<th>S.NO</th>
<th>Supercomputer</th>
<th>Mainframe Computer</th>
</tr>
<tr>
<td>1.</td>
<td>Super computers are used for large and complex mathematical computations.</td>
<td>While Mainframe computers are used as a storage for large database and serve as a maximum number of users simultaneously.</td>
</tr>
<tr>
<td>2.</td>
<td>Supercomputer’s speed is more than Mainframe computer. It can execute billions of instructions within a second.</td>
<td>Mainframe computer’s speed is comparatively less than Supercomputers. In this millions of instructions are executed simultaneously.</td>
</tr>
<tr>
<td>3.</td>
<td>Supercomputers are the largest computers.</td>
<td>Mainframe computers smaller than supercomputer in size.</td>
</tr>
<tr>
<td>4.</td>
<td>Supercomputers are the most costly in the the worlds.</td>
<td>Mainframe computers are less costly than supercomputers.</td>
</tr>
<tr>
<td>5.</td>
<td>In the present, the supercomputers have Linux and their variants operating systems.</td>
<td>While  Mainframe computers can have multiple operating systems simultaneously.</td>
</tr>
<tr>
<td>6.</td>
<td>Seymour Cray invent the Supercomputer.</td>
<td>The first successful mainframe computer is invented by IBM.</td>
</tr>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-305690 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems tag-distributed-system" id="post-305690">
<header class="entry-header">
<h1 class="entry-title">Difference between Network OS and Distributed OS</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
In this topic we shall see the difference between Network Operating System and Distributed Operating System. The main difference between these two operating systems (Network Operating System and Distributed Operating System) is that in <b>network operating system</b> each node or system can have <b>its own operating system</b> on the other hand in <b>distribute operating system</b> each node or system have <b>same operating system</b> which is opposite to the network operating system.</p>
<p>The difference Between Network Operating System and Distributed Operating System are given below:<br/>
</p></div></article><hr style="border: 2px dashed black;" /><article class="post-304860 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-304860">
<header class="entry-header">
<h1 class="entry-title">Raymond’s tree based algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<strong>Raymond’s tree based algorithm</strong> is lock based algorithm for mutual exclusion in a distributed system in which a site is allowed to enter the critical section if it has the token. In this algorithm, all sites are arranged as a directed tree such that the edges of the tree are assigned direction towards the site that holds the token. Site which holds the token is also called root of the tree.</p>
<p><strong>Data structure and Notations:</strong></p>
<ul>
<li>Every site S<sub>i</sub> keeps a FIFO queue, called <b>request_q</b><br/>
This queue stores the requests of all neighbouring sites that have sent a request for the token to site S<sub>i</sub> but have not yet been sent token. A non-empty <b>request_q</b> at any site indicates that the site has sent a <b>REQUEST</b> message to the root node.</li>
<li>Every site S<sub>i</sub> has a local variable, called <b>holder</b><br/>
This variable points to an immediate neighbour node on a directed path to the root node. </li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><strong>To enter Critical section:</strong>
<ul>
<li>When a site  S<sub>i</sub> wants to enter the critical section it sends a <b>REQUEST</b> message to the node along the directed path to the root, provided it does not hold the token and its <b>request_q</b> is empty. After sending <b>REQUEST</b> message it add its request to its <b>request_q</b>.</li>
<li>when a site S<sub>j</sub> on the path to the root receives the <b>REQUEST</b> message of site S<sub>i</sub>, it places the <b>REQUEST</b> in its <b>request_q</b> and sends the <b>REQUEST</b> message along the directed path to the root, if it has not sent any <b>REQUEST</b> message for previously received <b>REQUEST</b> message.</li>
<li>When the root site  S<sub>r</sub>( having token) receives the <b>REQUEST</b> message, it sends the token to the requesting site and sets its <b>holder</b> variable to point at that site.</li>
<li>On receiving the token, Site  S<sub>j</sub> deletes the top entry from its <b>request_q</b> and sends the token to the site indicated by deleted entry. <b>holder</b> variable of Site  S<sub>j</sub> is set to point at that site.<br/>
After deleting the topmost entry of the <b>request_q</b>, if it is still non-empty Site  S<sub>j</sub> sends a <b>REQUEST</b> message to the site indicated by <b>holder</b> variable in order to get token back. </li>
</ul>
</li>
<li><strong>To execute the critical section:</strong>
<ul>
<li>Site S<sub>i</sub> executes the critical section if it has received the token and its own entry is at the top of its <b>request_q</b>.</li>
</ul>
</li>
<li><strong>To release the critical section:</strong><br/>
After finishing the execution of the critical section, site S<sub>i</sub> does the following:</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-303874 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems" id="post-303874">
<header class="entry-header">
<h1 class="entry-title">Difference between Long-Term and Short-Term Scheduler</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Long-Term Scheduler</b> is also known as <b>Job Scheduler.</b> long-term scheduler regulates the programs which are selected to system for processing. In this the programs are setup in the queue and as per the requirement the best one job is selected and it takes the processes from job pool. It regulates the Degree of Multi-programming (DOM).</p>
<p><b>Short-Term Scheduler</b> is also known as <b>CPU Scheduler.</b> Short-Term Scheduler ensures which program is suitable or important for processing. It regulates the less DOM (Degree of Multi-programming).<br/>
</p></div></article><hr style="border: 2px dashed black;" /><article class="post-301894 post type-post status-publish format-standard hentry category-java category-operating-systems tag-java-multithreading tag-picked" id="post-301894">
<header class="entry-header">
<h1 class="entry-title">Message Passing in Java</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>What is message passing and why it is used?</strong><br/>
Message Passing in terms of computers is communication between processes. It is a form of communication used in object-oriented programming as well as parallel programming. Message passing in Java is like sending an object i.e. message from one thread to another thread. It is used when threads do not have shared memory and are unable to share monitors or semaphores or any other shared variables to communicate. Suppose we consider an example of producer and consumer, likewise what produce will produce, the consumer will be able to consume that only. We mostly use <strong><a href="http://www.geeksforgeeks.org/queue-data-structure/">Queue</a></strong> to implement communication between threads. </p>
<p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190509121341/Message-Passing-in-Java.jpg"><img alt="" class="aligncenter size-large wp-image-1048436" height="412" src="https://media.geeksforgeeks.org/wp-content/uploads/20190509121341/Message-Passing-in-Java-1024x634.jpg" width="665"/></a></p>
<p>In the example explained below, we will be using vector(queue) to store the messages, 7 at a time and after that producer will wait for the consumer until the queue is empty. </p>
<p>In Producer there are two synchronized methods <b>putMessage()</b> which will call form <b>run()</b> method of Producer and add message in Vector whereas <b>getMessage()</b> extracts the message from the queue for the consumer.</p>
<p>Using message passing simplifies <a href="https://www.geeksforgeeks.org/producer-consumer-solution-using-threads-java/">the producer-consumer problem</a> as they don’t have to reference each other directly but only communicate via a queue.</p>
<p><b>Example:</b></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-298354 post type-post status-publish format-standard hentry category-c-arrays category-operating-systems category-queue" id="post-298354">
<header class="entry-header">
<h1 class="entry-title">LRU Approximation (Second Chance Algorithm)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>If you are not familiar with Least Recently Used Algorithm, check <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-1-lru/">Least Recently Used Algorithm(Page Replacement)</a></p>
<p>This algorithm is a combination of using a queue, similar to FIFO (<a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-2-fifo/">FIFO (Page Replacement)</a>) alongside using an array to keep track of the bits used to give the queued page a “second chance”.<br/>
<br/>
<strong>How does the algorithm work:</strong></p>
<blockquote>
<ol>
<li>Set all the values of the bitref as False (Let it be the size of max capacity of queue).</li>
<li>Set an empty queue to have a max capacity.</li>
<li>Check if the queue is not full:
<ul>
<li>If the element is in the queue, set its corresponding bitref = 1.</li>
<li>If the element is not in the queue, then push it into the queue.</li>
</ul>
</li>
<li>If the queue is full:
<ul>
<li>Find the first element of the queue that has its bitref = 0 and if any element in the front has bitref = 1, set it to 0. Rotate the queue until you find an element with bitref = 0.</li>
<li>Remove that element from the queue.</li>
<li>Push the current element from the input array into the queue.</li>
</ul>
</li>
</ol>
</blockquote>
<p><strong>Explanation:</strong><br/>
The bits are set as usual in this case to one for the indices in the bitref until the queue is full.<br/>
Once the queue becomes full, according to FIFO Page Replacement Algorithm, we should get rid of the front of the queue (if the element is a fault/miss). But here we don’t do that.</p>
<p>Instead we first check its reference bit (aka bitref) if its 0 or 1 (False or True). If it is 0 (false), we pop it from the queue and push the waiting element into the queue. But if it is 1 (true), we then set its reference bit (bitref) to 0 and move it to the back of the queue. We keep on doing this until we come across the front of the queue to have its front value’s reference bit (bitref) as 0 (false).</p>
<p>Then we follow the usual by removing it from the queue and pushing the waiting element into the queue.</p>
<p>What if the waiting element is in the queue already? We just set its reference bit (bitref) to 1 (true).</p>
<p><img alt="" class="alignnone size-full wp-image-1016736" height="699" src="https://media.geeksforgeeks.org/wp-content/uploads/20190421142645/OriginalQueue-shot.png" width="518"><br/>
We now move all the values like 2, 4, 1 to the back until we encounter 3, whose bitref is 0. While moving 2, 4, 1 to the back, we set their bitref values to 0.<br/>
<img alt="" class="alignnone size-full wp-image-1016738" height="770" src="https://media.geeksforgeeks.org/wp-content/uploads/20190421142735/NewQueueState.png" width="475"/></img></p>
<p>So now, the question how is this an approximation of <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-1-lru/">LRU</a>, when it clearly implements <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-2-fifo/">FIFO</a> instead of <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-1-lru/">LRU</a>. Well, this works by giving a second chance to the front of the queue (which in <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-2-fifo/">FIFO</a>‘s case would have been popped and replaced). Here, the second chance is based on the fact that if the element is seen “recently” its reference bit (bitref) is set to 1 (true). If it was not seen recently, we would not have set its reference bit (bitref) to 1 (true) and thus removed it. Hence, this is why, it is an approximation and not <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-1-lru/">LRU</a> nor <a href="https://www.geeksforgeeks.org/program-page-replacement-algorithms-set-2-fifo/">FIFO</a>.</p>
<p>Below is the implementation of the above approach:</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-297276 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-297276">
<header class="entry-header">
<h1 class="entry-title">Mutual exclusion in distributed system | Suzuki–Kasami algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: </p>
<p><strong>Suzuki–Kasami algorithm</strong> is a token-based algorithm for achieving mutual exclusion in distributed systems.This is modification of Ricart–Agrawala algorithm, a permission based (Non-token based) algorithm which uses <b>REQUEST</b> and <b>REPLY</b> messages to ensure mutual exclusion.  </p>
<p>In token-based algorithms, A site is allowed to enter its critical section if it possesses the unique token. Non-token based algorithms uses timestamp to order requests for the critical section where as sequence number is used in token based algorithms.</p>
<p>Each requests for critical section contains a sequence number. This sequence number is used to distinguish old and current requests.</p>
<ul>
</ul>
<p><strong>Data structure and Notations:</strong></p>
<ul>
<li>An array of integers <b>RN[1…N]</b><br/>
        A site S<sub>i</sub> keeps <b>RN<sub>i</sub>[1…N]</b>, where <b>RN<sub>i</sub>[j]</b> is the largest sequence number received so far through <b>REQUEST</b> message from site S<sub>i</sub>.</li>
<li>An array of integer <b>LN[1…N]</b><br/>
         This array is used by the token.<b>LN[J]</b> is the sequence number of the request that is recently executed by site S<sub>j</sub>.</li>
<li>A queue <b>Q</b><br/>
        This data structure is used by the token to keep record of ID of sites waiting for the token</li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><strong>To enter Critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> wants to enter the critical section and it does not have the token then it increments its sequence number <b>RN<sub>i</sub>[i]</b> and sends a request message <b>REQUEST(i, sn)</b> to all other sites in order to request the token.<br/>
Here <b>sn</b> is update value of <b>RN<sub>i</sub>[i]</b></li>
<li>When a site S<sub>j</sub> receives the request message  <b>REQUEST(i, sn)</b> from site S<sub>i</sub>, it sets <b>RN<sub>j</sub>[i]</b> to maximum of <b>RN<sub>j</sub>[i]</b> and <b>sn</b> i.e <b>RN<sub>j</sub>[i]</b> = max(<b>RN<sub>j</sub>[i]</b>, <b>sn</b>).</li>
<li>After updating  <b>RN<sub>j</sub>[i]</b>, Site S<sub>j</sub> sends the token to site S<sub>i</sub> if it has token and <b>RN<sub>j</sub>[i]</b> = <b>LN[i]</b> + 1</li>
</ul>
</li>
<li><strong>To execute the critical section:</strong>
<ul>
<li>Site S<sub>i</sub> executes the critical section if it has acquired the token.</li>
</ul>
</li>
<li><strong>To release the critical section:</strong><br/>
After finishing the execution Site S<sub>i</sub>  exits the critical section and does following:</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-297946 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-297946">
<header class="entry-header">
<h1 class="entry-title">Algorithm for implementing Distributed Shared Memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Distributed shared memory(DSM)</strong> system is a resource management component of distributed operating system that implements shared memory model in distributed system which have no physically shared memory. The shared memory model provides a virtual address space which is shared by all nodes in a distributed system. </p>
<p>The central issues in implementing DSM are:</p>
<ul>
<li>how to keep track of location of remote data.</li>
<li>how to overcome communication overheads and delays involved in execution of communication protocols in system for accessing remote data.</li>
<li>how to make shared data concurrently accessible at several nodes to improve performance.</li>
</ul>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-297249 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-297249">
<header class="entry-header">
<h1 class="entry-title">Chandy–Lamport’s global state recording algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Each distributed system has a number of processes running on a number of different physical servers. These processes communicate with each other via communication channels using text messaging. These processes neither have a shared memory nor a common physical clock, this makes the process of determining the instantaneous global state difficult.  </p>
<p>A process could record it own local state at a given time but the messages that are in transit (on its way to be delivered) would not be included in the recorded state and hence the actual state of the system would be incorrect after the time in transit message is delivered. </p>
<p><b>Chandy</b> and <b>Lamport</b> were the first to propose a algorithm to capture consistent global state of a distributed system. The main idea behind proposed algorithm is that if we know that all message that hat have been sent by one process have been received by another then we can record the global state of the system. </p>
<p>Any process in the distributed system can initiate this global state recording algorithm using a special message called <b>MARKER</b>. This marker traverse the distributed system across all communication channel and cause each process to record its own state. In the end, the state of entire system (Global state) is recorded. This algorithm does not interfere with normal execution of processes.</p>
<p><strong>Assumptions of the algorithm:</strong></p>
<ul>
<li>There are finite number of processes in the distributed system and they do not share memory and clocks.</li>
<li>There are finite number of communication channels and they are unidirectional and FIFO ordered.</li>
<li>There exists a communication path between any two processes in the system</li>
<li>On a channel, messages are received in the same order as they are sent.</li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><b>Marker sending rule for a process <em>P</em> :</b>
<ul>
<li>Process <b>p</b> records its own local state</li>
<li>For each outgoing channel <b>C</b> from process <b>P</b>, <b>P</b> sends marker along <b>C</b> before sending any other messages along <b>C</b>.<br/>
(<b>Note:</b> Process Q will receive this marker on his incoming channel C1.)  </li>
</ul>
</li>
<li><b>Marker receiving rule for a process <em>Q</em> :</b>
<ul>
<li>If process <b>Q</b> has not yet recorded its own local state then
<ul>
<li>Record the state of incoming channel C1 as an empty sequence or null.</li>
<li>After recording the state of incoming channel C1, process <b>Q</b> Follows the marker sending rule</li>
</ul>
</li>
<li>If process <b>Q</b> has already recorded its state
<ul>
<li>Record the state of incoming channel <b>C1</b> as the sequence of messages received along channel C1  after the state of <b>Q</b> was recorded and before <b>Q</b> received the marker along C1 from process P.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Need of taking snapshot or recording global state of the system:</strong></p>
<ul>
<li><b>Checkpointing:</b> It helps in creating checkpoint. If somehow application fails, this checkpoint can be used re</li>
<li><b>Garbage collection:</b> It can be used to remove objects that do not have any references.</li>
<li>It can be used in deadlock and termination detection.</li>
<li>It is also helpful in other debugging.</li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-297485 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-297485">
<header class="entry-header">
<h1 class="entry-title">Huang’s Termination detection algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Huang’s algorithm</strong> is an algorithm for detecting termination in a distributed system. The algorithm was proposed by <b>Shing-Tsaan Huang</b> in 1989 in the Journal of Computers.</p>
<p>In a distributed system, a process is either in an active state or in an idle state at any given point of time. Termination occurs when all of the processes becomes idle and there are no any in transit(on its way to be delivered) computational message. </p>
<p><strong>Assumptions of the algorithm:</strong></p>
<ul>
<li>One of the co-operating processes which monitors the computation is called the <b>controlling agent</b>.</li>
<li>The initial weight of <b>controlling agent</b> is 1 </li>
<li>All other processes are initially idle and have weight 0.</li>
<li>The computation starts when the controlling agent send a computation message to one of the processes.</li>
<li>The process become active on receiving a computation message.</li>
<li>Computation message can be sent only by controlling agent or an active process. </li>
<li>Control message is sent to controlling agent by an active process when they are becoming idle.</li>
<li>The algorithm assigns a weight <b>W</b> (such that 0 &lt; <b>W</b> &lt; 1 ) to every active process and every in transit message.</li>
</ul>
<p><strong>Notations used in the algorithm:</strong></p>
<ul>
<li><strong>B(DW):</strong> Computation message with weight <b>DW</b></li>
<li><b>C(DW)</b>: Control message with weight <b>DW</b></li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><b>Rule to send B(DW) –</b>
<ul>
<li>Suppose Process P with weight <b>W</b> is sending <b>B(DW)</b> to process Q</li>
<li>Split the weight of the process P into <b>W1</b> and <b>W2</b>.<br/>
         Such that</li></ul></li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-297477 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-297477">
<header class="entry-header">
<h1 class="entry-title">Hierarchical Deadlock Detection in Distributed System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <br/>
In hierarchical deadlock detection algorithm, sites are arranged in a hierarchical fashion and a site detects deadlocks involving only its descendant sites. Distributed deadlock algorithms delegate the responsibility of deadlock detection to individual sites while in hierarchical there are local detectors at each site which communicate their local wait for graphs(WFG) with one another.</p>
<p><strong>Approach:</strong><br/>
Deadlocks that are local to a single site are detected at that site using their local WFG. Each site also sends its local WFG to deadlock detector at the next level. Thus, distributed deadlocks involving 2 or more sites would be detected by a deadlock detector in lowest level that has control over these sites.</p>
<p>In this approach, there are 2 methods to detect:</p>
<p><strong>1. Ho-Ramamoorthy algorithm:</strong></p>
<ul>
<li>Uses only two levels i.e. Master control nodes and Cluster control nodes.</li>
<li>Cluster control nodes are used for detecting deadlock among their members and reporting dependencies outside their cluster to Master control node.</li>
<li>The master control node is responsible for detecting inter-cluster deadlocks.</li>
</ul>
<p><strong>2. Menasce-Muntz algorithm:</strong> </p>
<ul>
<li>Leaf controllers are responsible for allocating resources whereas branch controllers find deadlock among the resources that their children span in the tree.</li>
<li>Network congestion can be managed and node failure is less critical than in fully centralized.</li>
<li>Detection can be done ways such as Continuous allocation reporting or periodically allocation reporting.</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>If the hierarchy coincides with resource access pattern local to cluster of sites, this approach can provide efficient deadlock detection as compared to both centralized and distributed methods.</li>
<li>It reduces the dependence on central sites thus, reducing the communication cost.</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>If deadlocks are span over several clusters, this approach will be inefficient.</li>
<li>It is more complicated to implement and would involve nontrivial modification to lock and transaction manager algorithms.</li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-296917 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems" id="post-296917">
<header class="entry-header">
<h1 class="entry-title">Computer Organization | Why need Interrupt ?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Interrupt</b> is the mechanism by which modules like I/O or memory may interrupt the normal processing by CPU. It may be either clicking a mouse, dragging a cursor, printing a document etc the case where interrupt is getting generated.</p>
<p><b>Why we require Interrupt? </b><br/>
External devices are comparatively slower than CPU. So if there is no interrupt CPU would waste a lot of time waiting for external devices to match its speed with that of CPU. This decreases the efficiency of CPU. Hence, interrupt is required to eliminate these limitations.</p>
<p><b>With Interrupt:</b></p>
<ol>
<li>Suppose CPU instructs printer to print a certain document.
</li>
<li>While printer does its task, CPU engaged in executing other tasks.
</li>
<li>When printer is done with its given work, it tells CPU that it has done with its work.<br/>
   (The word ‘tells’ here is interrupt which sends one message that printer has done its work successfully.).
</li>
</ol>
<p><b>Advantages:</b></p>
<ul>
<li>It increases the efficiency of CPU.
</li>
<li>It decreases the waiting time of CPU.
</li>
<li>Stops the wastage of instruction cycle.
</li>
</ul>
<p><b>Disadvantages:</b></p>
<ul>
<li>CPU has to do a lot of work to handle interrupts, resume its previous execution of programs (in short, overhead required to handle the  interrupt request.).
</li>
</ul>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-296892 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-296892">
<header class="entry-header">
<h1 class="entry-title">Mutual exclusion in distributed system | Lamport’s Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <br/>
<strong>Lamport’s Distributed Mutual Exclusion Algorithm</strong> is a permission based algorithm proposed by Lamport as an illustration of his synchronization scheme for distributed systems.<br/>
In permission based timestamp is used to order critical section requests and to resolve any conflict between requests.</p>
<p>In Lamport’s Algorithm critical section requests are executed in the increasing order of timestamps i.e a request with smaller timestamp will be given permission to execute critical section first than a request with larger timestamp. </p>
<p>In this algorithm:</p>
<ul>
<li>Three type of messages ( <b>REQUEST</b>, <b>REPLY</b> and <b>RELEASE</b>) are used and communication channels are assumed to follow FIFO order.</li>
<li>A site send a <b>REQUEST</b> message to all other site to get their permission to enter critical section.</li>
<li>A site send a <b>REPLY</b> message to requesting site to give its permission to enter the critical section.</li>
<li>A site send a <b>RELEASE</b> message to all other site upon exiting the critical section.</li>
<li>Every site S<sub>i</sub>, keeps a queue to store critical section requests ordered by their timestamps.<br/>
<b>request_queue<sub>i</sub></b> denotes the queue of site S<sub>i</sub></li>
<li>A timestamp is given to each critical section request using Lamport’s logical clock. </li>
<li>Timestamp is used to determine priority of critical section requests. Smaller timestamp gets high priority over larger timestamp. The execution of critical section request is always in the order of their timestamp.</li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><strong>To enter Critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> wants to enter the critical section, it sends a request message <b>Request(ts<sub>i</sub>, i)</b> to all other sites and places the request on <b>request_queue<sub>i</sub></b>. Here, Ts<sub>i</sub> denotes the timestamp of Site S<sub>i</sub></li>
<li>When a site S<sub>j</sub> receives the request message <b>REQUEST(ts<sub>i</sub>, i)</b> from site S<sub>i</sub>, it returns a timestamped REPLY message to site S<sub>i</sub> and places the request of site S<sub>i</sub> on <b>request_queue<sub>j</sub></b></li>
<p>.
</p></ul>
</li>
<li><strong>To execute the critical section:</strong>
<ul>
<li>A site S<sub>i</sub> can enter the critical section if it has received the message with timestamp larger than <b>(ts<sub>i</sub>, i)</b> from all other sites and its own request is at the top of <b>request_queue<sub>i</sub></b></li>
</ul>
</li>
<li><strong>To release the critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> exits the critical section, it removes its own request from the top of its request queue and sends a timestamped <b>RELEASE</b> message to all other sites</li>
<li>When a site S<sub>j</sub> receives the timestamped <b>RELEASE</b> message from site S<sub>i</sub>, it removes the request of S<sub>i</sub> from its request queue</li>
</ul>
</li>
</ul>
<p><strong>Message Complexity:</strong><br/>
Lamport’s Algorithm requires invocation of 3(N – 1) messages per critical section execution. These 3(N – 1) messages involves</p>
<ul>
<li>(N – 1) request messages</li>
<li>(N – 1) reply messages</li>
<li>(N – 1) release messages</li>
</ul>
<p><strong>Drawbacks of Lamport’s Algorithm:</strong></p>
<ul>
<li><strong>Unreliable approach:</strong> failure of any one of the processes will halt the progress of entire system.</li>
<li><strong>High message complexity:</strong> Algorithm requires 3(N-1) messages  per critical section invocation.</li>
</ul>
<p><strong>Performance:</strong></p>
<ul>
<li>Synchronization delay is equal to maximum message transmission time</li>
<li>It requires 3(N – 1) messages per CS execution.</li>
<li>Algorithm can be optimized to 2(N – 1) messages by omitting the <b>REPLY</b> message in some situations.  </li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-296849 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-296849">
<header class="entry-header">
<h1 class="entry-title">Mutual exclusion in distributed system | Maekawa’s Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<strong>Maekawa’s Algorithm</strong> is quorum based approach to ensure mutual exclusion in distributed systems. As we know, In permission based algorithms like Lamport’s Algorithm, Ricart-Agrawala Algorithm etc. a site request permission from every other site but in quorum based approach, A site does not request permission from every other site but from a subset of sites which is called <b>quorum</b>.</p>
<p>In this algorithm:</p>
<ul>
<li>Three type of messages ( <b>REQUEST</b>, <b>REPLY</b> and <b>RELEASE</b>) are used.</li>
<li>A site send a <b>REQUEST</b> message to all other site in its request set or quorum to get their permission to enter critical section.</li>
<li>A site send a <b>REPLY</b> message to requesting site to give its permission to enter the critical section.</li>
<li>A site send a <b>RELEASE</b> message to all other site in its request set or quorum upon exiting the critical section.</li>
</ul>
<p><strong>The construction of request set or Quorum:</strong><br/>
A request set or Quorum in Maekawa’s algorithm must satisfy the following properties:</p>
<ol>
<li>
<pre>∀i ∀j : i ≠ j, 1 ≤ i, j ≤ N :: R<sub>i</sub> ⋂ R<sub>j</sub> ≠ ∅ </pre>
<p><b>i.e</b> there is at least one common site between the request sets of any two sites.</p></li>
<li>
<pre>∀i : 1 ≤ i ≤ N :: S<sub>i</sub> ∊ R<sub>i</sub> </pre>
</li>
<li>
<pre>∀i : 1 ≤ i ≤ N :: |R<sub>i</sub>| = K </pre>
</li>
<li>Any site S<sub>i</sub> is contained in exactly K sets.</li>
<li>
<pre>N = K(K - 1) +1 and |R<sub>i</sub>| = √N </pre>
</li>
</ol>
<p><strong>Algorithm:</strong></p>
<ul>
<li><strong>To enter Critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> wants to enter the critical section, it sends a request message <b>REQUEST(i)</b> to all other sites in the request set <b>R<sub>i</sub></b>.</li>
<li>When a site S<sub>j</sub> receives the request message <b>REQUEST(i)</b> from site S<sub>i</sub>, it returns a <b>REPLY</b> message to site S<sub>i</sub> if it has not sent a <b>REPLY</b> message to the site from the time it received the last <b>RELEASE</b> message. Otherwise, it queues up the request. </li>
<p>.
        </p></ul>
</li>
<li><strong>To execute the critical section:</strong>
<ul>
<li>A site S<sub>i</sub> can enter the critical section if it has received the <b>REPLY</b> message from all the site in request set <b>R<sub>i</sub></b></li>
</ul>
</li>
<li><strong>To release the critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> exits the critical section, it sends <b>RELEASE(i)</b> message to all other sites in request set <b>R<sub>i</sub></b></li>
<li>When a site S<sub>j</sub> receives the <b>RELEASE(i)</b> message from site S<sub>i</sub>, it send <b>REPLY</b> message to the next site waiting in the queue and deletes that entry from the queue</li>
<li>In case queue is empty, site S<sub>j</sub> update its status to show that it has not sent any <b>REPLY</b> message since the receipt of the last <b>RELEASE</b> message  </li>
</ul>
</li>
</ul>
<p><strong>Message Complexity:</strong><br/>
Maekawa’s Algorithm requires invocation of 3√N messages per critical section execution as the size of a request set is √N. These 3√N messages involves.</p>
<ul>
<li>√N request messages</li>
<li>√N reply messages</li>
<li>√N release messages</li>
</ul>
<p><strong>Drawbacks of Maekawa’s Algorithm:</strong></p>
<ul>
<li>This algorithm is deadlock prone because a site is exclusively locked by other sites and requests are not prioritized by their timestamp.</li>
</ul>
<p><strong>Performance:</strong></p>
<ul>
<li>Synchronization delay is equal to twice the message propagation delay time</li>
<li>It requires 3√n messages per critical section execution. </li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-296884 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-296884">
<header class="entry-header">
<h1 class="entry-title">Mutual exclusion in distributed system | Ricart–Agrawala algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <br/>
<strong>Ricart–Agrawala algorithm</strong> is an algorithm to for mutual exclusion in a distributed system proposed by Glenn Ricart and Ashok Agrawala. This algorithm is an extension and optimization of Lamport’s Distributed Mutual Exclusion Algorithm. Like Lamport’s Algorithm, it also follows permission based approach to ensure mutual exclusion.   </p>
<p>In this algorithm:</p>
<ul>
<li>Two type of messages ( <b>REQUEST</b> and <b>REPLY</b>) are used and communication channels are assumed to follow FIFO order.</li>
<li>A site send a <b>REQUEST</b> message to all other site to get their permission to enter critical section.</li>
<li>A site send a <b>REPLY</b> message to other site to give its permission to enter the critical section.</li>
<li>A timestamp is given to each critical section request using Lamport’s logical clock. </li>
<li>Timestamp is used to determine priority of critical section requests. Smaller timestamp gets high priority over larger timestamp. The execution of critical section request is always in the order of their timestamp.</li>
</ul>
<p><strong>Algorithm:</strong></p>
<ul>
<li><strong>To enter Critical section:</strong>
<ul>
<li>When a site S<sub>i</sub> wants to enter the critical section, it send a timestamped <b>REQUEST</b> message to all other sites.</li>
<li>When a site S<sub>j</sub> receives a <b>REQUEST</b> message from site S<sub>i</sub>, It sends a <b>REPLY</b> message to site S<sub>i</sub> if and only if
<ul>
<li>Site S<sub>j</sub> is neither requesting nor currently executing the critical section.</li>
<li>In case Site S<sub>j</sub> is requesting, the timestamp of Site S<sub>i</sub>‘s request is smaller than its own request. </li>
<p>Otherwise the request is deferred by site S<sub>j</sub>.
          </p></ul>
</li>
</ul>
</li>
<li><strong>To execute the critical section:</strong>
<ul>
<li>Site S<sub>i</sub> enters the critical section if it has received the <b>REPLY</b> message from all other sites.</li>
</ul>
</li>
<li><strong>To release the critical section:</strong>
<ul>
<li>Upon exiting site S<sub>i</sub> sends <b>REPLY</b> message to all the deferred requests.</li>
</ul>
</li>
</ul>
<p><strong>Message Complexity:</strong><br/>
Ricart–Agrawala algorithm requires invocation of 2(N – 1) messages per critical section execution. These 2(N – 1) messages involves</p>
<ul>
<li>(N – 1) request messages</li>
<li>(N – 1) reply messages</li>
</ul>
<p><strong>Drawbacks of Ricart–Agrawala algorithm:</strong></p>
<ul>
<li><strong>Unreliable approach:</strong> failure of any one of node in the system can halt the progress of the system. In this situation, the process will starve forever.<br/>
The problem of failure of node can be solved by detecting failure after some timeout. </li>
</ul>
<p><strong>Performance:</strong></p>
<ul>
<li>Synchronization delay is equal to maximum message transmission time</li>
<li>It requires 2(N – 1) messages per Critical section execution</li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-296618 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-296618">
<header class="entry-header">
<h1 class="entry-title">Operating System | Recovery From Deadlock</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
When a  determines that a deadlock has occurred in the system, the system must recover from that deadlock. There are two approaches of breaking a :</p>
<p><strong>1. Process Termination:</strong><br/>
To eliminate the deadlock, we can simply kill one or more processes. For this, we use two methods:</p>
<ul>
<li><strong>(a). Abort all the Deadlocked Processes:</strong><br/>
Aborting all the processes will certainly break the deadlock, but with a great expenses. The deadlocked processes may have computed for a long time and the result of those partial computations must be discarded and there is a probability to recalculate them later.</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-296562 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-distributed-system" id="post-296562">
<header class="entry-header">
<h1 class="entry-title">Mutual exclusion in distributed system</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Mutual exclusion</strong> is a concurrency control property which is introduced to prevent race conditions. It is the requirement that a process can not enter its critical section while another concurrent process is currently present or executing in its critical section i.e only one process is allowed to execute the critical section at any given instance of time.</p>
<p><strong>Mutual exclusion in single computer system Vs. distributed system:</strong><br/>
In single computer system, memory and other resources are shared between different processes. The status of shared resources and the status of users is easily available in the shared memory so with the help of shared variable (For example: ) mutual exclusion problem can be easily solved. </p>
<p>In Distributed systems, we neither have shared memory nor a common physical clock and there for we can not solve mutual exclusion problem using shared variables. To eliminate the mutual exclusion problem in distributed system approach based on message passing is used.</p>
<p>A site in distributed system do not have complete information of state of the system due to lack of shared memory and a common physical clock. </p>
<p><strong>Requirements of Mutual exclusion Algorithm:</strong></p>
<ul>
<li><strong>No Deadlock:</strong><br/>
Two or more site should not endlessly wait for any message that will never arrive.</li>
<li><strong>No Starvation:</strong><br/>
Every site who wants to execute critical section should get an opportunity to execute it in finite time. Any site should not wait indefinitely to execute critical section while other site are repeatedly executing critical section</li>
<li><strong>Fairness:</strong><br/>
Each site should get a fair chance to execute critical section. Any request to execute critical section must be executed in the order they are made i.e  Critical section execution requests should be executed in the order of their arrival in the system.</li>
<li><strong>Fault Tolerance:</strong><br/>
In case of failure, it should be able to recognize it by itself in order to continue functioning without any disruption.</li>
</ul>
<p><strong>Solution to distributed mutual exclusion:</strong><br/>
As we know shared variables or a local kernel can not be used to implement mutual exclusion in distributed systems. Message passing is a way to implement mutual exclusion. Below are the three approaches based on message passing to implement mutual exclusion in distributed systems:</p>
<ol>
<li><b>Token Based Algorithm:</b>
<ul>
<li>A unique <b>token</b> is shared among all the sites.</li>
<li>If a site possesses the unique token, it is allowed to enter its critical section </li>
<li>This approach uses sequence number to order requests for the critical section.</li>
<li>Each requests for critical section contains a sequence number. This sequence number is used to distinguish old and current requests.</li>
<li>This approach insures Mutual exclusion as the token is unique</li>
<li>
<pre><b>Example:</b> 

Suzuki-Kasami’s Broadcast Algorithm</pre>
</li>
</ul>
</li>
<li><b>Non-token based approach:</b>
<ul>
<li>A site communicates with other sites in order to determine which sites should execute critical section next. This requires exchange of two or more successive round of messages among sites.</li>
<li>This approach use timestamps instead of sequence number to order requests for the critical section.</li>
<li>When ever a site make request for critical section, it gets a timestamp. Timestamp is also used to resolve any conflict between critical section requests.</li>
<li>All algorithm which follows non-token based approach maintains a logical clock. Logical clocks get updated according to Lamport’s scheme</li>
<li>
<pre><b>Example:</b> 

Lamport's algorithm, Ricart–Agrawala algorithm</pre>
</li>
</ul>
</li>
<li><b>Quorum based approach:</b>
<ul>
<li>Instead of requesting permission to execute the critical section from all other sites, Each site requests only a subset of sites which is called a <b>quorum</b>. </li>
<li>Any two subsets of sites or Quorum contains a common site.</li>
<li>This common site is responsible to ensure mutual exclusion</li>
<li>
<pre><b>Example:</b> 

Maekawa’s Algorithm</pre>
</li>
</ul>
</li>
</ol>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-279546 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-279546">
<header class="entry-header">
<h1 class="entry-title">Operating System | Translation Lookaside Buffer (TLB)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In Operating System (Memory Management Technique : ), for each process page table will be created, which will contain . This PTE will contain information like frame number (The address of main memory where we want to refer), and some other useful bits (e.g., valid/invalid bit, dirty bit, protection bit etc). This page table entry (PTE) will tell where in the main memory the actual page is residing. </p>
<p>Now the question is where to place the page table, such that overall access time (or reference time) will be less. </p>
<p>The problem initially was to fast access the main memory content based on address generated by CPU (i.e ). Initially, some people thought of using registers to store page table, as they are high-speed memory so access time will be less. </p>
<p>The idea used here is, place the page table entries in registers, for each request generated from CPU (virtual address), it will be matched to the appropriate page number of the page table, which will now tell where in the main memory that corresponding page resides. Everything seems right here, but the problem is register size is small (in practical, it can accommodate maximum of  0.5k to 1k page table entries) and process size may be big hence the required page table will also be big (lets say this page table contains 1M entries), so registers may not hold all the PTE’s of Page table. So this is not a practical approach.</p>
<p>To overcome this size issue, the entire page table was kept in main memory. but the problem here is two main memory references are required:</p>
<ol>
<li>To find the frame number
</li>
<li>To go to the address specified by frame number
</li>
</ol>
<p>To overcome this problem a high-speed cache is set up for page table entries called a Translation Lookaside Buffer (TLB). Translation Lookaside Buffer (TLB) is nothing but a special cache used to keep track of recently used transactions. TLB contains page table entries that have been most recently used. Given a virtual address, the processor examines the TLB if a page table entry is present (TLB hit), the frame number is retrieved and the real address is formed. If a page table entry is not found in the TLB (TLB miss), the page number is used to index the process page table. TLB first checks if the page is already in main memory, if not in main memory a page fault is issued then the TLB is updated to include the new page entry.</p>
<p><img class="aligncenter size-full" height="484" src="https://media.geeksforgeeks.org/wp-content/uploads/20190225192626/tlb1.jpg" width="849"/></p>
<p><b>Steps in TLB hit:</b></p>
<ol>
<li>CPU generates virtual address.
</li>
<li>It is checked in TLB (present).
</li>
<li>Corresponding frame number is retrieved, which now tells where in the main memory page lies.
</li>
</ol>
<p><b>Steps in Page miss:</b></p>
<ol>
<li>CPU generates virtual address.
</li>
<li>It is checked in TLB (not present).
</li>
<li>Now the page number is matched to page table residing in main memory (assuming page table contains all PTE).
</li>
<li>Corresponding frame number is retrieved, which now tells where in the main memory page lies.
</li>
<li>The TLB is updated with new PTE (if space is not there, one of the replacement technique comes into picture i.e either FIFO, LRU or MFU etc).
</li>
</ol>
<p><strong>Effective memory acess time(EMAT) :</strong> TLB is used to reduce effective memory access time as it is a high speed associative cache.<br/>
<strong>EMAT = h*(c+m) + (1-h)*(c+2m) </strong><br/>
where, h = hit ratio of TLB<br/>
       m = Memory access time<br/>
       c = TLB access time </p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-278610 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems category-technical-scripter" id="post-278610">
<header class="entry-header">
<h1 class="entry-title">Operating System | The Linux Kernel</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The main purpose of a computer is to run a <em>predefined sequence of instructions</em>, known as a <strong>program</strong>. A program under execution is often referred to as a <strong>process</strong>. Now, most special purpose computers are meant to run a single process, but in a sophisticated system such a general purpose computer, are intended to run many processes simulteneously. Any kind of process requires hardware resources such are Memory, Processor time, Storage space, etc.</p>
<p>In a General Purpose Computer running many processes simulteneously, we need a middle layer to manage the distribution of the hardware resources of the computer efficiently and fairly among all the various processes running on the computer. This middle layer is referred to as the <strong>kernel</strong>. Basically the kernel virtualizes the common hardware resources of the computer to provide each process with its own virtual resources. This makes the process seem as it is the sole process running on the machine. The kernel is also responsible for preventing and mitigating conflicts between different processes.</p>
<p> This schematically represented below:</p>
<p><img class="aligncenter size-full" height="331" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Hardware_Virtualization.png" width="391"><br/>
<center><b>Figure:</b> Virtual Resources for each Process</center></img></p>
<p>The <strong>Core Subsystems</strong> of the <strong>Linux Kernel</strong> are as follows:</p>
<ol>
<li> The Process Scheduler</li>
<li> The Memory Management Unit (MMU)</li>
<li> The Virtual File System (VFS) </li>
<li> The Networking Unit </li>
<li> Inter-Process Communication Unit </li>
</ol>
<p><img class="aligncenter size-full" height="328" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Linux_Subsystem.png" width="422"><br/>
<center><b>Figure:</b> The Linux Kernel</center></img></p>
<p>For the purpose of this article we will only be focussing on the 1st three important subsystems of the Linux Kernel.</p>
<p>The basic functioning of each of the 1st three subsystems is elaborated below:</p>
<ul>
<li> <strong>The Process Scheduler:</strong><br/>
This kernel subsystem is responsible for fairly distributing the CPU time among all the processes running on the system simulteneously.</li>
<li><strong> The Memory Management Unit:</strong><br/>
This kernel sub-unit is responsible for proper distribution of the memory resources among the various processes running on the system. The MMU does more than just simply provide separate virtual address spaces for each of the processes. </li>
<li><strong> The Virtual File System:</strong><br/>
This subsystem is responsible for providing a unified interface to access stored data across different filesystems and physical storage media.
  </li>
</ul>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-277737 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems tag-os-memory-management" id="post-277737">
<header class="entry-header">
<h1 class="entry-title">Computer Organization | Random Access Memory (RAM) vs Hard Disk Drive (HDD)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A person novice to computers often is in confusion between  and . Here we draw comparisons between the two.</p>
<p><strong>Similarities between RAM and HDD : </strong></p>
<ul>
<li>Both are used for storage of data.</li>
<li>Both are physical components of the computer machine.</li>
</ul>
<p><strong>Differences between RAM and HDD :</strong></p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>Parameter</th>
<th>RAM</th>
<th>HDD</th>
</tr>
</thead>
<tbody>
<tr>
<td>Full Form</td>
<td>RAM stands for Random Access Memory.</td>
<td>HDD stands for Hard Disk Drive.</td>
</tr>
<tr>
<td>Also known as</td>
<td>RAM is also known as primary memory.</td>
<td>HDD is also known as secondary memory.</td>
</tr>
<tr>
<td>Components</td>
<td>RAM does not contains, mechanical parts, only electronical parts like transistors.</td>
<td>HDD contains moving mechanical parts, like the arm.</td>
</tr>
<tr>
<td>R/W Time</td>
<td>RAM has shorter R/W time.</td>
<td>HDD has longer R/W time.</td>
</tr>
<tr>
<td>Memory Access</td>
<td>In RAM each and every element takes same time to be accessed.</td>
<td>In HDD different elements take different time to be accessed.</td>
</tr>
<tr>
<td>Size</td>
<td>In a system the RAM is smaller than the HDD.</td>
<td>In a system the HDD is smaller than the RAM.</td>
</tr>
<tr>
<td>Cost</td>
<td>RAM is costlier per unit storage.</td>
<td>HDD is cheaper per unit storage.</td>
</tr>
<tr>
<td>Noise</td>
<td>RAM does not produces noise.</td>
<td>HDD can produce noise due to mechanical movements.</td>
</tr>
<tr>
<td>Duration of Data</td>
<td>Data stored in RAM is temporary. It remembers as long as it has electricity, i.e. the power is on.</td>
<td>Data stored in HDD is permanent, i.e. it retains data even after shutdown.</td>
</tr>
<tr>
<td>Speed of Computer</td>
<td>Inadequate RAM slows down the speed of the computer.</td>
<td>HDD does not affect the speed of the computer.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-270153 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-270153">
<header class="entry-header">
<h1 class="entry-title">Operating System | Privileged and Non-Privileged Instructions</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In any Operating System, it is necessary to have <b></b> to ensure protection and security of the System from unauthorized or errant users . This Dual Mode separates the User Mode from the System Mode or Kernel Mode.</p>
<p><img class="aligncenter size-full " height="290" src="https://media.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-9-1.jpg" width="400"/></p>
<p><strong><u>What are Privileged Instructions?</u></strong></p>
<blockquote><p>The Instructions that can run only in Kernel Mode are called Privileged Instructions .</p></blockquote>
<p>Privileged Instructions possess the following characteristics :</p>
<p>(i) If any attempt is made to execute a Privileged Instruction in User Mode, then it will not be executed and treated as an illegal instruction. The Hardware traps it to the Operating System.</p>
<p>(ii) Before transferring the control to any User Program, it is the responsibility of the Operating System to ensure that the <strong>Timer</strong> is set to interrupt. Thus, if the timer interrupts then the Operating System regains the control.<br/>
Thus, any instruction which can modify the contents of the Timer is a Privileged Instruction.</p>
<p>(iii) Privileged Instructions are used by the Operating System in order to achieve correct operation.</p>
<p>(iv) Various examples of Privileged Instructions include:</p>
<ul>
<li>I/O instructions and Halt instructions</li>
<li>Turn off all Interrupts</li>
<li>Set the Timer</li>
<li>Context Switching</li>
<li>Clear the Memory or Remove a process from the Memory</li>
<li>Modify entries in Device-status table</li>
</ul>
<p><strong><u>What are Non-Privileged Instructions?</u></strong></p>
<blockquote><p>The Instructions that can run only in User Mode are called Non-Privileged Instructions .</p></blockquote>
<p>  Various examples of Non-Privileged Instructions include:</p>
<ul>
<li>Reading the status of Processor</li>
<li>Reading the System Time</li>
<li>Generate any Trap Instruction</li>
<li>Sending the final prinout of Printer</li>
</ul>
<p> Also, it is important to note that in order to change the mode from Privileged to Non-Privileged, we require a Non-privileged Instruction that does not generate any interrupt.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-266318 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems tag-linux-command" id="post-266318">
<header class="entry-header">
<h1 class="entry-title">Implementing Directory Management using Shell Script</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Directory management constitutes the functions dealing with organization and maintenance of various directories. Directories usually contain files of any type, but this may vary between file systems. The content of a directory does not affect the directory object itself.</p>
<p><strong>Some of the directory functions are: </strong></p>
<ul>
<li>Navigation</li>
<li>Absolute/ Relative Pathnames</li>
<li>Listing Directories </li>
<li>Creating Directories </li>
<li>Modifying Directories</li>
</ul>
<p>You can write your script in an editor like <em>pico </em>etc.  Execute your files as mentioned below in the output screenshot. <em>The following shell script implements these functions of directory management, using commands available in Linux.</em></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-260257 post type-post status-publish format-standard hentry category-computer-organization-architecture category-difference-between category-operating-systems category-technical-scripter tag-operating-systems-memory-management" id="post-260257">
<header class="entry-header">
<h1 class="entry-title">Logical vs Physical Address in Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Logical Address</strong> is generated by CPU while a program is running. The logical address is virtual address as it does not exist physically, therefore, it is also known as Virtual Address. This address is used as a reference to access the physical memory location by CPU. The term Logical Address Space is used for the set of all logical addresses generated by a program’s perspective.<br/>
The hardware device called Memory-Management Unit is used for mapping logical address to its corresponding physical address. </p>
<p>
<strong>Physical Address</strong> identifies a physical location of required data in a memory. The user never directly deals with the physical address but can access by its corresponding logical address. The user program generates the logical address and thinks that the program is running in this logical address but the program needs physical memory for its execution, therefore, the logical address must be mapped to the physical address by MMU before they are used. The term Physical Address Space is used for all physical addresses corresponding to the logical addresses in a Logical address space.<br/>
<br/>
<img alt="MMU scheme" src="https://media.geeksforgeeks.org/wp-content/uploads/operating_system.png"><br/>
<br/>
<strong>Differences Between Logical and Physical Address in Operating System</strong></img></p>
<ol>
<li>The basic difference between Logical and physical address is that Logical address is generated by CPU in perspective of a program whereas the physical address is a location that exists in the memory unit.</li>
<li>Logical Address Space is the set of all logical addresses generated by CPU for a program whereas the set of all physical address mapped to corresponding logical addresses is called Physical Address Space.</li>
<li>The logical address does not exist physically in the memory whereas physical address is a location in the memory that can be accessed physically.</li>
<li>Identical logical addresses are generated by Compile-time and Load time address binding methods whereas they differs from each other in run-time address binding method. Please refer <a href="https://www.geeksforgeeks.org/memory-management-mapping-virtual-address-physical-addresses/">this</a> for details.</li>
<li>The logical address is generated by the CPU while the program is running whereas the physical address is computed by the Memory Management Unit (MMU).</li>
</ol>
<p><strong>Comparison Chart:</strong></p>
<table style="width:90%">
<thead>
<tr>
<th>Paramenter</th>
<th>LOGICAL ADDRESS </th>
<th>PHYSICAL ADDRESS </th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic </td>
<td>generated by CPU</td>
<td>location in a memory unit  </td>
</tr>
<tr>
<td>Address Space </td>
<td>Logical Address Space is set of all logical addresses generated by CPU in reference to a program. </td>
<td>Physical Address is set of all physical addresses mapped to the corresponding logical addresses. </td>
</tr>
<tr>
<td>Visibility</td>
<td>User can view the logical address of a program. </td>
<td>User can never view physical address of program. </td>
</tr>
<tr>
<td>Generation</td>
<td>generated by the CPU </td>
<td>Computed by MMU </td>
</tr>
<tr>
<td>Access</td>
<td>The user can use the logical address to access the physical address.</td>
<td>The user can indirectly access physical address but not directly. </td>
</tr>
</tbody>
</table>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-258561 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems tag-operating-systems-memory-management" id="post-258561">
<header class="entry-header">
<h1 class="entry-title">Operating System | Memory Interleaving</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
Abstraction is one the most important aspect of computing. It is widely implemented Practice in the Computational field. </p>
<p><b>Memory Interleaving</b> is less or More an Abstraction technique. Though its a bit different from Abstraction. It is a Technique which divides memory into a number of modules such that Successive words in the address space are placed in the Different module.</p>
<p><strong>Consecutive Word in a Module:</strong></p>
<p><img alt="" class="aligncenter size-full wp-image-778551" height="500" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/raw-1.png" width="700"><br/>
<center><b>Figure-1:</b> Consecutive Word in a Module </center><br/>
</img></p></div></article><hr style="border: 2px dashed black;" /><article class="post-255385 post type-post status-publish format-standard hentry category-c-programs category-operating-systems tag-system-programming tag-technical-scripter-2018" id="post-255385">
<header class="entry-header">
<h1 class="entry-title">Get/Set process resource limits in C</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The <strong>getrlimit()</strong> and <strong>setrlimit()</strong> system calls can be used to get and set the resource limits such as files, CPU, memory etc. associated with a process.</p>
<blockquote><p>
Each resource has an associated <strong>soft and hard limit.</strong></p>
<ul>
<li> <strong><em>soft limit</em>:</strong> The soft limit is the actual limit enforced by the kernel for the corresponding resource.</li>
<li> <strong><em>hard limit</em>:</strong> The hard limit acts as a ceiling for the soft limit. </li>
</ul>
<p><strong>The soft limit ranges in between 0 and hard limit.</strong>
</p></blockquote>
<p>The two limits are defined by the following structure</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-255636 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems" id="post-255636">
<header class="entry-header">
<h1 class="entry-title">Memory Hierarchy Design and its Characteristics</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In the Computer System Design, Memory Hierarchy is an enhancement to organize the memory such that it can minimize the access time. The Memory Hierarchy was developed based on a program behavior known as locality of references.The figure below clearly demonstrates the different levels of memory hierarchy :</p>
<p><img class="aligncenter size-full" height="500" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-4-4.png" width="800"/></p>
<p>This Memory Hierarchy Design is divided into 2 main types:</p>
<ol>
<li><strong>External Memory or Secondary Memory –</strong><br/>
Comprising of Magnetic Disk, Optical Disk, Magnetic Tape i.e. peripheral storage devices which are accessible by the processor via I/O Module.
</li>
<li><strong>Internal Memory or Primary Memory –</strong><br/>
Comprising of Main Memory, Cache Memory &amp; CPU registers. This is directly accessible by the processor.
</li>
</ol>
<p>We can infer the following characteristics of Memory Hierarchy Design from above figure:</p>
<ol>
<li><strong>Capacity:</strong><br/>
It is the global volume of information the memory can store. As we move from top to bottom in the Hierarchy, the capacity increases.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-253534 post type-post status-publish format-standard hentry category-operating-systems tag-os-deadlocks tag-operating-systems-deadlock tag-os-process-synchronization" id="post-253534">
<header class="entry-header">
<h1 class="entry-title">Deadlock, Starvation, and Livelock</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Livelock</b> occurs when two or more processes continually repeat the same interaction in response to changes in the other processes without doing any useful work. These processes are not in the waiting state, and they are running concurrently. This is different from a deadlock because in a deadlock all processes are in the waiting state.</p>
<p><img class="aligncenter size-full" height="300" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/aaa-1.png" width="400"/></p>
<p><b>Example:</b><br/>
Imagine a pair of processes using two resources, as shown:</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-253312 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-picked" id="post-253312">
<header class="entry-header">
<h1 class="entry-title">Functions of Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
An <b>Operating System</b> acts as a communication bridge (interface) between the user and computer hardware. The purpose of an operating system is to provide a platform on which a user can execute programs in a convenient and efficient manner.</p>
<p>An operating system is a piece of software that manages the allocation of computer hardware. The coordination of the hardware must be appropriate to ensure the correct working of the computer system and to prevent user programs from interfering with the proper working of the system.</p>
<p><strong>What is Operating System ?</strong><br/>
An operating system is a program on which application programs are executed and acts as an communication bridge (interface) between the user and the computer hardware.</p>
<p>The main task an operating system carries out is the allocation of resources and services, such as allocation of: memory, devices, processors and information. The operating system also includes programs to manage these resources, such as a traffic controller, a scheduler, memory management module, I/O programs, and a file system.</p>
<p><strong>Important functions of an operating System:</strong></p>
<ol>
<li><strong>Security –</strong><br/>
The operating system uses password protection to protect user data and similar other techniques. it also prevents unauthorized access to programs and user data.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-253218 post type-post status-publish format-standard hentry category-operating-systems tag-operating-systems-memory-management" id="post-253218">
<header class="entry-header">
<h1 class="entry-title">Program for buddy memory allocation scheme in Operating Systems | Set 2 (Deallocation)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <a href="https://www.geeksforgeeks.org/program-for-buddy-memory-allocation-scheme-in-operating-systems-set-1-allocation/" target="blank">Buddy Allocation | Set 1</a><br/>
<b>Question:</b> Write a program to implement the buddy system of memory allocation and deallocation in Operating Systems.</p>
<p><b>Explanation –</b><br/>
As we already know from Set 1, the allocation is done via the usage of free lists. Now, for deallocation, we will maintain an extra data structure-a Map (unordered_set in C++, HashMap in Java) with the starting address of segment as key and size of the segment as value and update it whenever an allocation request comes. Now, when deallocation request comes, we will first check the map to see if it is a valid request. If so, we will then add the block to the free list tracking blocks of its sizes. Then, we will search the free list to see if it’s <i>buddy</i> is free-if so, we will merge the blocks and place them on the free list above them (which tracks blocks of double the size), else we will not coalesce and simply return after that.</p></div></article><hr style="border: 2px dashed black;" /><article class="post-252228 post type-post status-publish format-standard hentry category-operating-systems tag-operating-systems-memory-management" id="post-252228">
<header class="entry-header">
<h1 class="entry-title">Program for buddy memory allocation scheme in Operating Systems | Set 1 (Allocation)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Question:</b> Write a program to implement the buddy system of memory allocation in Operating Systems.</p>
<p><b>Explanation –</b><br/>
The buddy system is implemented as follows- A list of free nodes, of all the different possible powers of 2, is maintained at all times (So if total memory size is 1 MB, we’d have 20 free lists to track-one for blocks of size 1 byte, 1 for 2 bytes, next for 4 bytes and so on). </p>
<p>When a request for allocation comes, we look for the smallest block bigger than it. If such a block is found on the free list, the allocation is done (say, the request is of 27 KB and the free list tracking 32 KB blocks has at least one element in it), else we traverse the free list <i>upwards</i> till we find a big enough block. Then we keep splitting it in two blocks-one for adding to the next free list (of smaller size), one to traverse <i>down</i> the tree till we reach the target and return the requested memory block to the user. If no such allocation is possible, we simply return null.</p>
<p><strong>Example:</strong><br/>
Let us see how the algorithm proceeds by tracking a memory block of size 128 KB. Initially, the free list is: {}, {}, {}, {}, {}, {}, {}, { (0, 127) }</p>
<ul>
<li><b>Request:</b> 32 bytes<br/>
No such block found, so we traverse up and split the 0-127 block into 0-63, 634-127; we add 64-127 to list tracking 64 byte blocks and pass 0-63 downwards; again it is split into 0-31 and 32-63; since we have found the required block size, we add 32-63 to list tracking 32 byte blocks and return 0-31 to user.<br/>
List is: {}, {}, {}, {}, {}, { (32, 63) }, { (64, 127) }, {}
</li>
<li><b>Request:</b> 7 bytes<br/>
No such block found-split block 32-63 into two blocks, namely 32-47 and 48-63; then split 32-47 into 32-39 and 40-47; finally, return 32-39 to user (internal fragmentation of 1 byte occurs)<br/>
List is: {}, {}, {}, { (40, 47) }, { (48, 63) }, {}, { (64, 127) }, {}</li>
<li><b>Request:</b> 64 bytes<br/>
Straight up memory segment 64-127 will be allocated as it already exists.<br/>
List is: {}, {}, {}, { (40, 47) }, { (48, 63) }, {}, {}, {}</li>
<li>Request: 56 bytes<br/>
Result: Not allocated</li>
</ul>
<p>The result will be as follows:</p>
<p><img class="aligncenter size-full" height="479" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/GFG-20.png" width="1071"><br/>
<b>Figure –</b> Buddy Allocation-128 shows the starting address of next possible block (if main memory size ever increases)</img></p>
<p><b>Implementation –</b></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-250696 post type-post status-publish format-standard hentry category-operating-systems tag-operating-systems-memory-management" id="post-250696">
<header class="entry-header">
<h1 class="entry-title">Operating System | Second Chance (or Clock) Page Replacement Policy</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
Apart from LRU, OPT and FIFO page replacement policies, we also have the second chance/clock page replacement policy. In the Second Chance page replacement policy, the candidate pages for removal are considered in a round robin matter, and a page that has been accessed between consecutive considerations will not be replaced. The page replaced is the one that, when considered in a round robin matter, has not been accessed since its last consideration. </p>
<p>It can be implemented by adding a “second chance” bit to each memory frame-every time the frame is considered (due to a reference made to the page inside it), this bit is set to 1, which gives the page a second chance, as when we consider the candidate page for replacement, we replace the first one with this bit set to 0 (while zeroing out bits of the other pages we see in the process). Thus, a page with the “second chance” bit set to 1 is never replaced during the first consideration and will only be replaced if all the other pages deserve a second chance too!</p>
<p><b>Example –</b><br/>
Let’s say the reference string is <b>0 4 1 4 2 4 3 4 2 4 0 4 1 4 2 4 3 4</b> and we have <b>3</b> frames. Let’s see how the algorithm proceeds by tracking the second chance bit and the pointer.</p>
<ul>
<li>Initially, all frames are empty so after first 3 passes they will be filled with  {0, 4, 1} and the second chance array will be {0, 0, 0} as none has been referenced yet. Also, the pointer will cycle back to 0.
</li>
<li><b>Pass-4:</b> Frame={0, 4, 1}, second_chance = {0, 1, 0} [4 will get a second chance], pointer = 0 (No page needed to be updated so the candidate is still page in frame 0), pf = 3 (No increase in page fault number).
</li>
<li><b>Pass-5:</b> Frame={2, 4, 1}, second_chance= {0, 1, 0} [0 replaced; it’s second chance bit was 0, so it didn’t get a second chance], pointer=1 (updated), pf=4
</li>
<li><b>Pass-6:</b> Frame={2, 4, 1}, second_chance={0, 1, 0}, pointer=1, pf=4 (No change)
</li>
<li><b>Pass-7:</b> Frame={2, 4, 3}, second_chance= {0, 0, 0} [4 survived but it’s second chance bit became 0], pointer=0 (as element at index 2 was finally replaced), pf=5
</li>
<li><b>Pass-8:</b> Frame={2, 4, 3}, second_chance= {0, 1, 0} [4 referenced again], pointer=0, pf=5
</li>
<li><b>Pass-9:</b> Frame={2, 4, 3}, second_chance= {1, 1, 0} [2 referenced again], pointer=0, pf=5
</li>
<li><b>Pass-10:</b> Frame={2, 4, 3}, second_chance= {1, 1, 0}, pointer=0, pf=5 (no change)
</li>
<li><b>Pass-11:</b> Frame={2, 4, 0}, second_chance= {0, 0, 0}, pointer=0, pf=6 (2 and 4 got second chances)
</li>
<li><b>Pass-12:</b> Frame={2, 4, 0}, second_chance= {0, 1, 0}, pointer=0, pf=6 (4 will again get a second chance)
</li>
<li><b>Pass-13:</b> Frame={1, 4, 0}, second_chance= {0, 1, 0}, pointer=1, pf=7 (pointer updated, pf updated)
</li>
<li><b>Page-14:</b> Frame={1, 4, 0}, second_chance= {0, 1, 0}, pointer=1, pf=7 (No change)
</li>
<li><b>Page-15:</b> Frame={1, 4, 2}, second_chance= {0, 0, 0}, pointer=0, pf=8 (4 survived again due to 2nd chance!)
</li>
<li><b>Page-16:</b> Frame={1, 4, 2}, second_chance= {0, 1, 0}, pointer=0, pf=8 (2nd chance updated)
</li>
<li><b>Page-17:</b> Frame={3, 4, 2}, second_chance= {0, 1, 0}, pointer=1, pf=9 (pointer, pf updated)
</li>
<li><b>Page-18:</b> Frame={3, 4, 2}, second_chance= {0, 1, 0}, pointer=1, pf=9 (No change)
</li>
</ul>
<p>In this example, second chance algorithm does as well as the LRU method, which is much more expensive to implement in hardware.</p>
<p><strong>More Examples –</strong></p>
<pre><strong>Input:</strong> 2 5 10 1 2 2 6 9 1 2 10 2 6 1 2 1 6 9 5 1

3

<strong>Output:</strong> 13



<strong>Input:</strong> 2 5 10 1 2 2 6 9 1 2 10 2 6 1 2 1 6 9 5 1

4

<strong>Output:</strong> 11 </pre>
<p><b>Algorithm –</b><br/>
Create an array <b>frames</b> to track the pages currently in memory and another Boolean array <b>second_chance</b> to track whether that page has been accessed since it’s last replacement (that is if it deserves a second chance or not) and a variable <b>pointer</b> to track the target for replacement.</p>
<ol>
<li>Start traversing the array <b>arr</b>. If the page already exists, simply set its corresponding element in <b>second_chance</b> to true and return.
</li>
<li>If the page doesn’t exist, check whether the space pointed to by <b>pointer</b> is empty (indicating cache isn’t full yet) – if so, we will put the element there and return, else we’ll traverse the array <b>arr</b> one by one (cyclically using the value of <b>pointer</b>), marking all corresponding <b>second_chance</b> elements as false, till we find a one that’s already false. That is the most suitable page for replacement, so we do so and return.
</li>
<li>Finally, we report the page fault count.
</li>
</ol>
<p><img class="aligncenter size-full" height="444" src="https://media.geeksforgeeks.org/wp-content/uploads/GFG-3.jpg" width="956"><br/>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
</div></div></img></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-249710 post type-post status-publish format-standard hentry category-gate-cs category-greedy category-operating-systems category-technical-scripter tag-operating-systems-cpu-scheduling" id="post-249710">
<header class="entry-header">
<h1 class="entry-title">CPU Scheduling | Longest Remaining Time First (LRTF) Program</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
We have given some process with arrival time and Burst Time and we have to find the completion time (CT), Turn Around Time(TAT), Average Turn Around Time (Avg TAT), Waiting Time(WT), Average Waiting Time (AWT) for the given processes.</p>
<p><b>Example:</b> Consider the following table of arrival time and burst time for four processes P1, P2, P3 and P4. </p>
<pre>Process   Arrival time   Burst Time

P1            1 ms          2 ms

P2            2 ms          4 ms

P3            3 ms          6 ms

p4            4 ms          8 ms  </pre>
<p>Gantt chart will be as following below,</p>
<p><img class="aligncenter size-full" height="108" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/GANT.png" width="844"/></p>
<p>Since, complietion time (CT) can be directly determined by Gantt chart, and</p>
<pre>Turn Around Time (TAT)

= (Complition Time) - (Arival Time)



Also, Waiting Time (WT)

= (Turn Around Time) - (Burst Time) </pre>
<p>Therefore,</p>
<p><b>Output:</b></p>
<pre>Total Turn Around Time = 68 ms

So, Average Turn Around Time = 68/4 = 17.00 ms



And, Total Waiting Time = 48 ms

So, Average Waiting Time = 12.00 ms </pre>
<p><strong>Algorithm –</strong></p>
<ul>
<li><b>Step-1:</b> Create a structure of process containing all necessary fields like AT (Arrival Time), BT(Burst Time), CT(Completion Time), TAT(Turn Around Time), WT(Waiting Time).
</li>
<li><b>Step-2:</b> Sort according to the AT;
</li>
<li><b>Step-3:</b> Find the process having Largest Burst Time and execute for each single unit. Increase the total time by 1 and reduce the Burst Time of that process with 1.
</li>
<li><b>Step-4:</b> When any  process have 0 BT left, then update the CT(Completion Time of that process CT will be  Total Time at that time).
</li>
<li><b>Step-2:</b> After calculating the CT for each process, find TAT and WT.
<pre>(TAT = CT - AT) 

(WT  = TAT - BT) </pre>
</li>
</ul>
<p><b>Implementation of Algorithm –</b><br/>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
</div></div></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-249410 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems category-technical-scripter tag-operating-systems-cpu-scheduling" id="post-249410">
<header class="entry-header">
<h1 class="entry-title">CPU Scheduling | Longest Remaining Time First (LRTF) algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
This is a pre-emptive  version of Longest Job First (LJF) scheduling algorithm. In this scheduling algorithm, we find the process with maximum remaining time and then process it. We check for the maximum remaining time after some interval of time(say 1 unit each) to check if another process having more Burst Time arrived up to that time.</p>
<p><b>Procedure:</b></p>
<ul>
<li><b>Step-1:</b> First, sort the processes in increasing order of their Arrival Time.
</li>
<li><b>Step-2:</b> Choose the process having least arrival time but with most Burst Time. Then process it for 1 unit. Check if any other process arrives upto that time of execution or not.
</li>
<li><b>Step-3:</b> Repeat the above both steps until execute all the processes.
</li>
</ul>
<p><b>Example-1:</b> Consider the following table of arrival time and burst time for four processes P1, P2, P3 and P4. </p>
<pre>Process   Arrival time   Burst Time

P1            1 ms          2 ms

P2            2 ms          4 ms

P3            3 ms          6 ms

P4            4 ms          8 ms  </pre>
<p><strong>Working: (for input 1):</strong></p>
<ol>
<li>At t = 1, Available Process : P1. So, select P1 and execute 1 ms.
</li>
<li>At t = 2, Available Process : P1, P2. So, select P2 and execute 1 ms (since BT(P1)=1 which is less than BT(P2) = 4)
</li>
<li>At t = 3, Available Process : P1, P2, P3. So, select P3 and execute 1 ms (since, BT(P1) = 1 , BT(P2) = 3 , BT(P3) = 6).
</li>
<li>Repeat the above steps until the execution of all processes.
</li>
</ol>
<p><b>Note</b> that CPU will be idle for 0 to 1 unit time, since there is no process available in given interval.</p>
<p>Gantt chart will be as following below,</p>
<p><img alt="" class="aligncenter size-full wp-image-719290" height="51" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/88888888.png" width="646"/></p>
<p>Since, complietion time (CT) can be directly determined by Gantt chart, and </p>
<pre>Turn Around Time (TAT)

= (Complition Time) - (Arival Time)



Also, Waiting Time (WT)

= (Turn Around Time) - (Burst Time) </pre>
<p>Therefore, final table look like,</p>
<p><img alt="" class="aligncenter size-full wp-image-719305" height="144" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/222223333.png" width="627"> </img></p>
<p><strong>Output:</strong></p>
<pre>Total Turn Around Time = 68 ms

So, Average Turn Around Time = 68/4 = 17.00 ms



And, Total Waiting Time = 48 ms

So Average Waiting Time = 48/4 = 12.00 ms </pre>
<p></p>
<p><b>Example-2:</b> Consider the following table of arrival time and burst time for four processes P1, P2, P3,P4 and P5. </p>
<pre>Process   Arrival time   Burst Time

P1            0 ms          2 ms

P2            0 ms          3 ms

P3            2 ms          2 ms

P4            3 ms          5 ms 

P5            4 ms          4 ms </pre>
<p>Similarly example-1, Gantt chart for this example,</p>
<p><img class="aligncenter size-full" height="108" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/GANT-3.png" width="675"/></p>
<p>Since, complietion time (CT) can be directly determined by Gantt chart, and </p>
<pre>Turn Around Time (TAT)

= (Complition Time) - (Arival Time)



Also, Waiting Time (WT)

= (Turn Around Time) - (Burst Time) </pre>
<p>Therefore, final table look like,</p>
<p><img class="aligncenter size-full" height="189" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/PRO2.png" width="311"/></p>
<p><strong>Output:</strong></p>
<pre>Total Turn Around Time = 61 ms

So, Average Turn Around Time = 61/5 = 12.20 ms



And, Total Waiting Time = 45 ms

So, Average Waiting Time = 45/5 = 9.00 ms </pre>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-242740 post type-post status-publish format-standard hentry category-operating-systems" id="post-242740">
<header class="entry-header">
<h1 class="entry-title">Operating System | Boot Block</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Basically for a computer to start running to get an instance when it is powered up or rebooted it need to have an initial program to run. And this initial program which is known as <b>bootstrap</b> need to be simple. It must initialize all aspects of the system, from CPU registers to device controllers and the contents of the main memory and then starts the operating system.</p>
<p>To do this job the bootstrap program basically finds the operating system kernel on disk and then loads the kernel into memory and after this, it jumps to the initial address to begin the operating-system execution.</p>
<p><b>Why ROM:</b><br/>
For most of today’s computer bootstrap is stored in Read Only Memory (ROM). </p>
<ol>
<li>This location is good for storage because this place doesn’t require initialization and moreover location here it is fixed so that processor can start executing when powered up or reset.
</li>
<li>ROM is basically read-only memory and hence it cannot be affected by the computer virus.
</li>
</ol>
<p>The problem is that changing the bootstrap code basically requires changes in the ROM hardware chips.Because of this reason, most system nowadays has the tiny bootstrap loader program in the boot whose only job is to bring the full bootstrap program from the disk. Through this now we are able to change the full bootstrap program easily and the new version can be easily written onto the disk.</p>
<p>Full bootstrap program is stored in the <b>boot blocks</b> at a fixed location on the disk. A disk which has a boot partition is called a boot disk. The code in the boot ROM basically instructs the read controller to read the boot blocks into the memory and then starts the execution of code. The full bootstrap program is more complex than the bootstrap loader in the boot ROM, It is basically able to load the complete OS from a non-fixed location on disk to start the operating system running. Even though the complete bootstrap program is very small.</p>
<p><b>Example:</b><br/>
Let us try to understand this using an example of the boot process in Windows 2000.</p>
<p>The Windows 2000 basically stores its boot code in the first sector on the hard disk. Moreover, Windows 2000 allows the hard disk to be divided into one or more partition. In this one partition is basically identified as the boot partition which basically contains the operating system and the device drivers.</p>
<p>Booting in Windows 2000 starts by running the code that is placed in the system’s ROM memory. This code basically directs the system to read code directly from MBR. In addition to this boot code also contain the table which lists the partition for the hard disk and also a flag which basically indicates which partition is to be boot from the system. Once the system identifies the boot partition it reads the first sector from the memory which is basically known as boot sector and continue the process with the remainder of the boot process which basically includes loading of various system services.</p>
<p>The following figure shows the Booting from disk in Windows 2000.</p>
<p><img alt="" class="aligncenter size-full wp-image-688850" height="201" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/111-14.png" width="429"/></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-242731 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems category-technical-scripter tag-operating-systems-cpu-scheduling" id="post-242731">
<header class="entry-header">
<h1 class="entry-title">Preemptive and Non-Preemptive Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<strong>1. Preemptive Scheduling:</strong><br/>
Preemptive scheduling is used when a process switches from running state to ready state or from waiting state to ready state. The resources (mainly CPU cycles) are allocated to the process for the limited amount of time and then is taken away, and the process is again placed back in the ready queue if that process still has CPU burst time remaining. That process stays in ready queue till it gets next chance to execute. </p>
<p>Algorithms based on preemptive scheduling are: , and , etc.</p>
<p><img class="aligncenter size-full" height="324" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/pre-2.png" width="423"/></p>
<p><strong>2. Non-Preemptive Scheduling:</strong><br/>
Non-preemptive Scheduling is used when a process terminates, or a process switches from running to waiting state. In this scheduling, once the resources (CPU cycles) is allocated to a process, the process holds the CPU till it gets terminated or it reaches a waiting state. In case of non-preemptive scheduling does not interrupt a process running CPU in middle of the execution. Instead, it waits till the process complete its CPU burst time and then it can allocate the CPU to another process. </p>
<p>Algorithms based on preemptive scheduling are: , , etc.</p>
<p><img class="aligncenter size-full" height="323" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/nonpre.png" width="404"/></p>
<p><strong>Key Differences Between Preemptive and Non-Preemptive Scheduling:</strong></p>
<ol>
<li>In preemptive scheduling the CPU is allocated to the processes for the limited time whereas in Non-preemptive scheduling, the CPU is allocated to the process till it terminates or switches to waiting state.
</li>
<p></p>
<li>The executing process in preemptive scheduling is interrupted in the middle of execution when higher priority one comes whereas, the executing process in non-preemptive scheduling is not interrupted in the middle of execution and wait till its execution.
</li>
<p></p>
<li>In Preemptive Scheduling, there is the overhead of switching the process from ready state to running state, vise-verse, and maintaining the ready queue. Whereas in case of non-preemptive scheduling has no overhead of switching the process from running state to ready state.
</li>
<p></p>
<li>In preemptive scheduling, if a high priority process frequently arrives in the ready queue then the process with low priority has to wait for a long, and it may have to starve. On the other hands, in the non-preemptive scheduling, if CPU is allocated to the process having larger burst time then the processes with small burst time may have to starve.
</li>
<p></p>
<li>Preemptive scheduling attain flexible by allowing the critical processes to access CPU as they arrive into the ready queue, no matter what process is executing currently. Non-preemptive scheduling is called rigid as even if a critical process enters the ready queue the process running CPU is not disturbed.
</li>
<p></p>
<li>The Preemptive Scheduling has to maintain the integrity of shared data that’s why it is cost associative as it which is not the case with Non-preemptive Scheduling.</li>
</ol>
<p><strong>Comparison Chart:</strong></p>
<p><center></center></p>
<table style="width:90%">
<thead>
<tr>
<th>Paramenter</th>
<th>PREEMPTIVE SCHEDULING </th>
<th>NON-PREEMPTIVE SCHEDULING </th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic </td>
<td>In this resources(CPU Cycle)  are allocated to a process for a limited time. </td>
<td>Once resources(CPU Cycle) are allocated to a process, the process holds it till it completes its burst time or switches to waiting state.  </td>
</tr>
<tr>
<td>Interrupt </td>
<td>Process can be interrupted in between. </td>
<td>Process can not be interrupted untill it terminates itself or its time is up. </td>
</tr>
<tr>
<td>Starvation </td>
<td>If a process having high priority frequently arrives in the ready queue, low priority process may  starve. </td>
<td>If a process with long burst time is running CPU, then later coming process with less CPU burst time may starve. </td>
</tr>
<tr>
<td>Overhead </td>
<td>It has overheads of scheduling the processes. </td>
<td>It does not have overheads. </td>
</tr>
<tr>
<td>Flexibility </td>
<td>flexible </td>
<td>rigid </td>
</tr>
<tr>
<td>Cost </td>
<td>cost associated </td>
<td>no cost associated </td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-242109 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-242109">
<header class="entry-header">
<h1 class="entry-title">Operating System | Kernel I/O Subsystem (I/O System)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
The kernel provides many services related to I/O. Several services such as scheduling, caching, spooling, device reservation, and error handling – are provided by the kernel, s I/O subsystem built on the hardware and device-driver infrastructure. The I/O subsystem is also responsible for protecting itself from the errant processes and malicious users.</p>
<ol>
<li><b>I/O Scheduling –</b><br/>
To schedule a set of I/O request means to determine a good order in which to execute them. The order in which application issues the system call are the best choice. Scheduling can improve the overall performance of the system, can share device access permission fairly to all the processes, reduce the average waiting time, response time, turnaround time for I/O to complete.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-239720 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-operating-systems-input-output-systems" id="post-239720">
<header class="entry-header">
<h1 class="entry-title">Operating System | File Access Methods</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
When a file is used, information is read and accessed into computer memory and there are several ways to access this information of the file. Some systems provide only one access method for files. Other systems, such as those of IBM, support many access methods, and choosing the right one for a particular application is a major design problem.</p>
<p>There are three ways to access a file into a computer system: Sequential-Access, Direct Access, Index sequential Method.</p>
<ol>
<li><strong>Sequential Access –</strong><br/>
It is the simplest access method. Information in the file is processed in order, one record after the other. This mode of access is by far the most common; for example, editor and compiler usually access the file in this fashion.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-240527 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-operating-systems-input-output-systems" id="post-240527">
<header class="entry-header">
<h1 class="entry-title">Operating System | Structures of Directory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A <b>directory</b> is a container that is used to contain folders and file. It organises files and folders into hierarchical manner.</p>
<p><img alt="" class="aligncenter size-full wp-image-669398" height="341" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/111-11.png" width="756"/></p>
<p>There are several logical structures of directory, these are given as below.</p>
<ol>
<li><strong>Single-level directory –</strong><br/>
Single level directory is simplest disectory structure.In it all files are contained in same directory which make it easy to support and understand.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-239624 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-239624">
<header class="entry-header">
<h1 class="entry-title">Non-Contiguous Allocation in Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
 and  are the two ways which allow a process’s physical address space to be non-contiguous. It has <b>advantage</b> of reducing memory wastage but it increases the overheads due to address translation. It slows the execution of the memory because time is consumed in address translation.</p>
<p>In non-contiguous allocation, Operating system needs to maintain the table which is called <strong> Page Table</strong> for each process which contains the base address of the each block which is acquired by the process in memory space. In non-contiguous memory allocation, different parts of a process is allocated different places in Main Memory. Spanning is allowed which is not possible in other techniques like Dynamic or Static Contiguous memory allocation. That’s why paging is needed to ensure effective memory allocation. Paging is done to remove External Fragmentation. </p>
<p><strong>Working:</strong><br/>
Here a process can be spanned across different spaces in main memory in non-consecutive manner. Suppose process P of size 4KB. Consider main memory have two empty slots each of size 2KB. Hence total free space is, 2*2= 4 KB. In contiguous memory allocation, process P cannot be accommodated as spanning is not allowed. </p>
<p>In contiguous allocation, space in memory should be allocated to whole process. If not, then that space remains unallocated. But in Non-Contiguous allocation, process can be divided into different parts and hence filling the space in main memory. In this example, process P can be divided into two parts of equal size – 2KB. Hence one part of process P can be allocated to first 2KB space of main memory and other part of processP can be allocated to second 2KB space of main memory. Below diagram will explain in better way:</p>
<p><img alt="" class="aligncenter size-full wp-image-664623" height="373" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/1-353.png" width="377"/></p>
<p>But, in what manner we divide a process to allocate them into main memory is very important to understand. Process is divided after analysing the number of empty spaces and their size in main memory. Then only we divide our process. It is very time consuming process. Their number as well as their sizes changing every time due to execution of already present processes in main memory. </p>
<p>In order to avoid this time consuming process, we divide our process in secondary memory in advance before reaching the memory memory for its execution. Every process is divided into various parts of equal size called Pages. We also divide our main memory into different parts of equal size called Frames. It is important to understand that:</p>
<pre>Size of page in process 

= Size of frame in memory </pre>
<p>Although their numbers can be different. Below diagram will make you understand in better way: consider empty main memory having size of each frame is 2 KB, and two processes P1 and P2 are 2 KB each.</p>
<p><img alt="" class="aligncenter size-full wp-image-664628" height="412" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/1-1-1.png" width="461"/></p>
<p>Resolvent main memory,</p>
<p><img alt="" class="aligncenter size-full wp-image-664630" height="370" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/2222-6.png" width="308"/></p>
<p>In conclusion we can say that, Paging allows memory address space of a process to be non-contiguous. Paging is more flexible as only pages of a process are moved. It allows more processes to reside in main memory than Contiguous memory allocation.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-236056 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-operating-systems-input-output-systems" id="post-236056">
<header class="entry-header">
<h1 class="entry-title">Variable (or dynamic) Partitioning in Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In operating systems, Memory Management is the function responsible for allocating and managing computer’s main memory. Memory Management function keeps track of the status of each memory location, either allocated or free to ensure effective and efficient use of Primary Memory.</p>
<p>There are two Memory Management Techniques: <b>Contiguous</b>, and <b>Non-Contiguous</b>. In Contiguous Technique, executing process must be loaded entirely in main-memory. Contiguous Technique can be divided into:</p>
<ol>
<li>
</li>
<li>Variable (or dynamic) partitioning
</li>
</ol>
<p><strong>Variable Partitioning –</strong><br/>
It is a part of Contiguous allocation technique. It is used to alleviate the problem faced by Fixed Partitioning. In contrast with fixed partitioning, partitions are not made before the execution or during system configure. Various <strong>features</strong> associated with variable Partitioning- </p>
<ol>
<li>Initially RAM is empty and partitions are made during the run-time according to process’s need instead of partitioning during system configure.
</li>
<p></p>
<li>The size of partition will be equal to incoming process.
</li>
<p></p>
<li>The partition size varies according to the need of the process so that the internal fragmentation can be avoided to ensure efficient utilisation of RAM.
</li>
<p></p>
<li>Number of partitions in RAM is not fixed and depends on the number of incoming process and Main Memory’s size.
</li>
</ol>
<p><img alt="" class="aligncenter size-full wp-image-640886" height="389" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/111-10.png" width="263"/></p>
<p>There are some advantages and disadvantages of variable partitioning over fixed partitioning as given below.</p>
<p><strong>Advantages of Variable Partitioning –</strong></p>
<ol>
<li><strong>No Internal Fragmentation:</strong><br/>
In variable Partitioning, space in main memory is allocated strictly according to the need of process, hence there is no case of internal fragmentation. There will be no unused space left in the partition.
</li>
<p></p>
<li><strong>No restriction on Degree of Multiprogramming:</strong><br/>
More number of processes can be accommodated due to absence of internal fragmentation. A process can be loaded until the memory is not empty.
</li>
<p></p>
<li><strong>No Limitation on the size of the process:</strong><br/>
In Fixed partitioning, the process with the size greater than the size of the largest partition could not be loaded and process can not be divided as it is invalid in contiguous allocation technique. Here, In variable partitioning, the process size can’t be restricted since the partition size is decided according to the process size.
</li>
</ol>
<p><strong>Disadvantages of Variable Partitioning –</strong></p>
<ol>
<li><strong>Difficult Implementation:</strong><br/>
Implementing variable Partitioning is difficult as compared to Fixed Partitioning as it involves allocation of memory during run-time rather than during system configure.
</li>
<p></p>
<li><strong>External Fragmentation:</strong><br/>
There will be external fragmentation inspite of absence of internal fragmentation. </li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-235990 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-operating-systems-input-output-systems" id="post-235990">
<header class="entry-header">
<h1 class="entry-title">Fixed (or static) Partitioning in Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In operating systems, Memory Management is the function responsible for allocating and managing computer’s main memory. Memory Management function keeps track of the status of each memory location, either allocated or free to ensure effective and efficient use of Primary Memory. </p>
<p>There are two Memory Management Techniques: <b>Contiguous</b>, and <b>Non-Contiguous</b>. In Contiguous Technique, executing process must be loaded entirely in main-memory. Contiguous Technique can be divided into:</p>
<ol>
<li>Fixed (or static) partitioning
</li>
<li>Variable (or dynamic) partitioning
</li>
</ol>
<p><strong>Fixed Partitioning:</strong><br/>
This is the oldest and simplest technique used to put more than one processes in the main memory. In this partitioning, number of partitions (non-overlapping) in RAM are <b>fixed but size</b> of each partition may or <b>may not be same</b>. As it is <b>contiguous</b> allocation, hence no spanning is allowed. Here partition are made before execution or during system configure.</p>
<p><img alt="" class="aligncenter size-full wp-image-639999" height="365" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/444-4.png" width="404"/></p>
<p>As illustrated in above figure, first process is only consuming 1MB out of 4MB in the main memory.<br/>
Hence, Internal Fragmentation in first block is (4-1) = 3MB.<br/>
Sum of Internal Fragmentation in every block = (4-1)+(8-7)+(8-7)+(16-14)= 3+1+1+2 = 7MB.</p>
<p>Suppose process P5 of size 7MB comes. But this process cannot be accommodated inspite of available free space because of contiguous allocation (as spanning is not allowed). Hence, 7MB becomes part of External Fragmentation.</p>
<p>There are some advantages and disadvantages of fixed partitioning.</p>
<p><strong>Advantages of Fixed Partitioning –</strong></p>
<ol>
<li><strong>Easy to implement:</strong><br/>
Algorithms needed to implement Fixed Partitioning are easy to implement. It simply requires putting a process into certain partition without focussing on the emergence of Internal and External Fragmentation.
</li>
<p></p>
<li><strong>Little OS overhead:</strong><br/>
Processing of Fixed Partitioning require lesser excess and indirect computational power.
</li>
</ol>
<p><strong>Disadvantages of Fixed Partitioning –</strong></p>
<ol>
<li><strong>Internal Fragmentation:</strong><br/>
Main memory use is inefficient. Any program, no matter how small, occupies an entire partition. This can cause internal fragmentation.
</li>
<p></p>
<li><strong>External Fragmentation:</strong><br/>
The total unused space (as stated above) of various partitions cannot be used to load the processes even though there is space available but not in the contiguous form (as spanning is not allowed).
</li>
<p></p>
<li><strong>Limit process size:</strong><br/>
Process of size greater than size of partition in Main Memory cannot be accommodated. Partition size cannot be varied according to the size of incoming process’s size. Hence, process size of 32MB in above stated example is invalid.
</li>
<p></p>
<li><strong>Limitation on Degree of Multiprogramming:</strong><br/>
Partition in Main Memory are made before execution or during system configure. Main Memory is divided into fixed number of partition. Suppose if there are <img alt="n1" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-937e401cd3cef559d86c3a296fcf43e7_l3.png" style="vertical-align: -1px;" title="Rendered by QuickLaTeX.com" width="27"> partitions in RAM and <img alt="n2" class="ql-img-inline-formula quicklatex-auto-format" height="18" src="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1672a35080009080386b680663ed87ab_l3.png" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="28"> are the number of processes, then <img alt="n2 &lt;= n1" class="ql-img-inline-formula quicklatex-auto-format" height="19" src="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-231dea6b32402d0a6e0443d1a8c13eda_l3.png" style="vertical-align: -1px;" title="Rendered by QuickLaTeX.com" width="112"> condition must be fulfilled. Number of processes greater than number of partitions in RAM is invalid in Fixed Partitioning.
</img></img></img></li>
</ol>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/ayushnigam9424/">ayushnigam9424</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-235312 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization" id="post-235312">
<header class="entry-header">
<h1 class="entry-title">Message based Communication in IPC (inter process communication)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisites – , , <br/>
In the development of models and technologies, message abstraction is a necessary aspect that enables distributed computing. Distributed system is defined as a system in which components reside at networked communication and synchronise its functions only by movement of messages. In this, message recognizes any discrete data that is moved from one entity to another. It includes any kind of data representation having restriction of size and time, whereas it invokes a remote procedure or a sequence of object instance or a common message. This is the reason that “<i>message-based communication model</i>” can be beneficial to refer various model for inter-process communication, which is based on the data streaming abstraction.</p>
<p>Various distributed programming model use this type of communication despite of the abstraction which is shown to developers for programming the co-ordination of shared components. Below are some major distributed programming models that uses “<i>message-based communication model</i>”.</p>
<ul>
<li><strong>Message Passing –</strong><br/>
In this model, the concept of message as the major abstraction of model is introduced. The units which inter-change the data and information that is explicitly encode, in the form of message. According to then model, the schema and content of message changes or varies. Message Passing Interface and OpenMP are major example of this type of model.</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-234498 post type-post status-publish format-standard hentry category-cpp-programs category-computer-subject category-operating-systems tag-operating-systems-deadlock" id="post-234498">
<header class="entry-header">
<h1 class="entry-title">Program for Deadlock free condition in Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Given: A system has R identical resources, P processes competing for them and N is the maximum need of each process. The task is to find the minimum number of Resources required So that deadlock will never occur. </p>
<p><strong>Formula:</strong></p>
<pre>R &gt;= P * (N - 1) + 1 </pre>
<p><strong>Examples:</strong></p>
<pre>Input : P = 3, N = 4

Output : R &gt;= 10



Input : P = 7, N = 2

Output : R &gt;= 8 </pre>
<p><strong>Approach:</strong></p>
<blockquote><p>
Consider, 3 process A, B and C.<br/>
Let, Need of each process is 4<br/>
Therefore, The maximum resources require will be 3 * 4 = 12 <strong>i.e</strong>, Give 4 resources to each Process.<br/>
And, The minimum resources required will be 3 * (4 – 1) + 1 = 10.<br/>
i.e, Give 3 Resources to each of the Process, and we are left out with 1 Resource.<br/>
That 1 resource will be given to any of the Process A, B or C.<br/>
So that after using that resource by any one of the Process, It left the resources and that resources will be used by any other Process and thus <strong>Deadlock will Never Occur.</strong>
</p></blockquote>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-234337 post type-post status-publish format-standard hentry category-c-arrays category-c-programs category-computer-networks category-interview-experiences category-linked-list category-operating-systems category-tree tag-sandvine" id="post-234337">
<header class="entry-header">
<h1 class="entry-title">Sandvine Interview Experience for FTE 2018</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Sandvine visited our campus for FTE.<br/>
Total 3 round<br/>
1. Aptitude (20 MCQ) 20 min<br/>
2. Technical (30 MCQ) 40 min ( Computer Network, Operating System, C/Java/python code output )<br/>
3. 3 coding question + 1 question to write about 3 bugs in the given code. 40 min</p>
<p>Coding Question were :<br/>
1. Given a binary tree and depth n, we have to print node at the depth n and function should not traverse tree<br/>
beyond the depth n.<br/>
2. given a binary array consisting of {0, 1} we have to return the index at which one operation can be performed ( convert 0 to 1 ) such continuous 1 is maximized. linear space and time complexity were expected.<br/>
3. given a linked list such we have to group nodes at even place and odd place together after that we have to append odd place node to the even place node in the reverse order.<br/>
ex : 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;7 ;<br/>
output : 2-&gt;4-&gt;6-&gt;7-&gt;5-&gt;3-&gt;1 :</p>
<p>we have to write only pseudo code in their text editor.<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-233558 post type-post status-publish format-standard hentry category-computer-organization-architecture category-digital-electronics-logic-design category-gate-cs category-operating-systems tag-operating-systems-memory-management tag-technical-scripter-2018" id="post-233558">
<header class="entry-header">
<h1 class="entry-title">Computer Organization | RAM vs ROM</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Random Access Memory (RAM)</b> is used to store the programs and data being used by the CPU in real time. The data on the random access memory can be read, written, and erased any number of times. RAM is the hardware element where the data being currently used is stored. It is a volatile memory. Types of RAM:</p>
<ol>
<li><strong>Static RAM</strong>, or (SRAM) which stores a bit of data using the state of a six transistor memory cell.
</li>
<li><strong>Dynamic RAM</strong>, or (DRAM) which stores a bit data using a pair of transistor and capacitor which constitute a DRAM memory cell.
</li>
</ol>
<p><b>Read Only Memory (ROM)</b> is a type of memory where the data has been prerecorded. Data stored in ROM is retained even after the computer is turned off ie, non-volatile. Types of ROM:</p>
<ol>
<li><strong>Programmable ROM</strong>, where the data is written after the memory chip has been created. It is non-volatile.
</li>
<li><strong>Erasable Programmable ROM</strong>, where the data on this non-volatile memory chip can be erased by exposing it to high-intensity UV light.
</li>
<li><strong>Electrically Erasable Programmable ROM</strong>, where the data on this non-volatile memory chip can be electrically erased using field electron emission.
</li>
<li><strong>Mask ROM</strong>, in which the data is written during the manufacturing of the memory chip.
</li>
</ol>
<p>The following table differentiates ROM and RAM:</p>
<table width="100%">
<thead>
<tr>
<th>Difference</th>
<th>RAM</th>
<th>ROM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data retention</td>
<td>RAM is a volatile memory which could store the data as long as the power is supplied. </td>
<td>ROM is a non-volatile memory which could retain the data even when power is turned off. </td>
</tr>
<tr>
<td>Working type</td>
<td>Data stored in RAM can be retrieved and altered. </td>
<td>Data stored in ROM can only be read.</td>
</tr>
<tr>
<td>Use</td>
<td>Used to store the data that has to be currently processed by CPU temporarily. </td>
<td>It stores the instructions required during bootstrap of the computer. </td>
</tr>
<tr>
<td>Speed </td>
<td>It is a high-speed memory.</td>
<td>It is much slower than the RAM.</td>
</tr>
<tr>
<td>CPU Interaction</td>
<td>The CPU can access the data stored on it. </td>
<td>The CPU can not access the data stored on it unless the data is stored in RAM.</td>
</tr>
<tr>
<td>Size and Capacity</td>
<td>Large size with higher capacity.</td>
<td>Small size with less capacity.</td>
</tr>
<tr>
<td>Used as/in </td>
<td>CPU Cache, Primary memory.</td>
<td>Firmware, Micro-controllers</td>
</tr>
<tr>
<td>Accessibility</td>
<td>The data stored is easily accessible</td>
<td>The data stored is not as easily accessible as in RAM </td>
</tr>
<tr>
<td>Cost</td>
<td>Costlier </td>
<td>cheaper than RAM.</td>
</tr>
</tbody>
</table>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-232298 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-232298">
<header class="entry-header">
<h1 class="entry-title">Difference between Spooling and Buffering</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>There are two ways by which Input/output subsystems can  improve the performance and efficiency of the computer by using a memory space in main memory or on the disk and these two are <i>spooling and buffering</i>.</p>
<p><strong> –</strong><br/>
Spooling stands for Simultaneous peripheral operation online. A spool is a similar to  buffer as it holds the jobs for a device till the device is ready to accept the job. It considers disk as a huge buffer which can store as many jobs for the device till the output devices are ready to accept them.</p>
<p><strong>Buffering –</strong><br/>
he  main memory has an area called buffer that is used to store or hold the data temporarily that is being transmitted either between two devices or between a device or an application. Buffering is an act of storing data temporarily in the buffer. It helps in matching the speed of the data stream between the sender and receiver. If speed of the sender’s transmission is slower than receiver, then a buffer is created in main memory of the receiver, and it accumulates the bytes received from the sender and vice versa.</p>
<p>The basic difference between Spooling and Buffering is that Spooling overlaps the input/output of one job with the execution of another job while the buffering overlaps input/output of one job with the execution of the same job.</p>
<p><strong>Differences between Spooling and Buffering –</strong></p>
<ul>
<li>The key difference between spooling and buffering is that Spooling can handle the input/output of one job along with the computation of an another job at the same time while buffering handles input/output of one job along with its computation.
</li>
<li>Spooling is an stands for Simultaneous Peripheral Operation online. Whereas buffering is not an acronym.
</li>
<li>Spooling is more efficient than buffering, as spooling can overlap processing two jobs at a time.
</li>
<li>Buffering use limited area in main memory while Spooling uses the disk as a huge buffer.
</li>
</ul>
<p><strong>Comparison chart –</strong></p>
<table width="100%">
<thead>
<tr>
<th></th>
<th>SPOOLING</th>
<th>BUFFERING</th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic Difference </td>
<td>It overlap the input/output of one job with the execution of another job. </td>
<td>It overlaps the input/output of one job with the execution of the same job. </td>
</tr>
<tr>
<td>Full form (stands for) </td>
<td>Simultaneous peripheral operation online </td>
<td>No full form </td>
</tr>
<tr>
<td>Efficiency </td>
<td>Spooling is more efficient than buffering. </td>
<td>Buffering is less efficient than spooling. </td>
</tr>
<tr>
<td>Consider Size  </td>
<td>It considers disk as a huge spool or buffer. </td>
<td>Buffer is a limited area in main memory. </td>
</tr>
</tbody>
</table>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-231602 post type-post status-publish format-standard hentry category-algorithm category-operating-systems" id="post-231602">
<header class="entry-header">
<h1 class="entry-title">Program for SSTF disk scheduling algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
Given an array of disk track numbers and initial head position, our task is to find the total number of seek operations done to access all the requested tracks if <b>Shortest Seek Time First (SSTF)</b> is a disk scheduling algorithm is used.</p>
<p><strong>Shortest Seek Time First (SSTF) –</strong><br/>
Basic idea is the tracks which are closer to current disk head position should be serviced first in order to <i>minimise the seek operations</i>.</p>
<p><strong>Algorithm –</strong></p>
<ol>
<li>Let Request array represents an array storing indexes of tracks that have been requested. ‘head’ is the position of disk head.
</li>
<li>Find the positive distance of all tracks in the request array from head.
</li>
<li>Find a track from requested array which has not been accessed/serviced yet and has minimum distance from head.
</li>
<li>Increment the total seek count with this distance.
</li>
<li>Currently serviced track position now becomes the new head position.
</li>
<li>Go to step 2 until all tracks in request array have not been serviced.
</li>
</ol>
<p><b>Example –</b><br/>
Request sequence = {176, 79, 34, 60, 92, 11, 41, 114}<br/>
Initial head position = 50<br/>
The following chart shows the sequence in which requested tracks are serviced using SSTF.</p>
<p><img alt="" class="aligncenter size-full wp-image-611499" height="440" src="https://media.geeksforgeeks.org/wp-content/uploads/3333-4.png" width="1147"/></p>
<p>Therefore, total seek count is calculates as:</p>
<pre>= (50-41)+(41-34)+(34-11)+(60-11)+(79-60)+(92-79)+(114-92)+(176-114)

= 204 </pre>
<p><strong>Implementation –</strong><br/>
Implementation of SSTF is given below. Note that we have made a node class having 2 members. ‘distance’ is used to store the distance between head and the track position. ‘accessed’ is a boolean variable which tells whether the track has been accessed/serviced before by disk head or not.<br/>
<div class="responsive-tabs">
<h2 class="tabtitle">Java</h2>
<div class="tabcontent">
</div></div></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-228683 post type-post status-publish format-standard hentry category-computer-subject category-linux-unix category-operating-systems" id="post-228683">
<header class="entry-header">
<h1 class="entry-title">Process states and Transitions in a UNIX Process</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<h3 align="center">Process</h3>
<p>A process is an instance of a program in execution. A set of processes combined together make a complete program.</p>
<p>There are two categories of processes in Unix, namely</p>
<ul>
<li><b>User processes</b>: They are operated in user mode.</li>
<li><b>Kernel processes</b>: They are operated in kernel mode.</li>
</ul>
<h3 align="center">Process States</h3>
<p>The states that a Process enters in working from start till end are known as Process states. These are listed below as:</p>
<ul>
<li><strong>Created</strong>-Process is newly created by system call, is not ready to run
</li>
<li><strong>User running</strong>-Process is running in user mode which means it is a user process.
</li>
<li><strong>Kernel Running</strong>-Indicates process is a kernel process running in kernel mode.
</li>
<li><strong>Zombie-</strong> Process does not exist/ is terminated.
</li>
<li><strong>Preempted- </strong>When process runs from kernel to user mode, it is said to be preempted.
</li>
<li><strong>Ready to run in memory-</strong> It indicated that process has reached a state where it is ready to run in memory and is waiting for kernel to schedule it.
</li>
<li><strong>Ready to run, swapped</strong>– Process is ready to run but no empty main memory is present
</li>
<li><strong>Sleep, swapped-</strong> Process has been swapped to secondary storage and is at a blocked state.
</li>
<li><strong>Asleep in memory-</strong> Process is in memory(not swapped to secondary storage) but is in blocked state.
</li>
</ul>
<div class="wp-caption aligncenter" id="attachment_577891" style="width: 970px"><img alt="Process transitions" class="size-full wp-image-577891" height="720" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/transitions.jpg" width="960"><p class="wp-caption-text">The numbers indicate the steps that are followed.</p></img></div>
<h3 align="center">Process Transitions</h3>
<p>The working of Process is explained in following steps:</p>
<ol>
<li><b>User-running:</b> Process is in user-running.
</li>
<li><b>Kernel-running:</b> Process is allocated to kernel and hence, is in kernel mode.
</li>
<li><b>Ready to run in memory:</b> Further, after processing in main memory process is rescheduled to the Kernel.i.e.The process is not executing but is ready to run as soon as the kernel schedules it.
</li>
<li><b>Asleep in memory:</b> Process is sleeping but resides in main memory. It is waiting for the task to begin.
</li>
<li><b>Ready to run, swapped:</b> Process is ready to run and be swapped by the processor into main memory, thereby allowing kernel to schedule it for execution.
</li>
<li><b>Sleep, Swapped:</b> Process is in sleep state in secondary memory, making space for execution of other processes in  main memory. It may resume once the task is fulfilled.
</li>
<li><b>Pre-empted:</b> Kernel preempts an on-going process for allocation of another process, while the first process is moving from kernel to user mode.
</li>
<li><b>Created:</b> Process is newly created but not running. This is the start state for all processes.
</li>
<li><b>Zombie:</b> Process has been executed thoroughly and exit call has been enabled.<br/>
The process, thereby, no longer exists. But, it stores a statistical record for the process.<br/>
This is the final state of all processes.
</li>
</ol>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-226413 post type-post status-publish format-standard hentry category-dbms category-dynamic-programming category-interview-experiences category-operating-systems tag-paytm" id="post-226413">
<header class="entry-header">
<h1 class="entry-title">Paytm Interview experience for FTE (On-Campus)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Online Coding Round</strong> : Platform used was cocubes.com<br/>
<strong>Time</strong> : 75 min <strong>Question</strong> : 3 Coding Question</p>
<p>1st Question : Simple linked list implementation. Given two strings in the form of linked lists you were to find the lexicographical greatest string.<br/>
2nd Question : You were given an array and you were supposed to find the number of elements which is/are largest among all elements present in the right side of that particular element in the array.<br/>
3rd Question : It was a question related to BP+Bitmask. I don’t remember the exact question.</p>
<p>Around 27 students were selected from the coding round and were called for further interview rounds.</p>
<p><strong>Round 1(Face-To-Face)</strong></p>
<p>The interviewer was very friendly.He asked me to introduce my self</p>
<p>Then he asked me some question :</p>
<p>1) Find the maximum cost in traversing a 2-D matrix from one given cell to another. It is same as Min Cost Path DP problem.</p>
<p>He asked me to write a code for this.</p>
<p>2) Rod Cutting DP</p>
<p>I gave him an approach and he was satisfied with this. Then he asked me to write the code.</p>
<p>3) Left view of Binary Tree<br/>
I gave him an approach and he was happy with approach. After this I was asked to write the code.</p>
<p>After these questions he went on for some theoretical questions related to OOPS, DBMS, OS etc.</p>
<p>He asked basic questions like polymorphism and its types. Then, about Normalization and its types with example. He also asked questions related to semaphores.</p>
<p><strong>Round 2(Face To Face 2)</strong></p>
<p>The interviewer was very friendly.He asked me to introduce my self and about my hobby.</p>
<p>He then moved on to the theoretical concepts of subjects. He asked me questions related to DBMS(transactions and its properties-ACID, about normalization with examples, indexing), OS(paging, segmentation, difference between process and thread etc).</p>
<p>After this he moved to my project, he asked me to give brief idea about my project. He asked questions related to my project(SQL vs No SQL, Node-Js concepts etc.).</p>
<p>Then he asked me a simple coding question with certain constraints and I solved it. He was very happy with my solution.</p>
<p>At the last he gave me a puzzle to which I couldn’t solve.</p>
<p><strong>Round 3(Technical+Managerial)</strong></p>
<p>The interviewer was very friendly. He went through my resume and asked about my interest and extra co-curricular activities.</p>
<p>After this he asked about my aims, and other HR’s like questions.</p>
<p>He asked few project related questions and this was all for this round.</p>
<p><strong>Round 4(HR)</strong></p>
<p>The interviewer was very friendly. She asked me to introduce myself.</p>
<p>She asked about my hobby. After this few questions like Why Paytm? etc. This was non-tech round. She wanted to check your nature, attitude and team work skills. Then I was asked to wait for the results.</p>
<p><strong>Verdict</strong> – Selected 🙂</p>
<p>A big thank you to GeeksforGeeks for providing such invaluable material for preparation.<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-224734 post type-post status-publish format-standard hentry category-computer-organization-architecture category-digital-electronics-logic-design category-gate-cs category-operating-systems tag-os-memory-management" id="post-224734">
<header class="entry-header">
<h1 class="entry-title">Introduction to memory and memory units</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Memories are made up of registers. Each register in the memory is one storage location. Storage location is also called as memory location. Memory locations are identified using <strong>Address</strong>. The total number of bit a memory can store is its <strong>capacity</strong>. </p>
<p>A storage element is called a <strong>Cell</strong>. Each register is made up of storage element in which one bit of data is stored. The data in a memory are stored and retrieved by the process called <strong>writing</strong> and <strong>reading</strong> respectively. </p>
<p><img class="aligncenter size-full" height="500" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Read-and-write.png" width="700"/></p>
<p>A <strong>word</strong> is a group of bits where a memory unit stores binary information. A word with group of 8 bits is called a <strong>byte</strong>.<br/>
A memory unit consists of data lines, address selection lines, and control lines that specify the direction of transfer. The block diagram of a memory unit is shown below:</p>
<p><img class="aligncenter size-full" height="318" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/memory-unit.png" width="400"/></p>
<p>Data lines provide the information to be stored in memory. The control inputs specify the direction transfer. The k-address lines specify the word chosen.</p>
<p>When there are k address lines, 2<sup>k</sup> memory word can be accessed.   </p>
<p>Refer for , , , and </p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-221703 post type-post status-publish format-standard hentry category-java-programs category-operating-systems tag-cpu-scheduling tag-operating-systems-cpu-scheduling" id="post-221703">
<header class="entry-header">
<h1 class="entry-title">Round Robin Scheduling with different arrival times</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Prerequisite:</strong> <a href="https://www.geeksforgeeks.org/program-round-robin-scheduling-set-1/">Round Robin Scheduling with arrival time as 0</a></p>
<p><strong>Round robin scheduling algorithm</strong> is used to schedule process fairly each job a time slot or quantum and the interrupting the job if it is not completed by then the job come after the other job which are arrived in the quantum time that make these scheduling fairly<br/>
<br/>
<b>Note:</b></p>
<ul>
<li>Round robin is cyclic in nature so starvation doesn’t occur </li>
<li>Round robin is variant of first come, first served scheduling</li>
<li>No priority, special importance given to any process or task</li>
<li>RR scheduling is also known as Time slicing scheduling</li>
</ul>
<p><b>Advantages:</b></p>
<ul>
<li>Each process is served by CPU for a fixed time so priority is same for each one</li>
<li>Starvation does not occur because of its cyclic nature.</li>
</ul>
<p><b>Disadvantages:</b></p>
<ul>
<li>Throughput depends on quantum time.</li>
<li>If we want to give some process priority, we cannot.</li>
</ul>
<table width="50%">
<thead>
<tr>
<th>Process</th>
<th>Arrival Time</th>
<th>Burst Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>P1</td>
<td>0</td>
<td>10</td>
</tr>
<tr>
<td>P2</td>
<td>1</td>
<td>4</td>
</tr>
<tr>
<td>P3</td>
<td>2</td>
<td>5</td>
</tr>
<tr>
<td>P4</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<p><b>Quantum time is 3</b> this means each process is only executing for 3 units of time at a time.<br/>
</p>
<p><b>How to compute these process requests:-</b></p>
<ol type="1">
<li>Take the process which occurs first and start executing the process.(for quantum time only)</li>
<li>Check if any other process request has arrived. If a process request arrives during the quantum time in which another process is executing, then add the new process to the Ready queue</li>
<li>After quantum time has passed, check for any processes in Ready queue. If ready queue is empty continue current process. If queue not empty and current process is not complete, then add current process to the end of the ready queue.</li>
<li>Take the first process from the Ready queue and start executing it (same rules)</li>
<li>Repeat all steps above from 2-5</li>
<li>If process is complete and the ready queue is empty then task is complete</li>
</ol>
<p>After all these we get the three times which are:</p>
<ol type="1">
<li><strong>Completion Time:</strong> the time taken for a process to complete.</li>
<li><strong>Turn Around Time:</strong> total time the process exists in system.(completion time – arrival time).</li>
<li><strong>Waiting Time:</strong> total time the waiting for there complete execution.(turn around time – burst time ).</li>
</ol>
<p>
<b>How to implement in programming language</b></p>
<pre>

1. Create two arrays of burst time res_b[] and of 

  arrival time res_a[] and copy the value of 

  the b[] and a[] array for calculate the 

  remaining time.(b[] is burst time, a[] arrival time).

2. Create an another array for wt[] to store waiting time.

3. Initialize Time : t=0;

4. Keep traversing the all process while all 

   process are not done.

   Do following for i'th process if it is not done yet.

   a- if res_a[i]&lt;= q   (quantum time :- q)

        1. if res_b[i]&gt;q 

             a. t=t+q

             b. res_b[i]-=q;

             c. a[i]+=q;

        2. else res_b[i]&lt;=q(for last to execute)

              a. t=t+b[i];

              b. wt[i]=t-b[i]-a[i];

              c.res_b[i]=0;

    b- else res_a[i]&lt;q

          1. Initialize j=0 to number of process

             if a[j]&lt;a[i] (compare is there any 

             other process come before these process)

                    1. if res_b[j]&gt;q 

                            a. t=t+q

                            b. res_b[j]-=q;

                            c. a[j]+=q;

                    2. else res_b[j]&lt;=q

                           a. t=t+b[j];

                           b. wt[j]=t-b[j]-a[j];

                           c.res_b[j]=0; 

          2. now we executing the i'th process 

                      1. if res_b[i]&gt;q 

                            a. t=t+q

                            b. res_b[i]-=q;

                            c. a[i]+=q;

                      2. else res_b[i]&lt;=q

                            a. t=t+b[i];

                            b. wt[i]=t-b[i]-a[i];

                            c.res_b[i]=0;

</pre>
<p></p>
<p>Below is the implementation of the above approach: </p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-223007 post type-post status-publish format-standard hentry category-operating-systems tag-os-deadlocks tag-operating-systems-deadlock" id="post-223007">
<header class="entry-header">
<h1 class="entry-title">Techniques used in centralized approach of deadlock detection in distributed systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
In the centralized approach of deadlock detection, <b>two techniques</b> are used namely: Completely centralized  algorithm and Ho Ramamurthy algorithm (One phase and Two-phase). </p>
<ul>
<li><b>Completely Centralized Algorithm –</b><br/>
In a network of n sites, one site is chosen as a control site. This site is responsible for deadlock detection. It has control over all resources of the system. If a site requires a resource it requests the control site, the control site allocates and de-allocates resources and maintains a wait for graph. And at regular interval of time, it checks the wait for graph to detect a cycle. If cycle exits then it will declare system as deadlock otherwise the system will continue working. The major drawbacks of this technique are as follows:</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-220644 post type-post status-publish format-standard hentry category-aptitude-gq category-c category-cpp category-cs-placements-gq category-dbms category-internship-interview-experiences category-interview-experiences category-operating-systems category-placements-gq tag-cvent" id="post-220644">
<header class="entry-header">
<h1 class="entry-title">Cvent Interview Experience(On campus for Internship and Full Time)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p> </p>
<p><strong>Technical attitude test(Round 1)</strong></p>
<p>This round consisted of 30 aptitude questions based on general aptitude and computer science fundamental subjects like operating system, dbms, c/c++, sql, computer networks.</p>
<p>Around 300 students sat for this test and 41 students were shortlisted for the next coding round.</p>
<p><strong>Coding round(Round 2)</strong><br/>
This round consisted of 1 programming question which had to be solved in a timespan of 90 minutes.<br/>
The test was conducted on codility platform.<br/>
The coding question was that we are given a rectangle which is of size 26×26 and we have been given some battle ships and their is another person who does not knows what is the position of these battle ships and he randomly hits those battle ships and the positions that the person hits are given.<br/>
The battle shop can be of maximum 4 size and we were given the top left and bottom right corner of the battle ship.<br/>
We had to return what is the number of battle ships that are hit and are sunk.<br/>
The battle ship is said to be sunk of all the coordinates of the battle ships in the matrix have been hit and if some coordinates are hit then the battle ship is only hit but not sunk.</p>
<p>For example<br/>
Ship – {1A 2B, 3A 3A}<br/>
Hits – {1A 3A 5C 1B}</p>
<p>In this example there are 2 battle ships and the second person has made 4 hits.<br/>
The position of the ships are from index (1, 1) to (2, 2) and the position of second ship is from (3, 1) to (3, 1).<br/>
The battle ship 1 has been hit and battle ship 2 has been sunk.</p>
<p>11 students were shortlisted for further rounds of interview.</p>
<p><strong>Technical interview (Round 3)</strong><br/>
This was a technical interview<br/>
1. You hace been given a array which is sorted and rotated and you have to search a element from that array.</p>
<p>2. There is a orchid of apple trees and all the trees are standing in a line and they have apples on them.<br/>
There are 2 people and they have a number k and l that means they can pluck apples from k and l consecutive trees and we had to maximize the number of apples that they can pluck from the trees provided that they cannot overlap their interval of trees.</p>
<p>3. Implement three stacks in a array.I was able to implement a basic solution and then he extended the problem to implement k stacks in a array.</p>
<p>4. What all you have learnt in your college apart from computer programming.</p>
<p>5. He asked what is the advantage of a RDBMS software over a file based databases management software.</p>
<p>Out of 11 students only 3 students were shortlisted for further rounds of interview.</p>
<p><strong>Aptitude and personally assessment test (Round 4)</strong><br/>
It was a 50 minutes short test which had 50 general aptitude and English questions that had to be solved in 22 minutes.<br/>
Then I had to solve a good number of psychometric based questions that judge a person’s personality.</p>
<p>Only 2 students reached round 4 that was technical interview round.</p>
<p><strong>Technical cum HR Interview (Round 4)</strong><br/>
It was a 1 hour round with the director of technology, Cvent.<br/>
1. He asked me about my introduction.<br/>
2. He asked what I liked and disliked about the company ppt?<br/>
3. In what all companies have you applied till date?<br/>
4. What is your dream company?<br/>
5. Why do you want to join Cvent?<br/>
6. Are you happy joining Thapar university and what was your dream college before joining Thapar?<br/>
7. He asked a technical question that you have been given a 10×10×10 cube consisting of 1000 cubes of size 1. He asked what all types of cubes you can see from all the sides of the cubes. He asked me to drive a formula for a n×n×n cube.<br/>
8. He asked me about my favorite subjects and then i told him that i am comfortable in operating system, data structures and algorithms and database management.<br/>
9. He asked questions about databases and concepts such as inner join, outer join etc.<br/>
10. He asked whether I had any questions for him?<br/>
I asked what is the role of machine learning and artificial intelligence in the Cvent company?</p>
<p>Finally I was the only one to be selected for 6 months internship and full time offer at Cvent.</p>
<p>I would like to thank geeksforgeeks for helping me out in preparing for the company as well as providing an excellent resource for placement preparing.</p>
<p>Being their campus ambassador helped me a lot in acquiring great knowledge and sharing it with my juniors.</p>
<p>This article has been contributed by <strong>Ashish Madaan</strong>.<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-220617 post type-post status-publish format-standard hentry category-operating-systems tag-os-processes-threads" id="post-220617">
<header class="entry-header">
<h1 class="entry-title">Pass the value from child process to parent process</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite</b>: <a href="https://www.geeksforgeeks.org/c-program-demonstrate-fork-and-pipe/">Pipe() and Fork() Basic</a><br/>
Write a C program in which the child process takes an input array and send it to the parent process using pipe() and fork() and then print it in the parent process.</p>
<p><strong>Examples:</strong> Suppose we have an array a[]={1, 2, 3, 4, 5} in child process, then output should be 1 2 3 4 5.</p>
<pre>

Input:  1 2 3 4 5

Output: 1 2 3 4 5

</pre>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-220095 post type-post status-publish format-standard hentry category-operating-systems tag-distributed-system" id="post-220095">
<header class="entry-header">
<h1 class="entry-title">Deadlock detection in Distributed systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In a distributed system deadlock can neither be prevented nor avoided as the system is so vast that it is impossible to do so. Therefore, only deadlock detection can be implemented. The techniques of deadlock detection in the distributed system require the following:</p>
<ul>
<li><b>Progress –</b> The method should be able to detect all the deadlocks in the system.
</li>
<li><b>Safety –</b> The method should not detect false of phantom deadlocks.
</li>
</ul>
<p>There are three approaches to detect deadlocks in distributed systems. They are as follows:</p>
<ol>
<li><b>Centralized approach –</b><br/>
In the centralized approach there is only one responsible resource to detect deadlock. The advantage of this approach is that it is simple and easy to implement, while the drawbacks include excessive workload at one node, single point failure (that is the whole system is dependent on one node if that node fails the whole system crashes) which in turns makes the system less reliable.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-218859 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-218859">
<header class="entry-header">
<h1 class="entry-title">Interprocess Communication: Methods</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – ,<br/>
<b>Inter-process communication (IPC)</b> is set of interfaces, which is usually programmed in order for the programs to communicate between series of processes. This allows running programs concurrently in an Operating System. These are the methods in IPC:</p>
<ol>
<li><b>Pipes (Same Process) –</b><br/>
This allows flow of data in one direction only. Analogous to simplex systems (Keyboard). Data from the output is usually buffered until input process receives it which must have a common origin.
</li>
<p></p>
<li><b>Names Pipes (Different Processes) –</b><br/>
This is a pipe with a specific name it can be used in processes that don’t have a shared common process origin. E.g. is FIFO where the details written to a pipe is first named.
</li>
<p></p>
<li><b> Message Queuing –</b><br/>
This allows messages to be passed between processes using either a single queue or several message queue. This is managed by system kernel these messages are coordinated using an API.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-218732 post type-post status-publish format-standard hentry category-computer-organization-architecture category-operating-systems category-school-programming tag-cbse-class-11 tag-school-programming" id="post-218732">
<header class="entry-header">
<h1 class="entry-title">Secondary Memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Primary memory has limited storage capacity and is volatile. Secondary memory overcome this limitation by providing permanent storage of data and in bulk quantity. Secondary memory is also termed as external memory and refers to the various storage media on which a computer can store data and programs. The Secondary storage media can be fixed or removable. Fixed Storage media is an internal storage medium like hard disk that is fixed inside the computer. Storage medium that are portable and can be taken outside the computer are termed as removable storage media.</p>
<p><strong>Difference between Primary Memory and Secondary Memory:</strong></p>
<table style="table-layout:fixed;" width="100%">
<thead>
<tr>
<th>Primary Memory</th>
<th>Secondary Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>Primary memory is directly accessed by the Central Processing Unit(CPU).</td>
<td>Secondary memory is not accessed directly by the Central Processing Unit(CPU). Instead, data accessed from a secondary memory is first loaded into Random Access Memory(RAM) and is then sent to the Processing Unit.</td>
</tr>
<tr>
<td style="background-color:rgba(183, 223, 182, 0.5);"> RAM provides much faster accessing speed to data than secondary memory. By loading software programs and required files into primary memory(RAM), computer can process data much more quickly.</td>
<td style="background-color:rgba(183, 223, 182, 0.5);">Secondary Memory is slower in data accessing. Typically primary memory is six times faster than the secondary memory.</td>
</tr>
<tr>
<td>Primary memory, i.e. Random Access Memory(RAM) is volatile and gets completely erased when a computer is shut down.</td>
<td>Secondary memory provides a feature of being non-volatile, which means it can hold on to its data with or without electrical power supply.</td>
</tr>
</tbody>
</table>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-218438 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-picked tag-os-process-synchronization" id="post-218438">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Synchronization | Set 2</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , , <br/>
<b>Process Synchronization</b> is a technique which is used to coordinate the process that use shared Data. There are two types of Processes in an Operating Systems:-</p>
<ol>
<li><strong>Independent Process –</strong><br/>
The process that does not affect or is affected by the other process while its execution then the process is called Independent Process. Example The process that does not share any shared variable, database, files, etc.
</li>
<li><strong>Cooperating Process –</strong><br/>
The process that affect or is affected by the other process while execution, is called a Cooperating Process. Example The process that share file, variable, database, etc are the Cooperating Process.
</li>
</ol>
<p>Process Synchronization is mainly used for Cooperating Process that shares the resources.Let us consider an example of<br/>
//racing condition image</p>
<p><img class="aligncenter size-full" height="600" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Race-condition.png" width="600"/></p>
<p>It is the condition where several processes tries to access the resources and modify the shared data concurrently and outcome of the process depends on the particular order of execution that leads to data inconsistency, this condition is called <b>Race Condition</b>.This condition can be avoided using the technique called Synchronization or Process Synchronization, in which we allow only one process to enter and manipulates the shared data in Critical Section.<br/>
//diagram of the view of CS</p>
<p><img class="aligncenter size-full" height="350" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/CR_repr.png" width="400"/></p>
<p>This setup can be defined in various regions like:</p>
<ul>
<li><b>Entry Section –</b><br/>
It is part of the process which decide the entry of a particular process in the Critical Section, out of many other processes.
</li>
<li><b>Critical Section –</b><br/>
It is the part in which only one process is allowed to enter and modify the shared variable.This part of the process ensures that only no other process can access the resource of shared data.
</li>
<li><b>Exit Section –</b><br/>
This process allows the other process that are waiting in the Entry Section, to enter into the Critical Sections. It checks that a process that after a process has finished execution in Critical Section can be removed through this Exit Section.
</li>
<li><b>Remainder Section –</b><br/>
The other parts of the Code other than Entry Section, Critical Section and Exit Section are known as Remainder Section.
</li>
</ul>
<p>Critical Section problems must satisfy these three requirements:</p>
<ol>
<li><b>Mutual Exclusion –</b><br/>
It states that no other process is allowed to execute in the critical section if a process is executing in critical section.
</li>
<li><b>Progress –</b><br/>
When no process is in the critical section, then any process from outside that request for execution can enter in the critical section without any delay. Only those process can enter that have requested and have finite time to enter the process.
</li>
<li><b>Bounded Waiting –</b><br/>
An upper bound must exist on the number of times a process enters so that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted.
</li>
</ol>
<p>Process Synchronization are handled by two approaches:</p>
<ol>
<li><b>Software Approach –</b><br/>
In Software Approach, Some specific Algorithm approach is used to maintain synchronization of the data. Like in Approach One or Approach Two, for a number of two process, a temporary variable like (turn) or boolean variable (flag) value is used to store the data. When the condition is True then the process in waiting State, known as Busy Waiting State. This does not satisfy all the Critical Section requirements.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-217183 post type-post status-publish format-standard hentry category-operating-systems tag-cbse-class-11 tag-school-programming" id="post-217183">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Need and Functions</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Goal of an Operating System:</strong><br/>
The fundamental goal of a Computer System is to execute user programs and to make tasks easier. Various application programs along with hardware system are used to perform this work. Operating System is a software which manages and control the entire set of resources and effectively utilize every part of a computer.<br/>
The figure shows how OS acts as a medium between hardware unit and application programs.  </p>
<p><center><img alt="" src="http://contribute.geeksforgeeks.org/wp-content/uploads/needofos.png"> </img></center></p>
<p><strong>Need of Operating System: </strong></p>
<ul>
<li><strong>OS as a platform for Application programs:</strong> Operating system provides a platform, on top of which, other programs, called application programs can run. These application programs help the users to perform a specific task easily. It acts as an interface between the computer and the user. It is designed in such a manner that it operates, controls and executes various applications on the computer.</li>
<li><strong>Managing Input-Output unit:</strong> Operating System also allows the computer to manage its own resources such as memory, monitor, keyboard, printer etc. Management of these resources is required for an effective utilization.The operating system controls the various system input-output resources and allocates them to the users or programs as per their requirement.</li>
<li><strong>Consistent user interface:</strong> Operating System provides the user an easy-to-work user interface, so the user doesn’t have to learn a different UI every time and can focus on the content and be productive as quickly as possible. Operating System provides templates, UI components to make the working of a computer, really easy for the user.</li>
<li><strong>Multitasking:</strong> Operating System manages memory and allow multiple programs to run in their own space and even communicate with each other through shared memory. Multitasking gives users a good experience as they can perform several tasks on a computer at a time.</li></ul>
</div></article><hr style="border: 2px dashed black;" /><article class="post-216777 post type-post status-publish format-standard hentry category-operating-systems" id="post-216777">
<header class="entry-header">
<h1 class="entry-title">Operating System | Free space management</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The system keeps tracks of the free disk blocks for allocating space to files when they are created. Also, to reuse the space released from deleting the files, free space management becomes crucial. The system maintains a free space list which keeps track of the disk blocks that are not allocated to some file or directory. The free space list can be implemented mainly as:</p>
<ol>
<li><b>Bitmap or Bit vector –</b><br/>
A Bitmap or Bit Vector is series or collection of bits where each bit corresponds to a disk block. The bit can take two values: 0 and 1:  <em>0 indicates that the block is allocated</em> and 1 indicates a free block.<br/>
The given instance of disk blocks on the disk in <em>Figure 1</em> (where green blocks are allocated) can be represented by a bitmap of 16 bits as:<strong> 0000111000000110</strong>.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-216444 post type-post status-publish format-standard hentry category-computer-networks category-interview-experiences category-operating-systems tag-nokia" id="post-216444">
<header class="entry-header">
<h1 class="entry-title">Nokia Interview Experience | Set 5</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Nokia interview</strong></p>
<p><strong>First round</strong>: Based on AMCAT</p>
<p>After cleared first round, we got a mail, even I got short listed for the second round.first round was held in college  through webcam.</p>
<p>For second round we went to nokia networks in Bangalore .</p>
<p><strong>Round 2</strong>: Started with GD, they took many students from GD Round.</p>
<p><strong> Round 3:</strong>  Technical round they asked me avoab networks python (which I mentioned? in the resume), and about project.many students rejected in technical round.</p>
<p><strong>Round4:</strong> HR round (I didn’t go through this round)</p>
<p>it was a Nice experience, friendly company</p>
<p>Thanks to <strong>geeksfogeeks</strong>, I read most of the programming concept from friendly study site#geeksforgeeks</p>
<p>All the best for everyone, who are aiming for Nokia.</p>
<p> </p>
<p> </p>
<p> </p>
<p> <br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-210127 post type-post status-publish format-standard hentry category-operating-systems" id="post-210127">
<header class="entry-header">
<h1 class="entry-title">Tasks in Real Time systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The system is subjected to real time, i.e. response should be guaranteed within a specified timing constraint or system should meet the specified deadline. For example flight control system, real-time monitors etc.<br/>
There are two types of tasks in real-time systems:</p>
<ol>
<li>Periodic tasks</li>
<li>Dynamic tasks</li>
</ol>
<ul>
<li><strong>Periodic Tasks:</strong> In periodic task, jobs are released at regular intervals. A periodic task is one which repeats itself after a fixed time interval. A periodic task is denoted by five tuples: <strong>T<sub>i</sub> = &lt; Φ<sub>i</sub>, P<sub>i</sub>, e<sub>i</sub>, D<sub>i</sub> &gt;</strong><br/>
Where, </li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-189201 post type-post status-publish format-standard hentry category-c category-linux-unix category-operating-systems" id="post-189201">
<header class="entry-header">
<h1 class="entry-title">Communication between two process using signals in C</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite :</b> <a href="https://www.geeksforgeeks.org/signals-c-language/"><b>C signal handling</b></a></p>
<p>In this post, the communication between child and parent processes is done using kill() and signal(), fork() system call.</p>
<ul>
<li><strong><a href="https://www.geeksforgeeks.org/fork-system-call/">fork()</a></strong> creates the child process from the parent. The pid can be checked to decide whether it is the child (if pid == 0) or the parent (pid = child process id).</li>
<li>The parent can then send messages to child using the pid and kill().</li>
<li>
The child picks up these signals with signal() and calls appropriate functions.</li>
</ul>
<p><strong>Example of how 2 processes can talk to each other using kill() and signal():</strong></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-211666 post type-post status-publish format-standard hentry category-operating-systems" id="post-211666">
<header class="entry-header">
<h1 class="entry-title">Operating System | Sleeping Barber problem</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<strong>Problem :</strong> The analogy is based upon a hypothetical barber shop with one barber. There is a barber shop which has one barber, one barber chair, and n chairs for waiting for customers if there are any to sit on the chair. </p>
<ul>
<li>If there is no customer, then the barber sleeps in his own chair. </li>
<li>When a customer arrives, he has to wake up the barber. </li>
<li>If there are many customers and the barber is cutting a customer’s hair, then the remaining customers either wait if there are empty chairs in the waiting room or they leave if no chairs are empty.</li>
</ul>
<p><img alt="" class="aligncenter size-full wp-image-499093" height="193" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Untitled-Diagram-25.png" width="511"/></p>
<p><b>Solution :</b> The solution to this problem includes three <a href="https://www.geeksforgeeks.org/semaphores-operating-system/">semaphores</a>.First is for the customer which counts the number of customers present in the waiting room (customer in the barber chair is not included because he is not waiting). Second, the barber 0 or 1 is used to tell whether the barber is idle or is working, And the third mutex is used to provide the mutual exclusion which is required for the process to execute. In the solution, the customer has the record of the number of customers waiting in the waiting room if the number of customers is equal to the number of chairs in the waiting room then the upcoming customer leaves the barbershop.</p>
<p>When the barber shows up in the morning, he executes the procedure barber, causing him to block on the semaphore customers because it is initially 0. Then the barber goes to sleep until the first customer comes up.</p>
<p>When a customer arrives, he executes customer procedure the customer acquires the mutex for entering the critical region, if another customer enters thereafter, the second one will not be able to anything until the first one has released the mutex. The customer then checks the chairs in the waiting room if waiting customers are less then the number of chairs then he sits otherwise he leaves and releases the mutex.</p>
<p>If the chair is available then customer sits in the waiting room and increments the variable waiting value and also increases the customer’s semaphore this wakes up the barber if he is sleeping.</p>
<p>At this point, customer and barber are both awake and the barber is ready to give that person a haircut. When the haircut is over, the customer exits the procedure and if there are no customers in waiting room barber sleeps.</p>
<p><img alt="" class="aligncenter size-full wp-image-495075" height="323" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/abc-3.png" width="516"/></p>
<p><strong>Algorithm for Sleeping Barber problem:</strong></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-211763 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-211763">
<header class="entry-header">
<h1 class="entry-title">Operating System | Belady’s Anomaly</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
In Operating System, process data is loaded in fixed sized chunks and each chunk is referred to as a page. The processor loads these pages in the fixed sized chunks of memory called frames. Typically the size of each page is always equal to the frame size. </p>
<p>A page fault occurs when a page is not found in the memory, and needs to be loaded from the disk. If a page fault occurs and all memory frames have been already allocated, then replacement of a page in memory is required on the request of a new page. This is referred to as demand-paging. The choice of which page to replace is specified by a page replacement algorithms. The commonly used page replacement algorithms are FIFO, LRU, optimal page replacement algorithms etc.</p>
<p>Generally, on increasing the number of frames to a process’ virtual memory, its execution becomes faster as less number of page faults occur. Sometimes the reverse happens, i.e. more number of page faults occur when more frames are allocated to a process. This most unexpected result is termed as<strong> Belady’s Anomaly</strong>.</p>
<p><b>Bélády’s anomaly</b> is the name given to the phenomenon where increasing the number of page frames results in an increase in the number of page faults for a given memory access pattern. </p>
<p>This phenomenon is commonly experienced in following page replacement algorithms:</p>
<ol>
<li>First in first out (FIFO)
</li>
<li>Second chance algorithm
</li>
<li>Random page replacement algorithm
</li>
</ol>
<p><strong>Reason of Belady’s Anomaly –</strong><br/>
The other two commonly used page replacement algorithms are Optimal and LRU, but Belady’s Anamoly can never occur in these algorithms for any reference string as they belong to a class of stack based page replacement algorithms.</p>
<p>A <strong>stack based algorithm </strong>is one for which it can be shown that the set of pages in memory for <em>N</em> frames is always a subset of the set of pages that would be in memory with <em>N + 1</em> frames. For LRU replacement, the set of pages in memory would be the <em>n</em> most recently referenced pages. If the number of frames increases then these<em> n</em> pages will still be the most recently referenced and so, will still be in the memory. While in FIFO, if a page named <em>b</em> came into physical memory before a page – <em>a</em> then priority of replacement of <em>b</em> is greater than that of <em>a</em>, but this is not independent of the number of page frames and hence, FIFO does not follow a stack page replacement policy and therefore suffers Belady’s Anomaly.</p>
<p><b>Example:</b> Consider the following diagram to understand the behaviour of a stack-based page replacement algorithm</p>
<p><img src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/stackbased.png"/></p>
<p>The diagram illustrates that given the set of pages i.e. {0, 1, 2} in 3 frames of memory is not a subset of the pages in memory – {0, 1, 4, 5} with 4 frames and it is a violation in the property of stack based algorithms. This situation can be frequently seen in FIFO algorithm.</p>
<p><strong>Belady’s Anomaly in FIFO –</strong><br/>
Assuming a system that has no pages loaded in the memory and uses the FIFO Page replacement algorithm. Consider the following reference string:</p>
<pre>1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 </pre>
<p><strong>Case-1:</strong> If the system has 3 frames, the given reference string on using FIFO page replacement algorithm yields a total of 9 page faults. The diagram below illustrates the pattern of the page faults occurring in the example.</p>
<p><img class="aligncenter size-full" height="167" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/fifo3.png" width="800"/></p>
<p><strong>Case-2:</strong> If the system has 4 frames, the given reference string on using FIFO page replacement algorithm yields a total of 10 page faults. The diagram below illustrates the pattern of the page faults occurring in the example.</p>
<p><img class="aligncenter size-full" height="215" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/fifo4.png" width="800"/></p>
<p>It can be seen from the above example that on increasing the number of frames while using the FIFO page replacement algorithm, the number of <b>page faults increased</b> from 9 to 10. </p>
<p><b>Note –</b> It is not necessary that every string reference pattern cause Belady anomaly in FIFO but there are certain kind of string references that worsen the FIFO performance on increasing the number of frames.</p>
<p><strong>Why Stack based algorithms do not suffer Anomaly –</strong><br/>
All the stack based algorithms never suffer Belady Anomaly because these type of algorithms assigns a priority to a page (for replacement) that is independent of the number of page frames. Examples of such policies are Optimal, LRU and LFU. Additionally these algorithms also have a good property for simulation, i.e. the miss (or hit) ratio can be computed for any number of page frames with a single pass through the reference string.</p>
<p>In LRU algorithm every time a page is referenced it is moved at the top of the stack, so, the top <em>n</em> pages of the stack are the <em>n</em> most recently used pages.Even if the number of frames are incremented to <em>n+1</em>, top of the stack will have <em>n+1</em> most recently used pages.</p>
<p>Similar example can be used to calculate the number of page faults in LRU algorithm. Assuming a system that has no pages loaded in the memory and uses the LRU Page replacement algorithm. Consider the following reference string:</p>
<pre>1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5  </pre>
<p><strong>Case-1:</strong> If the system has 3 frames, the given reference string on using LRU page replacement algorithm yields a total of 10 page faults. The diagram below illustrates the pattern of the page faults occurring in the example.</p>
<p><img class="aligncenter size-full" height="172" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/LRU33.png" width="800"/></p>
<p><strong>Case-2:</strong> If the system has 4 frames, the given reference string on using LRU page replacement algorithm, then total 8 page faults occur. The diagram shows the pattern of the page faults in the example.</p>
<p><img class="aligncenter size-full" height="216" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/LRU44-1.png" width="800"/></p>
<p><strong>Conclusion –</strong><br/>
Various factors substantially affect the number of page faults, such as reference string length and the number of free page frames available. Anomalies also occurs due to the small cache size as well as the reckless rate of change of the contents of cache. Also, the situation of fixed number of page faults even after increasing the number of frames can also be seen as an anomaly. Often algorithms like <b>Random page replacement algorithm</b> are also susceptible to Belady’s Anomaly, because it <b>may behave like first in first out (FIFO)</b> page replacement algorithm.  But Stack based algorithms are generally immune to all such situations as they are guaranteed to give better page hits when the frames are incremented. </p>
<p><strong>GATE CS Corner questions –</strong><br/>
Practicing the following questions will help you test your knowledge. All questions have been asked in GATE in previous years or in GATE Mock Tests. It is highly recommended that you practice them.</p>
<ol>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
</ol>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-211191 post type-post status-publish format-standard hentry category-hash category-heap category-operating-systems tag-cpp-map tag-cpp-pair tag-cpp-vector tag-data-structures-heap" id="post-211191">
<header class="entry-header">
<h1 class="entry-title">LFU (Least Frequently Used) Cache Implementation</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Least Frequently Used (LFU)</strong> is a caching algorithm in which the least frequently used cache block is removed whenever the cache is overflowed. In LFU we check the old page as well as the frequency of that page and if the frequency of the page is larger than the old page we cannot remove it and if all the old pages are having same frequency then take last i.e FIFO method for that and remove that page.</p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p><strong>Min-heap</strong> data structure is a good option to implement this algorithm, as it handles insertion, deletion, and update in logarithmic time complexity. A tie can be resolved by removing the least recently used cache block. The following two containers have been used to solve the problem: </p>
<ul>
<li>A vector of integer pairs has been used to represent the cache, where each pair consists of the block number and the number of times it has been used. The vector is ordered in the form of a min-heap, which allows us to access the least frequently used block in constant time. </li>
<li>A hashmap has been used to store the indices of the cache blocks which allows searching in constant time.</li>
</ul>
<p>Below is the implementation of the above approach: </p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-211241 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-os-process-synchronization" id="post-211241">
<header class="entry-header">
<h1 class="entry-title">Producer Consumer Problem using Semaphores | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
Producer consumer problem is a classical synchronization problem. We can solve this problem by using semaphores.</p>
<p>A <strong>semaphore</strong> S is an integer variable that can be accessed only through two standard operations : wait() and signal().<br/>
The wait() operation reduces the value of semaphore by 1 and the signal() operation increases its value by 1.</p>
<pre>

wait(S){

while(S&lt;=0);   // busy waiting

S--;

}



signal(S){

S++;

}

</pre>
<p>Semaphores are of two types:</p>
<ol>
<li><strong>Binary Semaphore –</strong> This is also known as mutex lock. It can have only two values – 0 and 1. Its value is initialized to 1. It is used to implement solution of critical section problem with multiple processes.
</li>
<li><strong>Counting Semaphore –</strong> Its value can range over an unrestricted domain. It is used to control access to a resource that has multiple instances.
</li>
</ol>
<p><strong>Problem Statement –</strong> We have a buffer of fixed size. A producer can produce an item and can place in the buffer. A consumer can pick items and can consume them. We need to ensure that when a producer is placing an item in the buffer, then at the same time consumer should not consume any item. In this problem, buffer is the critical section.</p>
<p>To solve this problem, we need two counting semaphores – Full and Empty. “Full” keeps track of number of items in the buffer at any given time and “Empty” keeps track of number of unoccupied slots.</p>
<p><strong>Initialization of semaphores –</strong><br/>
mutex = 1<br/>
Full = 0       // Initially, all slots are empty. Thus full slots are 0<br/>
Empty = n      // All slots are empty initially</p>
<p><strong>Solution for Producer –</strong></p>
<pre>

do{



//produce an item



wait(empty);

wait(mutex);



//place in buffer



signal(mutex);

signal(full);



}while(true)

</pre>
<p>When producer produces an item then the value of “empty” is reduced by 1 because one slot will be filled now. The value of mutex is also reduced to prevent consumer to access the buffer. Now, the producer has placed the item and thus the value of “full” is increased by 1. The value of mutex is also increased by 1 beacuse the task of producer has been completed and consumer can access the buffer.</p>
<p><strong>Solution for Consumer –</strong></p>
<pre>

do{



wait(full);

wait(mutex);



// remove item from buffer



signal(mutex);

signal(empty);



// consumes item



}while(true)

</pre>
<p>As the consumer is removing an item from buffer, therefore the value of “full” is reduced by 1 and the value is mutex is also reduced so that the producer cannot access the buffer at this moment. Now, the consumer has consumed the item, thus increasing the value of “empty” by 1. The value of mutex is also increased so that producer can access the buffer now.</p>
<p>See for implementation – </p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-203951 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-memory-management" id="post-203951">
<header class="entry-header">
<h1 class="entry-title">Operating System | Requirements of memory management system</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Memory management keeps track of the status of each memory location, whether it is allocated or free. It allocates the memory dynamically to the programs at their request and frees it for reuse when it is no longer needed. Memory management meant to satisfy some requirements that we should keep in mind.</p>
<p>These Requirements of memory management are:</p>
<ol>
<li><strong>Relocation –</strong> The available memory is generally shared among a number of processes in a multiprogramming system, so it is not possible to know in advance which other programs will be resident in main memory at the time of execution of his program. Swapping the active processes in and out of the main memory enables the operating system to have a larger pool of ready-to-execute process.<br/>
<br/>
When a program gets swapped out to a disk memory, then it is not always possible that when it is swapped back into main memory then it occupies the previous memory location, since the location may still be occupied by another process. We may need to <strong>relocate</strong> the process to a different area of memory. Thus there is a possibility that program may be moved in main memory due to swapping.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-207518 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-207518">
<header class="entry-header">
<h1 class="entry-title">Methods of resource allocation to processes by operating system</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The Operating System allocates resources when a program need them. When the program terminates, the resources are de-allocated, and allocated to other programs that need them. Now the question is, what strategy does the operating system use to allocate these resources to user programs?</p>
<p>There are two Resource allocation techniques:</p>
<ol>
<li><strong>Resource partitioning approach –</strong><br/>
In this approach, the operating system decides beforehand, that what resources should be allocated to which user program. It divides the resources in the system to many <em>resource partitions</em>, where each partition may include various resources – for example, 1 MB memory, disk blocks, and a printer.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-205323 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-205323">
<header class="entry-header">
<h1 class="entry-title">Operating System | Multithreading</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A <b>thread</b> is a path which is followed during a program’s execution. Majority of programs written now a days run as a single thread.Lets say, for example a program is not capable of reading keystrokes while making drawings. These tasks cannot be executed by the program at the same time. This problem can be solved through multitasking so that two or more tasks can be executed simultaneously.</p>
<p>Multitasking is of two types: Processor based and thread based. Processor based multitasking is totally managed by the OS, however multitasking through multithreading can be controlled by the programmer to some extent.</p>
<p>The concept of <b>multi-threading</b> needs proper understanding of these two terms – <b>a process and a thread</b>. A process is a program being executed. A process can be further divided into independent units known as threads. </p>
<p>A thread is like a small light-weight process within a process. Or we can say a collection of threads is what is known as a process. </p>
<p><img class="aligncenter size-full" height="400" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/thread-1.jpg" width="600"/></p>
<p><strong>Applications –</strong><br/>
Threading is used widely in almost every field. Most widely it is seen over the internet now days where we are using transaction processing of every type like recharges, online transfer, banking etc. Threading is a segment which divide the code into small parts that are of very light weight and has less burden on CPU memory so that it can be easily worked out and can achieve goal in desired field. The concept of threading is designed due to the problem of fast and regular changes in technology and less the work in different areas due to less application. Then as says “need is the generation of creation or innovation” hence by following this approach human mind develop the concept of thread to enhance the capability of programming.</p>
<p>Refer for , , and .</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-201554 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-201554">
<header class="entry-header">
<h1 class="entry-title">Operating System | Benefits of Multithreading</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
The benefits of multi threaded programming can be broken down into four major categories:</p>
<ol>
<li><strong>Responsiveness –</strong><br/>
Multithreading in an interactive application may allow a program to continue running even if a part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user. </li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-201574 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-201574">
<header class="entry-header">
<h1 class="entry-title">Operating System | Deadlock detection algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>If a system does not employ either a deadlock prevention or  then a deadlock situation may occur. In this case-</p>
<ul>
<li>Apply an algorithm to examine state of system to determine whether deadlock has has occurred or not.</li>
<li>Apply an algorithm to recover from the deadlock. For more refer- <a href="https://www.geeksforgeeks.org/deadlock-detection-recovery/">Deadlock Recovery</a></li>
</ul>
<p><strong>Deadlock Detection Algorithm/ <a href="https://www.geeksforgeeks.org/operating-system-bankers-algorithm/">Bankers Algorithm</a>:</strong><br/>
The algorithm employs several time varying data structures:</p>
<ul>
<li><strong>Available- </strong> A vector of length m indicates the number of available resources of each type.</li>
<li><strong>Allocation- </strong>An n*m matrix defines the number of resources of each type currently allocated to a process. Column represents resource and resource represent process.</li>
<li><strong>Request- </strong> An n*m matrix indicates the current request of each process. If request[i][j] equals k then process P<sub>i</sub> is requesting k more instances of resource type R<sub>j</sub>.</li>
</ul>
<p>We treat rows in the matrices Allocation and Request as vectors, we refer them as Allocation<sub>i</sub> and Request<sub>i</sub>.</p>
<p><strong>Steps of Algorithm:</strong></p>
<ol>
<li>Let <em>Work</em> and <em>Finish</em> be vectors of length m and n respectively. Initialize <em>Work= Available</em>. For <em>i=0, 1, …., n-1</em>, if <em>Request<sub>i</sub></em> = 0, then <em>Finish[i]</em> = true; otherwise, <em>Finish[i]</em>= false. </li>
<li>Find an index i such that both<br/>
a) <em>Finish[i] == false</em><br/>
b) <em>Request<sub>i</sub> &lt;= Work</em><br/>
If no such <em>i</em> exists go to step 4.</li>
<li><em>Work= Work+ Allocation<sub>i</sub></em><br/>
<em>Finish[i]= true</em><br/>
Go to Step 2.</li>
<li>If <em>Finish[i]== false</em> for some i, 0&lt;=i&lt;n, then the system is in a deadlocked state. Moreover, if <em>Finish[i]==false</em> the process P<sub>i</sub> is deadlocked.</li>
</ol>
<p>For example,<br/>
<img alt="allocation, request matrix" src="https://media.geeksforgeeks.org/wp-content/uploads/deadlockdetection.jpg"/></p>
<ol>
<li>
In this, Work = [0, 0, 0] &amp;<br/>
     Finish = [false, false, false, false, false]</li>
<li><em>i=0</em> is selected as both Finish[0] = false and [0, 0, 0]&lt;=[0, 0, 0].</li>
<li>Work =[0, 0, 0]+[0, 1, 0] =&gt;[0, 1, 0] &amp;<br/>
     Finish = [true, false, false, false, false]. </li>
<li><em>i=2</em> is selected as both Finish[2] = false and [0, 0, 0]&lt;=[0, 1, 0].</li>
<li>Work =[0, 1, 0]+[3, 0, 3] =&gt;[3, 1, 3] &amp;<br/>
     Finish = [true, false, true, false, false].</li>
<li><em>i=1</em> is selected as both Finish[1] = false and [2, 0, 2]&lt;=[3, 1, 3].</li>
<li>Work =[3, 1, 3]+[2, 0, 0] =&gt;[5, 1, 3] &amp;<br/>
     Finish = [true, true, true, false, false]. </li>
<li><em>i=3</em> is selected as both Finish[3] = false and [1, 0, 0]&lt;=[5, 1, 3].</li>
<li>Work =[5, 1, 3]+[2, 1, 1] =&gt;[7, 2, 4] &amp;<br/>
     Finish = [true, true, true, true, false]. </li>
<li><em>i=4</em> is selected as both Finish[4] = false and [0, 0, 2]&lt;=[7, 2, 4].</li>
<li>Work =[7, 2, 4]+[0, 0, 2] =&gt;[7, 2, 6] &amp;<br/>
     Finish = [true, true, true, true, true]. </li>
<li>Since Finish is a vector of all true it means <strong>there is no deadlock</strong> in this example.</li>
</ol>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/EduardoNodarse/">EduardoNodarse</a>, <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a>, <a href="https://auth.geeksforgeeks.org/user/rasswanthsenthil/">rasswanthsenthil</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-200920 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-os-memory-management" id="post-200920">
<header class="entry-header">
<h1 class="entry-title">Operating System | Techniques to handle Thrashing</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <a href="https://www.geeksforgeeks.org/virtual-memory-operating-systems/">Virtual Memory</a></p>
<p><strong>Thrashing</strong> is a condition or a situation when the system is spending a major portion of its time in servicing the page faults, but the actual processing done is very negligible.</p>
<p><img alt="" class="aligncenter size-full wp-image-431062" height="357" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/2-103.png" width="424"/></p>
<p>The basic concept involved is that if a process is allocated too few frames, then there will be too many and too frequent page faults. As a result, no useful work would be done by the CPU and the CPU utilisation would fall drastically. The long-term scheduler would then try to improve the CPU utilisation by loading some more processes into the memory thereby increasing the degree of multiprogramming. This would result in a further decrease in the CPU utilization triggering a chained reaction of higher page faults followed by an increase in the degree of multiprogramming, called Thrashing.</p>
<p><strong>Locality Model –</strong><br/>
A locality is a set of pages that are actively used together. The locality model states that as a process executes, it moves from one locality to another. A program is generally composed of several different localities which may overlap.</p>
<p>For example when a function is called, it defines a new locality where memory references are made to the instructions of the function call, it’s local and global variables, etc. Similarly, when the function is exited, the process leaves this locality.</p>
<p><strong>Techniques to handle:</strong></p>
<ol>
<li><strong>Working Set Model –</strong>
<p>This model is based on the above-stated concept of the Locality Model.<br/>
The basic principle states that if we allocate enough frames to a process to accommodate its current locality, it will only fault whenever it moves to some new locality. But if the allocated frames are lesser than the size of the current locality, the process is bound to thrash.</p>
<p>According to this model, based on a parameter A, the working set is defined as the set of pages in the most recent ‘A’ page references. Hence, all the actively used pages would always end up being a part of the working set.</p>
<p>The accuracy of the working set is dependant on the value of parameter A. If A is too large, then working sets may overlap. On the other hand, for smaller values of A, the locality might not be covered entirely.</p>
<p>If D is the total demand for frames and  <img alt=" WSS_i " class="ql-img-inline-formula quicklatex-auto-format" height="24" src="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ccf471ee72bb5e49981c56541148cd7d_l3.png" style="vertical-align: -4px;" title="Rendered by QuickLaTeX.com" width="68">  is the working set size for a process i,<br/>
<br/>
<img alt="  D=\sum\nolimits{ WSS_ i}  " class="ql-img-inline-formula quicklatex-auto-format" height="27" src="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d6084cea947ca09ce9810823390454f7_l3.png" style="vertical-align: 26px;" title="Rendered by QuickLaTeX.com" width="142"/></img></p>
<p>Now, if ‘m’ is the number of frames available in the memory, there are 2 possibilities:</p>
<ul>
<li>(i) D&gt;m i.e. total demand exceeds the number of frames, then thrashing will occur as some processes would not get enough frames.
</li>
<li>(ii) D&lt;=m, then there would be no thrashing.
</li>
</ul>
<p></p>
<p>If there are enough extra frames, then some more processes can be loaded in the memory. On the other hand, if the summation of working set sizes exceeds the availability of frames, then some of the processes have to be suspended(swapped out of memory).</p>
<p>This technique prevents thrashing along with ensuring the highest degree of multiprogramming possible. Thus, it optimizes CPU utilisation.</p>
</li>
<li><strong>Page Fault Frequency –</strong>
<p>A more direct approach to handle thrashing is the one that uses Page-Fault Frequency concept.</p>
<p><img alt="" class="aligncenter size-full wp-image-431035" height="357" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/1-161.png" width="456"/></p>
<p>The problem associated with Thrashing is the high page fault rate and thus, the concept here is to control the page fault rate. </p>
<p>If the page fault rate is too high, it indicates that the process has too few frames allocated to it. On the contrary, a low page fault rate indicates that the process has too many frames.</p>
<p>Upper and lower limits can be established on the desired page fault rate as shown in the diagram.<br/>
If the page fault rate falls below the lower limit, frames can be removed from the process. Similarly, if the page fault rate exceeds the upper limit, more number of frames can be allocated to the process.<br/>
In other words, the graphical state of the system should be kept limited to the rectangular region formed in the given diagram.</p>
<p>Here too, if the page fault rate is high with no free frames, then some of the processes can be suspended and frames allocated to them can be reallocated to other processes. The suspended processes can then be restarted later.
</p></li>
</ol>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-200717 post type-post status-publish format-standard hentry category-c-arrays category-heap category-operating-systems tag-os-cpu-scheduling" id="post-200717">
<header class="entry-header">
<h1 class="entry-title">Program for Preemptive Priority CPU Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Implementing priority CPU scheduling. In this problem, we are using <a href="https://www.geeksforgeeks.org/binary-heap/">Min Heap</a> as the data structure for implementing priority scheduling.<br/>
<strong>In this problem smaller numbers denote higher priority.</strong><br/>
The following functions are used in the given code below:</p>
<pre>struct process {

   processID,

   burst time,

   response time,

   priority,

   arrival time.

} </pre>
<p><strong>void quicksort(process array[], low, high)</strong>– This function is used to arrange the processes in ascending order according to their arrival time.<br/>
<strong>int partition(process array[], int low, int high)</strong>– This function is used to partition the array for sorting.<br/>
<strong>void insert(process Heap[], process value, int *heapsize, int *currentTime)</strong>– It is used to include all the valid and eligible processes in the heap for execution. heapsize defines the number of processes in execution depending on the current time currentTime keeps record of the current CPU time.<br/>
<strong>void order(process Heap[], int *heapsize, int start)</strong>– It is used to reorder the heap according to priority if the processes after insertion of new process.<br/>
<strong>void extractminimum(process Heap[], int *heapsize, int *currentTime)</strong>– This function is used to find the process with highest priority from the heap. It also reorders the heap after extracting the highest priority process.<br/>
<strong>void scheduling(process Heap[], process array[], int n, int *heapsize, int *currentTime)</strong>– This function is responsible for executing the highest priority extracted from Heap[].<br/>
<strong>void process(process array[], int n)</strong>– This function is responsible for managing the entire execution of the processes as they arrive in the CPU according to their arrival time.</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-200535 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-200535">
<header class="entry-header">
<h1 class="entry-title">Operating System | Threads and its types</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Thread is a single sequence stream within a process. Threads have same properties as of the process so they are called as light weight processes. Threads are executed one after another but gives the illusion as if they are executing in parallel. Each thread has different states. Each thread has </p>
<ol>
<li>A program counter
</li>
<li>A register set
</li>
<li>A stack space
</li>
</ol>
<p>Threads are not independent of each other as they share the code, data, OS resources etc.</p>
<p><b>Similarity between Threads and Processes –</b></p>
<ul>
<li>Only one thread or process is active at a time
</li>
<li>Within process both execute sequentiall
</li>
<li>Both can create children
</li>
</ul>
<p><b>Differences between Threads and Processes –</b></p>
<ul>
<li>Threads are not independent, processes are.
</li>
<li>Threads are designed to assist each other, processes may or may not do it
</li>
</ul>
<p><b>Types of Threads:</b></p>
<ol>
<li><b>User Level thread (ULT) –</b><br/>
Is implemented in the user level library, they are not created using the system calls. Thread switching does not need to call OS and to cause interrupt to Kernel. Kernel doesn’t know about the user level thread and manages them as if they were single-threaded processes.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-200098 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-200098">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | States of a process</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
States of a process are as following:</p>
<p><img class="aligncenter size-full" height="800" src="https://media.geeksforgeeks.org/wp-content/uploads/20190604122001/states_modified.png" width="800"/></p>
<ul>
<li><b>New (Create) –</b> In this step, the process is about to be created but not yet created, it is the program which is present in secondary memory that will be picked up by OS to create the process.
</li>
<li><b>Ready –</b> New -&gt; Ready to run. After the creation of a process, the process enters the ready state i.e. the process is loaded into the main memory. The process here is ready to run and is waiting to get the CPU time for its execution. Processes that are ready for execution by the CPU are maintained in a queue for ready processes.
</li>
<li><b>Run –</b> The process is chosen by CPU for execution and the instructions within the process are executed by any one of the available CPU cores.
</li>
<li><b>Blocked or wait –</b> Whenever the process requests access to I/O or needs input from the user or needs access to a critical region(the lock for which is already acquired) it enters the blocked or wait state. The process continues to wait in the main memory and does not require CPU. Once the I/O operation is completed the process goes to the ready state.
</li>
<li><b>Terminated or completed –</b> Process is killed as well as PCB is deleted.
</li>
<li><b>Suspend ready –</b> Process that was initially in the ready state but were swapped out of main memory(refer Virtual Memory topic) and placed onto external storage by scheduler are said to be in suspend ready state. The process will transition back to ready state whenever the process is again brought onto the main memory.
</li>
<li><b>Suspend wait or suspend blocked –</b> Similar to suspend ready but uses the process which was performing I/O operation and lack of main memory caused them to move to secondary memory.<br/>
When work is finished it may go to suspend ready.
</li>
</ul>
<p><b>CPU and IO Bound Processes:</b><br/>
If the process is intensive in terms of CPU operations then it is called CPU bound process. Similarly, If the process is intensive in terms of I/O operations then it is called IO bound process.</p>
<p><b>Types of schedulers:</b></p>
<ol>
<li><b>Long term – performance –</b> Makes a decision about how many processes should be made to stay in the ready state, this decides the degree of multiprogramming. Once a decision is taken it lasts for a long time hence called long term scheduler.
</li>
<li><b>Short term – Context switching time –</b> Short term scheduler will decide which process to be executed next and then it will call dispatcher. A dispatcher is a software that moves process from ready to run and vice versa. In other words, it is context switching.
</li>
<li><b>Medium term – Swapping time –</b> Suspension decision is taken by medium term scheduler. Medium term scheduler is used for swapping that is moving the process from main memory to secondary and vice versa.
</li>
</ol>
<p><b>Multiprogramming –</b> We have many processes ready to run. There are two types of multiprogramming:</p>
<ol>
<li><b>Pre-emption –</b> Process is forcefully removed from CPU. Pre-emption is also called as time sharing or multitasking.
</li>
<li><b>Non pre-emption –</b> Processes are not removed until they complete the execution.
</li>
</ol>
<p><b>Degree of multiprogramming –</b><br/>
The number of processes that can reside in the ready state at maximum decides the degree of multiprogramming, e.g., if the degree of programming = 100, this means 100 processes can reside in the ready state at maximum.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/kbapat/">kbapat</a>, <a href="https://auth.geeksforgeeks.org/user/nitishanon/">nitishanon</a>, <a href="https://auth.geeksforgeeks.org/user/shreyashagrawal/">shreyashagrawal</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-199307 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-199307">
<header class="entry-header">
<h1 class="entry-title">Operating System | Inverted Page Table</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , , <br/>
Most of the Operating Systems implement a separate pagetable for each process, i.e. for ‘n’ number of processes running on a Multiprocessing/ Timesharing operating system, there are ‘n’ number of pagetables stored in the memory. Sometimes when a process is very large in size and it occupies virtual memory then with the size of the process, it’s pagetable size also increases substantially.</p>
<pre><strong>Example:</strong> A process of size 2 GB with:

Page size = 512 Bytes

Size of page table entry = 4 Bytes, then

Number of pages in the process = 2 GB / 512 B = 2<sup>22</sup>

PageTable Size = 2<sup>22</sup> * 2<sup>2</sup> = 2<sup>24</sup> bytes</pre>
<p>Through this example, it can be concluded that for multiple processes running simultaneously in an OS, a considerable part of memory is occupied by page tables only.</p>
<p>Operating Systems also incorporate <strong>multilevel paging schemes</strong> which further increase the space required for storing the page tables and a large amount of memory is invested in storing them. The amount of memory occupied by the page tables can turn out to be a huge overhead and is always unacceptable as main memory is always a scarce resource. Various efforts are made to utilize the memory efficiently and to maintain a good balance in the level of multiprogramming and efficient CPU utilization.</p>
<p><strong>Inverted Page Table –</strong><br/>
An alternate approach is to use the <strong>Inverted Page Table</strong> structure that consists of one-page table entry for every frame of the main memory. So the number of page table entries in the Inverted Page Table reduces to the number of frames in physical memory and a single page table is used to represent the paging information of all the processes. </p>
<p>Through the inverted page table, the overhead of storing an individual page table for every process gets eliminated and only a fixed portion of memory is required to store the paging information of all the processes together. This technique is called as inverted paging as the indexing is done with respect to the frame number instead of the logical page number. Each entry in the page table contains the following fields.</p>
<ul>
<li><strong>Page number –</strong> It specifies the page number range of the logical address.</li>
<p></p>
<li><strong>Process id –</strong> An inverted page table contains the address space information of all the processes in execution. Since two different processes can have similar set of virtual addresses, it becomes necessary in Inverted Page Table to store a process Id of each process to identify it’s address space uniquely. This is done by using the combination of PId and Page Number. So this Process Id acts as an address space identifier and ensures that a virtual page for a particular process is mapped correctly to the corresponding physical frame.</li>
<p></p>
<li><strong>Control bits –</strong> These bits are used to store extra paging-related information. These include the valid bit, dirty bit, reference bits, protection and locking information bits.</li>
<p></p>
<li><strong>Chained pointer –</strong> It may be possible sometime that two or more processes share a part of main memory. In this case, two or more logical pages map to same Page Table Entry then a chaining pointer is used to map the details of these logical pages to the root page table.
</li>
</ul>
<p><strong>Working –</strong> The operation of an inverted page table is shown below. </p>
<p><img alt="" class="aligncenter size-full wp-image-420770" height="385" src="https://media.geeksforgeeks.org/wp-content/uploads/33-6.png" width="691"/></p>
<p>The virtual address generated by the CPU contains the fields and each page table entry contains and the other relevant information required in paging related mechanism. When a memory reference takes place, this virtual address is matched by the memory-mapping unit and the Inverted Page table is searched to match the and the corresponding frame number is obtained. If the match is found at the i<sup>th</sup> entry then the physical address of the process, <i>, is sent as the real address otherwise if no match is found then Segmentation Fault is generated.</i></p>
<p><strong>Note: Number of Entries in Inverted page table = Number of frames in Physical address Space(PAS) </strong></p>
<p><strong>Examples –</strong> The Inverted Page table and its variations are implemented in various systems like PowerPC, UltraSPARC and the IA-64 architecture. An implementation of the Mach operating system on the RT-PC also uses this technique.</p>
<p><strong>Advantages and Disadvantages:</strong></p>
<ul>
<li><strong>Reduced memory space –</strong><br/>
Inverted Pagetables typically reduces the amount of memory required to store the page tables to a size bound of physical memory. The maximum number of entries could be the number of page frames in the physical memory.</li>
<p></p>
<li><strong>Longer lookup time –</strong><br/>
Inverted Page tables are sorted in order of frame number but the memory look-up takes place with respect to the virtual address, so, it usually takes a longer time to find the appropriate entry but often these page tables are implemented using hash data structures for a faster lookup.</li>
<p></p>
<li><strong>Difficult shared memory implementation –</strong><br/>
As the Inverted Page Table stores a single entry for each frame, it becomes difficult to implement the shared memory in the page tables. Chaining techniques are used to map more than one virtual address to the entry specified in order of frame number.</li>
</ul>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-199294 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-199294">
<header class="entry-header">
<h1 class="entry-title">Operating System | Real time systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Real time system means that the system is subjected to real time, i.e., response should be guaranteed within a specified timing constraint or system should meet the specified deadline. For example: flight control system, real time monitors etc. </p>
<p>Types of real time systems based on timing constraints:</p>
<ol>
<li><b>Hard real time system –</b><br/>
This type of sytem can never miss its deadline. Missing the deadline may have disastrous consequences.The usefulness of result produced by a hard real time system decreases abruptly and may become negative if tardiness increases. Tardiness means how late a real time system completes its task with respect to its deadline. Example: Flight controller system.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-197553 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems" id="post-197553">
<header class="entry-header">
<h1 class="entry-title">Operating System | Difference between dispatcher and scheduler</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b><a href="https://www.geeksforgeeks.org/gate-notes-operating-system-scheduler/">Schedulers</a></b> are special system software which handle process scheduling in various ways. Their main task is to select the jobs to be submitted into the system and to decide which process to run. There are :</p>
<ol>
<li><b>Long term (job) scheduler –</b> Due to the smaller size of main memory initially all program are stored in secondary memory. When they are stored or loaded in the main memory they are called process. This is the decision of long term scheduler that how many processes will stay in the ready queue. Hence, in simple words, long term scheduler decides the degree of multi-programming of system.
</li>
<p></p>
<li><b>Medium term scheduler –</b> Most often, a running process needs I/O operation which doesn’t requires CPU. Hence during the execution of a process when a I/O operation is required then the operating system sends that process from running queue to blocked queue. When a process completes its I/O operation then it should again be shifted to ready queue. ALL these decisions are taken by the medium-term scheduler. Medium-term scheduling is a part of <b>swapping</b>.
</li>
<p></p>
<li><b>Short term (CPU) scheduler –</b> When there are lots of processes in main memory initially all are present in the ready queue. Among all of the process, a single process is to be selected for execution. This decision is handled by short term scheduler.
<p>Let’s have a look at the figure given below. It may make a more clear view for you.</p>
<p><img alt="" class="aligncenter size-full wp-image-409403" height="448" src="https://media.geeksforgeeks.org/wp-content/uploads/22_.png" width="726"/></p></li></ol>
<p><b>Dispatcher –</b><br/>
A dispatcher is a special program which comes into play after the scheduler. When the scheduler completes its job of selecting a process, it is the dispatcher which takes that process to the desired state/queue. The dispatcher is the module that gives a process control over the CPU after it has been selected by the short-term scheduler. This function involves the following:</p>
<ul>
<li>Switching context
</li>
<li>Switching to user mode
</li>
<li>Jumping to the proper location in the user program to restart that program
</li>
</ul>
<p></p>
<p><b>The Difference between the Scheduler and Dispatcher –</b><br/>
Consider a situation, where various processes are residing in the ready queue waiting to be executed. The CPU cannot execute all of these processes simultaneously, so the operating system has to choose a particular process on the basis of the scheduling algorithm used. So, this procedure of selecting a process among various processes is done by <b>the scheduler</b>. Once the scheduler has selected a process from the queue, the <b>dispatcher</b> comes into the picture, and it is the dispatcher who takes that process from the ready queue and moves it into the running state. Therefore, the scheduler gives the dispatcher an ordered list of processes which the dispatcher moves to the CPU over time.</p>
<p><b>Example –</b><br/>
There are 4 processes in the ready queue, P1, P2, P3, P4; Their arrival times are t0, t1, t2, t3 respectively. A First in First out (FIFO) scheduling algorithm is used. Because P1 arrived first, the scheduler will decide it is the first process that should be executed, and the dispatcher will remove P1 from the ready queue and give it to the CPU. The scheduler will then determine P2 to be the next process that should be executed, so when the dispatcher returns to the queue for a new process, it will take P2 and give it to the CPU. This continues in the same way for P3, and then P4. </p>
<p><img alt="" class="aligncenter size-full wp-image-409417" height="142" src="https://media.geeksforgeeks.org/wp-content/uploads/333.png" width="581"/></p>
<table width="100%">
<thead>
<tr>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Properties</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">DISPATCHER</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">SCHEDULER</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:LEFT">Definition:</td>
<td style="text-align:LEFT">Dispatcher is a module that gives control of CPU to the process selected by short term scheduler</td>
<td style="text-align:LEFT">Scheduler is something which selects a process among various processes</td>
</tr>
<tr>
<td>Types:</td>
<td>There are no diifrent types in dispatcher.It is just a code segment.</td>
<td>There are 3 types of scheduler i.e. Long-term, Short-term, Medium-term</td>
</tr>
<tr>
<tr>
<td style="text-align:LEFT">Dependency:</td>
<td style="text-align:LEFT">Working of dispatcher is dependednt on scheduler.Means dispatcher have to wait untill scheduler selects a process.</td>
<td style="text-align:LEFT">Scheduler works idependently.It works immediately when needed</td>
</tr>
<tr>
<td>Algorithm:</td>
<td>Dispatcher has no specific algorithm for its implementation</td>
<td>Scheduler works on various algorithm  such as FCFS, SJF, RR etc. </td>
</tr>
<tr>
<td style="text-align:LEFT">Time Taken:</td>
<td style="text-align:LEFT">The time taken by dispatcher is called dispatch latency.</td>
<td style="text-align:LEFT">TIme taken by scheduler is usually negligible.Hence we neglect it.</td>
</tr>
<tr>
<td>Functions:</td>
<td>Dispatcher is also responsible for:Context Switching, Switch to user mode, Jumping to proper location when process again restarted</td>
<td>The only work of scheduler is selection of processes.</td>
</tr>
</tr></tbody>
</table>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a>, <a href="https://auth.geeksforgeeks.org/user/BenTrono/">BenTrono</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-197393 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems" id="post-197393">
<header class="entry-header">
<h1 class="entry-title">Operating System | Secondary memory – Hard disk drive</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A hard disk is a memory storage device which looks like this:</p>
<p><img class="aligncenter size-full" height="300" src="https://media.geeksforgeeks.org/wp-content/uploads/harddisk1.jpg" width="450"/></p>
<p>The disk is divided into <b>tracks</b>. Each track is further divided into <b>sectors</b>. The point to be noted here is that outer tracks are bigger in size than the inner tracks but they contain the same number of sectors and have equal storage capacity. This is because the storage density is high in sectors of the inner tracks where as the bits are sparsely arranged in sectors of the outer tracks. Some space of every sector is used for formatting. So, the actual capacity of a sector is less than the given capacity. </p>
<p>Read-Write(R-W) head moves over the rotating hard disk. It is this Read-Write head that performs all the read and write operations on the disk and hence, position of the R-W head is a major concern. To perform a read or write operation on a memory location, we need to place the R-W head over that position. Some important terms must be noted here:</p>
<ol>
<li><strong>Seek time –</strong> The time taken by the R-W head to reach the desired track from it’s current position.
</li>
<li><strong>Rotational latency –</strong> Time taken by the sector to come under the R-W head.
</li>
<li><strong>Data transfer time –</strong> Time taken to transfer the required amount of data. It depends upon the rotational speed.
</li>
<li><strong>Controller time –</strong> The processing time taken by the controller.
</li>
<li><strong>Average Access time –</strong> seek time + Average Rotational latency + data transfer time + controller time.
</li>
</ol>
<p><strong>Note:</strong>Average Rotational latency is mostly 1/2*(Rotetional latency).</p>
<p>In questions, if the seek time and controller time is not mentioned, take them to be zero.</p>
<p>If the amount of data to be transferred is not given, assume that no data is being transferred. Otherwise, calculate the time taken to transfer the given amount of data.</p>
<p>The average of rotational latency is taken when the current position of R-W head is not given. Because, the R-W may be already present at the desired position or it might take a whole rotation to get the desired sector under the R-W head. But, if the current position of the R-W head is given then the rotational latency must be calculated.</p>
<p><strong>Example –</strong><br/>
Consider a hard disk with:<br/>
4 surfaces<br/>
64 tracks/surface<br/>
128 sectors/track<br/>
256 bytes/sector</p>
<ol>
<li>What is the capacity of the  hard disk?<br/>
Disk capacity = surfaces * tracks/surface * sectors/track * bytes/sector<br/>
Disk capacity = 4 * 64 * 128 * 256<br/>
Disk capacity = 8 MB</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-194611 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems tag-cbse-class-11 tag-school-programming" id="post-194611">
<header class="entry-header">
<h1 class="entry-title">Types of computer memory (RAM and ROM)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Memory is the most essential element of a computing system because without it computer can’t perform simple tasks. Computer memory is of two basic type – Primary memory / Volatile memory and Secondary memory / non-volatile memory. Random Access Memory (RAM) is volatile memory and Read Only Memory (ROM) is non-volatile memory.</p>
<p><img alt="" class="aligncenter size-full" height="273" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/memory.png" width="658"/></p>
<p><strong>1. Random Access Memory (RAM) –</strong></p>
<ul>
<li>It is also called as <em>read write memory</em> or the<em> main memory</em> or the <em>primary memory</em>.</li>
<li>The programs and data that the CPU requires during execution of a program are stored in this memory.</li>
<li>It is a volatile memory as the data loses when the power is turned off.</li>
<li>RAM is further classified into two types- <em>SRAM (Static Random Access Memory)</em> and <em>DRAM (Dynamic Random Access Memory)</em>.</li>
</ul>
<p><img alt="" class="aligncenter size-full" height="417" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/difference-1.png" width="623"/></p>
<p><strong>2. Read Only Memory (ROM) –</strong></p>
<ul>
<li>Stores crucial information essential to operate the system, like the program essential to boot the computer.</li>
<li>It is not volatile.</li>
<li>Always retains its data.</li>
<li>Used in embedded systems or where the programming needs no change.</li>
<li>Used in calculators and peripheral devices.</li>
<li>ROM is further classified into 4 types- <em>ROM</em>, <em>PROM</em>, <em>EPROM</em>, and <em>EEPROM</em>.
</li></ul>
<p><b>Types of Read Only Memory (ROM) –</b></p>
<ol>
<li><b>PROM (Programmable read-only memory)</b> – It can be programmed by user. Once programmed, the data and instructions in it cannot be changed.
</li>
<li><b>EPROM (Erasable Programmable read only memory)</b> – It can be reprogrammed. To erase data from it, expose it to ultra violet light. To reprogram it, erase all the previous data.
</li>
<li><b>EEPROM (Electrically erasable programmable read only memory)</b> – The data can be erased by applying electric field, no need of ultra violet light. We can erase only portions of the chip.
</li>
</ol>
<p><img alt="" class="aligncenter size-full" height="324" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/ram.png" width="593"><br/>
</img></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/Roy19/">Roy19</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-192138 post type-post status-publish format-standard hentry category-operating-systems" id="post-192138">
<header class="entry-header">
<h1 class="entry-title">Operating System | File Directory | Path Name</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – </p>
<p><strong>Hierarchical Directory Systems –</strong></p>
<p>Directory is maintained in the form of a tree. Each user can have as many directories as are needed so, that files can be grouped together in a natural way.</p>
<p>Advantages of this structure:</p>
<ul>
<li>Searching is efficient</li>
<li>Groping capability of files increase</li>
</ul>
<p>When the file system is organized as a directory tree, some way is needed for specifying file names.</p>
<p>Two different methods are commonly used:</p>
<ol>
<li><strong>Absolute Path name –</strong> In this method, each file is given an <strong>absolute path</strong> name consisting of the path from the root directory to the file. As an example, the path <strong>/usr/ast/mailbox</strong> means that the root directory contains a subdirectory usr, which in turn contains a subdirectory ast, which contains the file mailbox.
<p>Absolute path names always start at the root directory and are unique.</p>
<p>In UNIX the components of the path are separated by ‘/’. In Windows, the separator is ‘\’.<br/>
<strong>Windows</strong> \usr\ast\mailbox<br/>
<strong>UNIX</strong>  /usr/ast/mailbox</p>
</li>
<li><strong>Relative Path name –</strong> This is used in conjunction with the concept of the <strong>working directory</strong> (also called the <strong>current directory</strong>).A user can designate one directory as the current working directory, in which case all path names not beginning at the root directory are taken relative to the working directory.
<p>For <strong>example</strong>, if the current working directory is /usr/ast, then the file whose absolute path is /usr/ast/mailbox can be referenced simply as mailbox.<br/>
In other words, the UNIX<br/>
command : <strong> cp /usr/ast/mailbox /usr/ast/mailbox.bak</strong><br/>
and the command : <strong> cp mailbox mailbox.bak</strong><br/>
do exactly the same thing if the working directory is /usr/ast.
</p></li>
</ol>
<p><strong> When to use which approach? </strong><br/>
Some programs need to access a specific file without regard to what the working directory is. In that case, they should always use absolute path names. For example, a spelling checker might need to read /usr/lib/dictionary to do its work. It should use the full, absolute path name in this case because it does not know what the working directory will be when it is called. The absolute path name will always work, no matter what the working directory is.</p>
<p>Of course, if the spelling checker needs a large number of files from /usr/lib, an alternative approach is for it to issue a system call to change its working directory to /usr/lib, and then use just dictionary as the first parameter to open. By explicitly changing the working directory, it knows for sure where it is in the directory tree, so it can then use relative paths.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/magbene/">magbene</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-191827 post type-post status-publish format-standard hentry category-computer-organization-architecture category-operating-systems" id="post-191827">
<header class="entry-header">
<h1 class="entry-title">Different Types of RAM (Random Access Memory )</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>RAM(Random Access Memory) is a part of computer’s Main Memory which is directly accessible by CPU. RAM is used to Read and Write data into it which is accessed by CPU randomly. RAM is volatile in nature, it means if the power goes off, the stored information is lost. RAM is used to store the data that is currently processed by the CPU. Most of the programs and data that are modifiable are stored in RAM. </p>
<p>Integrated RAM chips are available in two form:</p>
<ol>
<li>SRAM(Static RAM)</li>
<li>DRAM(Dynamic RAM)</li>
</ol>
<p>The block diagram of RAM chip is given below.</p>
<p><img alt="" class="aligncenter size-full wp-image-373336" height="280" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/RAM.png" width="723"/></p>
<p align="center"><strong>SRAM</strong></p>
<p>The SRAM memories consist of circuits capable of retaining the stored information as long as the power is applied. That means this type of memory requires constant power. SRAM memories are used to build Cache Memory.</p>
<p><strong>SRAM Memory Cell:</strong> Static memories(SRAM) are memories that consist of circuits capable of retaining their state as long as power is on. Thus this type of memories is called volatile memories. The below figure shows a cell diagram of SRAM. A latch is formed by two inverters connected as shown in the figure. Two transistors T1 and T2 are used for connecting the latch with two bit lines. The purpose of these transistors is to act as switches that can be opened or closed under the control of the word line, which is controlled by the address decoder. When the word line is at 0-level, the transistors are turned off and the latch remains its information. For example, the cell is at state 1 if the logic value at point A is 1 and at point B is 0. This state is retained as long as the word line is not activated.<br/>
<img alt="" class="aligncenter size-full wp-image-373373" height="361" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/SRAM.png" width="543"><br/>
For <strong>Read operation</strong>, the word line is activated by the address input to the address decoder. The activated word line closes both the transistors (switches) T1 and T2. Then the bit values at points A and B can transmit to their respective bit lines. The sense/write circuit at the end of the bit lines sends the output to the processor.<br/>
For <strong>Write operation</strong>, the address provided to the decoder activates the word line to close both the switches. Then the bit value that to be written into the cell is provided through the sense/write circuit and the signals in bit lines are then stored in the cell.</img></p>
<p align="center"><strong>DRAM</strong></p>
<p>DRAM stores the binary information in the form of electric charges that applied to capacitors. The stored information on the capacitors tend to lose over a period of time and thus the capacitors must be periodically recharged to retain their usage. The main memory is generally made up of DRAM chips.</p>
<p><strong>DRAM Memory Cell:</strong> Though SRAM is very fast, but it is expensive because of its every cell requires several transistors. Relatively less expensive RAM is DRAM, due to the use of one transistor and one capacitor in each cell, as shown in the below figure., where C is the capacitor and T is the transistor. Information is stored in a DRAM cell in the form of a charge on a capacitor and this charge needs to be periodically recharged.<br/>
For storing information in this cell, transistor T is turned on and an appropriate voltage is applied to the bit line. This causes a known amount of charge to be stored in the capacitor. After the transistor is turned off, due to the property of the capacitor, it starts to discharge. Hence, the information stored in the cell can be read correctly only if it is read before the charge on the capacitors drops below some threshold value.<br/>
<img alt="" class="aligncenter size-full wp-image-373387" height="346" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/DRAM.png" width="381"/></p>
<p><strong>Types of DRAM</strong></p>
<p>There are mainly 5 types of DRAM:</p>
<ol>
<li>
<strong>Asynchronous DRAM (ADRAM):</strong> The DRAM described above is the asynchronous type DRAM. The timing of the memory device is controlled asynchronously. A specialized memory controller circuit generates the necessary control signals to control the timing. The CPU must take into account the delay in the response of the memory.
</li>
<li>
<strong>Synchronous DRAM (SDRAM):</strong> These RAM chips’ access speed is directly synchronized with the CPU’s clock. For this, the memory chips remain ready for operation when the CPU expects them to be ready. These memories operate at the CPU-memory bus without imposing wait states. SDRAM is commercially available as modules incorporating multiple SDRAM chips and forming the required capacity for the modules.
</li>
<li>
<strong>Double-Data-Rate SDRAM (DDR SDRAM):</strong> This faster version of SDRAM performs its operations on both edges of the clock signal; whereas a standard SDRAM performs its operations on the rising edge of the clock signal. Since they transfer data on both edges of the clock, the data transfer rate is doubled. To access the data at high rate, the memory cells are organized into two groups. Each group is accessed separately.
</li>
<li>
<strong>Rambus DRAM (RDRAM):</strong> The RDRAM provides a very high data transfer rate over a narrow CPU-memory bus. It uses various speedup mechanisms, like synchronous memory interface, caching inside the DRAM chips and very fast signal timing. The Rambus data bus width is 8 or 9 bits.
</li>
<li>
<strong>Cache DRAM (CDRAM):</strong> This memory is a special type DRAM memory with an on-chip cache memory (SRAM) that acts as a high-speed buffer for the main DRAM.
</li>
</ol>
<p align="center"><strong>Difference between SRAM and DRAM</strong></p>
<p>Below table lists some of the differences between SRAM and DRAM:<br/>
<img alt="" class="aligncenter size-full wp-image-373291" height="329" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/SRAM-DRAM-1.png" width="677"/></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-191506 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems category-school-programming tag-cbse-class-11 tag-school-programming" id="post-191506">
<header class="entry-header">
<h1 class="entry-title">Operating System | Types of Operating Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>An  performs all the basic tasks like managing file,process, and memory. Thus operating system acts as manager of all the resources, i.e. <strong>resource manager</strong>. Thus operating system becomes an interface between user and machine.</p>
<p><strong>Types of Operating Systems:</strong> Some of the widely used operating systems are as follows-</p>
<p><strong>1. Batch Operating System –</strong><br/>
This type of operating system does not interact with the computer directly. There is an operator which takes similar jobs having same requirement and group them into batches. It is the responsibility of operator to sort the jobs with similar needs.</p>
<p><img class="aligncenter size-full" height="307" src="https://media.geeksforgeeks.org/wp-content/uploads/BatchOS.jpeg" width="600"/></p>
<p> <strong>Advantages of Batch Operating System:</strong></p>
<ul>
<li>It is very difficult to guess or know the time required by any job to complete. Processors of the batch systems know how long the job would be when it is in queue</li>
<li>Multiple users can share the batch systems</li>
<li>The idle time for batch system is very less</li>
<li>It is easy to manage large work repeatedly in batch systems</li>
</ul>
<p> <strong>Disadvantages of Batch Operating System:</strong></p>
<ul>
<li>The computer operators should be well known with batch systems</li>
<li>Batch systems are hard to debug</li>
<li>It is sometime costly</li>
<li>The other jobs will have to wait for an unknown time if any job fails</li>
</ul>
<p><strong>Examples of Batch based Operating System:</strong> Payroll System, Bank Statements etc.</p>
<p><strong>2. Time-Sharing Operating Systems –</strong><br/>
Each task is given some time to execute, so that all the tasks work smoothly. Each user gets time of CPU as they use single system. These systems are also known as Multitasking Systems. The task can be from single user or from different users also. The time that each task gets to execute is called quantum. After this time interval is over OS switches over to next task.</p>
<p><img class="aligncenter size-full" height="313" src="https://media.geeksforgeeks.org/wp-content/uploads/Time-Share.jpeg" width="600"/></p>
<p><strong>Advantages of Time-Sharing OS: </strong></p>
<ul>
<li>Each task gets an equal opportunity</li>
<li>Less chances of duplication of software</li>
<li>CPU idle time can be reduced</li>
</ul>
<p><strong>Disadvantages of Time-Sharing OS:</strong></p>
<ul>
<li>Reliability problem</li>
<li>One must have to take care of security and integrity of user programs and data</li>
<li>Data communication problem</li>
</ul>
<p><strong>Examples of Time-Sharing OSs are:</strong> Multics, Unix etc.</p>
<p><strong>3. Distributed Operating System –</strong><br/>
These types of operating system is a recent advancement in the world of computer technology and are being widely accepted all-over the world and, that too, with a great pace. Various autonomous interconnected computers communicate each other using a shared communication network. Independent systems possess their own memory unit and CPU. These are referred as <strong>loosely coupled systems</strong> or distributed systems. These system’s processors differ in size and function. The major benefit of working with these types of operating system is that it is always possible that one user can access the files or software which are not actually present on his system but on some other system connected within this network i.e., remote access is enabled within the devices connected in that network.</p>
<p><img class="aligncenter size-full" height="535" src="https://media.geeksforgeeks.org/wp-content/uploads/Distributed.jpeg" width="620"/></p>
<p><strong>Advantages of Distributed Operating System:</strong></p>
<ul>
<li>Failure of one will not affect the other network communication, as all systems are independent from each other</li>
<li>Electronic mail increases the data exchange speed</li>
<li>Since resources are being shared, computation is highly fast and durable</li>
<li>Load on host computer reduces</li>
<li>These systems are easily scalable as many systems can be easily added to the network</li>
<li>Delay in data processing reduces</li>
</ul>
<p><strong>Disadvantages of Distributed Operating System:</strong></p>
<ul>
<li>Failure of the main network will stop the entire communication</li>
<li>To establish distributed systems the language which are used are not well defined yet</li>
<li>These types of systems are not readily available as they are very expensive. Not only that the underlying software is highly complex and not understood well yet</li>
</ul>
<p><strong>Examples of Distributed Operating System are-</strong> LOCUS etc.</p>
<p><strong>4. Network Operating System –</strong><br/>
These systems run on a server and provide the capability to manage data, users, groups, security, applications, and other networking functions. These type of operating systems allow shared access of files, printers, security, applications, and other networking functions over a small private network. One more important aspect of Network Operating Systems is that all the users are well aware of the underlying configuration, of all other users within the network, their individual connections etc. and that’s why these computers are popularly known as <strong>tightly coupled systems</strong>.</p>
<p><img class="aligncenter size-full" height="657" src="https://media.geeksforgeeks.org/wp-content/uploads/Network-OS.jpeg" width="582"/></p>
<p><strong>Advantages of Network Operating System:</strong></p>
<ul>
<li>Highly stable centralized servers</li>
<li>Security concerns are handled through servers</li>
<li>New technologies and hardware up-gradation are easily integrated to the system</li>
<li>Server access are possible remotely from different locations and types of systems</li>
</ul>
<p><strong>Disadvantages of Network Operating System:</strong></p>
<ul>
<li>Servers are costly</li>
<li>User has to depend on central location for most operations</li>
<li>Maintenance and updates are required regularly</li>
</ul>
<p><strong>Examples of Network Operating System are:</strong> Microsoft Windows Server 2003, Microsoft Windows Server 2008, UNIX, Linux, Mac OS X, Novell NetWare, and BSD etc.</p>
<p><strong>5. Real-Time Operating System –</strong><br/>
These types of OSs serves the real-time systems. The time interval required to process and respond to inputs is very small. This time interval is called <strong>response time</strong>.</p>
<p><strong>Real-time systems</strong> are used when there are time requirements are very strict like missile systems, air traffic control systems, robots etc.</p>
<p><strong>Two types of Real-Time Operating System which are as follows:</strong></p>
<ul>
<li><strong>Hard Real-Time Systems:</strong><br/>
These OSs are meant for the applications where time constraints are very strict and even the shortest possible delay is not acceptable. These systems are built for saving life like automatic parachutes or air bags which are required to be readily available in case of any accident. Virtual memory is almost never found in these systems.</li>
<li><strong>Soft Real-Time Systems:</strong><br/>
These OSs are for applications where for time-constraint is less strict.</li>
</ul>
<p><img class="aligncenter size-full" height="424" src="https://media.geeksforgeeks.org/wp-content/uploads/RTOS.jpeg" width="349"/></p>
<p><strong>Advantages of RTOS:</strong></p>
<ul>
<li><strong>Maximum Consumption:</strong> Maximum utilization of devices and system,thus more output from all the resources </li>
<li><strong>Task Shifting:</strong> Time assigned for shifting tasks in these systems are very less. For example in older systems it takes about 10 micro seconds in shifting one task to another and in latest systems it takes 3 micro seconds.</li>
<li><strong>Focus on Application:</strong> Focus on running applications and less importance to applications which are in queue.</li>
<li><strong>Real time operating system in embedded system:</strong> Since size of programs are small, RTOS can also be used in embedded systems like in transport and others.</li>
<li><strong>Error Free:</strong> These types of systems are error free.</li>
<li><strong>Memory Allocation:</strong> Memory allocation is best managed in these type of systems.</li>
</ul>
<p><strong>Disadvantages of RTOS:</strong></p>
<ul>
<li><strong>Limited Tasks:</strong> Very few tasks run at the same time and their concentration is very less on few applications to avoid errors.</li>
<li><strong>Use heavy system resources:</strong> Sometimes the system resources are not so good and they are expensive as well.</li>
<li><strong>Complex Algorithms:</strong> The algorithms are very complex and difficult for the designer to write on.</li>
<li><strong>Device driver and interrupt signals:</strong> It needs specific device drivers and interrupt signals to response earliest to interrupts.</li>
<li><strong>Thread Priority:</strong> It is not good to set thread priority as these systems are very less prone to switching tasks.</li>
<p><strong>Examples of Real-Time Operating Systems are:</strong> Scientific experiments, medical imaging systems, industrial control systems, weapon systems, robots, air traffic control systems, etc.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/nkg447/">nkg447</a>, <a href="https://auth.geeksforgeeks.org/user/Da Man/">Da Man</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-191091 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-191091">
<header class="entry-header">
<h1 class="entry-title">Operating System | Microkernel</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Kernel</strong> is the core part of an operating system which manages system resources. It also acts like a bridge between application and hardware of the computer. It is one of the first programs loaded on start-up (after the Bootloader).</p>
<p><img alt="" class="aligncenter size-full" height="193" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/kernel.jpeg" width="245"/></p>
<p><strong><u>Kernel mode and User mode of CPU operation</u></strong><br/>
(Thanks <b>Sulbha Sharma</b> for contributing this section)</p>
<p>The CPU can execute certain instruction only when it is in the kernel mode. These instruction are called privilege instruction. They allow implementation of special operation whose execution by the user program could interface with the functioning of operating system or activity of another user program. For example, instruction for managing memory protection.</p>
<ul>
<li>The operating system puts the CPU in kernel mode when it is executing in the kernel so, that kernel can execute some special operation.</li>
<li>The operating system puts the CPU in user mode when a user program is in execution so, that user program cannot interface with the operating system program.</li>
<li>User-level instruction does not require special privilege. Example are ADD,PUSH,etc.</li>
</ul>
<p><img alt="Transistion from user to kernel mode" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/box-2-1.jpg"/></p>
<p>The concept of modes can be extended beyond two, requiring more than a single mode bit CPUs that support virtualization use one of these extra bits to indicate when the virtual machine manager, VMM, is in control of the system. The VMM has more privileges than ordinary user programs, but not so many as the full kernel.</p>
<p>System calls are typically implemented in the form of software interrupts, which causes the hardware’s interrupt handler to transfer control over to an appropriate interrupt handler, which is part of the operating system, switching the mode bit to kernel mode in the process. The interrupt handler checks exactly which interrupt was generated, checks additional parameters ( generally passed through registers ) if appropriate, and then calls the appropriate kernel service routine to handle the service requested by the system call.</p>
<p>User programs’ attempts to execute illegal instructions ( privileged or non-existent instructions ), or to access forbidden memory areas, also generate software interrupts, which are trapped by the interrupt handler and control is transferred to the OS, which issues an appropriate error message, possibly dumps data to a log ( core ) file for later analysis, and then terminates the offending program.</p>
<p><strong>What is Microkernel?</strong><br/>
Microkernel is one of the classification of the kernel. Being a kernel it manages all system resources. But in a microkernel, the <strong>user services</strong> and <strong>kernel services</strong> are implemented in different address space. The user services are kept in <strong>user address space</strong>, and kernel services are kept under <strong>kernel address space</strong>, thus also reduces the size of kernel and size of operating system as well.</p>
<p><img alt="" class="aligncenter size-full" height="381" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Microkernel.jpeg" width="414"/></p>
<p>It provides minimal services of process and memory management. The communication between client program/application and services running in user address space is established through message passing, reducing the speed of execution microkernel. The Operating System <strong>remains unaffected</strong> as user services and kernel services are isolated so if any user service fails it does not affect kernel service. Thus it adds to one of the advantages in a microkernel. It is easily <strong>extendable</strong> i.e. if any new services are to be added they are added to user address space and hence requires no modification in kernel space. It is also portable, secure and reliable.</p>
<p><strong>Microkernel Architecture –</strong><br/>
Since kernel is the core part of the operating system, so it is meant for handling the most important services only. Thus in this architecture only the most important services are inside kernel and rest of the OS services are present inside system application program. Thus users are able to interact with those not-so important services within the system application. And the microkernel is solely responsible for the most important services of operating system they are named as follows:</p>
<ul>
<li>Inter process-Communication</li>
<li>Memory Management</li>
<li>CPU-Scheduling</li>
</ul>
<p><strong>Advantages of Microkernel –</strong></p>
<ul>
<li>The architecture of this kernel is small and isolated hence it can function better.</li>
<li>Expansion of the system is easier, it is simply added in the system application without disturbing the kernel. </li>
</ul>
<p><strong>Eclipse IDE</strong> is a good example of Microkernel Architecture.</p>
<p>Read next – </p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-190890 post type-post status-publish format-standard hentry category-operating-systems" id="post-190890">
<header class="entry-header">
<h1 class="entry-title">Operating System | Monolithic Kernel and key differences from Microkernel</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Apart from microkernel, <b>Monolithic Kernel</b> is another classification of Kernel. Like microkernel this one also manages system resources between application and hardware, but <strong>user services</strong> and <strong>kernel services</strong> are implemented under same address space. It increases the size of the kernel, thus increases size of operating system as well.</p>
<p>This kernel provides CPU scheduling, memory management, file management and other operating system functions through system calls. As both services are implemented under same address space, this makes operating system execution faster.</p>
<p>Below is the diagrammatic representation of Monolithic Kernel:</p>
<p><img alt="" class="aligncenter size-full" height="466" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/monolithic_kernel.jpeg" width="390"/></p>
<p>If any service fails the entire system crashes, and it is one of the drawbacks of this kernel. The entire operating system needs modification if user adds a new service. </p>
<p><strong>Advantages of Monolithic Kernel –</strong></p>
<ul>
<li>One of the major advantage of having monolithic kernel is that it provides CPU scheduling, memory management, file management and other operating system functions through system calls.</li>
<li>The other one is that it is a single large process running entirely in a single address space.</li>
<li>It is a single static binary file. Example of some Monolithic Kernel based OSs are: Unix, Linux, Open VMS, XTS-400, z/TPF.</li>
</ul>
<p><strong>Disadvantages of Monolithic Kernel –</strong></p>
<ul>
<li>One of the major disadvantage of monolithic kernel is that, if anyone service fails it leads to entire system failure.</li>
<li>If user has to add any new service. User needs to modify entire operating system.</li>
</ul>
<p><strong>Key differences between Monolithic Kernel and Microkernel –</strong></p>
<p><img alt="" class="aligncenter size-full" height="537" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Difference.jpeg" width="675"/></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-190064 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-190064">
<header class="entry-header">
<h1 class="entry-title">Operating System | Swap Space</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A computer has sufficient amount of  physical memory but most of times we need more so we swap some memory on disk. Swap space is a space on hard disk which is a substitute of physical memory. It is used as virtual memory which contains process memory image. Whenever our computer run short of physical memory it uses it’s virtual memory and stores information in memory on disk. Swap space helps the computer’s operating system in pretending that it have more RAM than it actually has. It is also called as swap file.This interchange of data between virtual memory and real memory is called as swapping and space on disk as “swap space”.</p>
<p>Virtual memory is a combination of RAM and disk space that running processes can use. <b>Swap space</b> is the <b>portion of virtual memory</b> that is on the hard disk, used when RAM is full.</p>
<p>Swap space can be useful to computer in various ways:</p>
<ul>
<li>It can be used as a single contiguous memory which reduces i/o operations to read or write a file.</li>
<li>Applications which are not used or are used less can be kept in swap file.</li>
<li>Having sufficient swap file helps the system keep some physical memory free all the time.</li>
<li>The space in physical memory which has been freed due to swap space can be used by OS for some other important tasks.</li>
</ul>
<p>In operating systems such as Windows, Linux, etc systems provide a certain amount of swap space by default which can be changed by users according to their needs. If you don’t want to use virtual memory you can easily disable it all together but in case if you run out of memory then kernel will kill some of the processes in order to create a sufficient amount of space in physical memory. So it totally depends upon user whether he wants to use swap space or not.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-189854 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-189854">
<header class="entry-header">
<h1 class="entry-title">Measure the time spent in context switch?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A <i>Context switch</i> is the time spent between two processes (i.e., bringing a waiting process into execution and sending an executing process into waiting state). This happens in multitasking.The operating system must bring the state information if waiting process into memory and save the state information of the currently running process.</p>
<p>In order to solve this problem, we would like to record the timestamps of the first and last instruction of the swapping processes.The context switch time is the difference between the two processes.</p>
<p><strong>Let’s take an example: </strong>Assume there are only two processes, P1 and P2.<br/>
P1 is executing and P2 is waiting for execution. At some point, the operating system must swap P1 and P2, let’s assume it happens at the nth instruction of P1. If t(x, k) indicates the timestamp in microseconds of the kth instruction of process x, then the context switch would take t(2, 1) – t(1, n).</p>
<p>Another issue is that swapping is governed by the scheduling algorithm of the operating system and there may be many kernel level threads which are also doing context switches. Other processes could be contending for the CPU or the kernel handling interrupts. The user does not have any control over these extraneous context switches. For instance, if at time t(1, n) the kernel decides to handle an interrupt, then the context switch time would be overstated.</p>
<p>In order to avoid these obstacles, we must construct an environment such that after P1 executes, the task scheduler immediately selects P2 to run. This may be accomplished by constructing a data channel, such as a pipe between P1 and P2.</p>
<p>That is, let’s allow P1 to be the initial sender and P2 be the receiver. Initially, P2 is blocked(sleeping) as it awaits the data token. When P1 executes, it delivers the data token over the data channel to P2 and immediately attempts to read the response token. A context switch results and the task scheduler must selects another process to run.Since P2 is now in a ready-to-run state, it is a desirable candidate to be selected by the task scheduler for execution.When P2 runs, the role of P1 and P2 are swapped. P2 is now acting as the sender and P1 as the blocked receiver.</p>
<p><strong>To summaries –</strong></p>
<ol>
<li>P2 blocks awaiting data from P1</li>
<li>P1 marks the starting time.</li>
<li>P1 sends token to P2.</li>
<li>P1 attempts to read a response token from P2. This induces a context switch.</li>
<li>P2 is scheduled and receives the token.</li>
<li>P2 sends a response token to P1.</li>
<li>P2 attempts read a response token from P1. This induces a context switch.</li>
<li>P1 is scheduled and receives the token.</li>
<li>P1 marks the end time.</li>
</ol>
<p>The key is that the delivery of a data token induces a context switch. Let Td and Tr be the time it takes to deliver and receive a data token, respectively, and let Tc be the amount of time spent in a context switch. At step 2, P1 records the timestamp of the delivery of the token, and at step 9, it records the timestamp of the response. The amount of time elapsed, T, between these events may be expressed by:</p>
<pre>

<span style="text-align:center"> T = 2 * (Td + Tc + Tr)</span>

</pre>
<p><strong>This formula arises because of the following events:</strong></p>
<ul>
<li>P1 sends the token (3)</li>
<li>CPU context switches (4)</li>
<li>P2 receives it (5)</li>
<li>P2 then sends the response token (6)</li>
<li>CPU context switches (7)</li>
<li>and finally, P1 receives it (8)</li>
</ul>
<p>GATE CS Practice Questions –</p>
<ul>
<li></li>
<li> </li>
</ul>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-187868 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-187868">
<header class="entry-header">
<h1 class="entry-title">Dual Mode operations in OS</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>An error in one program can adversely effect many processes, it might modify data of another program, or also can effect the operating system. For example, if a process stuck in infinite loop then this infinite loop could effect correct operation of other processes. So to ensure the proper execution of the operating system there are two modes of operation:</p>
<p><b>User mode –</b><br/>
When the computer system run user application like creating a text document or using any application program, then the system is in user mode. When the user application requests for a service from the operating system or an interrupt occurs or , then there there will be a transition from user to kernel mode to fulfill the requests.<br/>
<b>Note:</b> To switch from kernel mode to user mode, mode bit should be 1.</p>
<p>Given below image describes what happen interrupt occurs:<br/>
<img alt="" class="aligncenter size-full" height="300" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/dual_mode.jpeg" width="735"/></p>
<p><b>Kernel Mode –</b><br/>
When system boots then hardware starts in kernel mode and when operating system is loaded then it start user application in user mode. To provide protection to the hardware, we have privileged instructions which execute only in kernel mode. If user attempt to run privileged instruction in user mode then it will treat instruction as illegal and traps to OS. Some of the privileged instructions are:</p>
<ol>
<li>Handling Interrupts</li>
<li>To switch from user mode to kernel mode.</li>
<li>Input Output management.</li>
</ol>
<p><b>Note:</b> To switch from user mode to kernel mode mode bit should be 0.</p>
<p>Read next – </p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-184303 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems category-technical-scripter" id="post-184303">
<header class="entry-header">
<h1 class="entry-title">Allocating kernel memory (buddy system and slab system)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – </p>
<p>Two strategies for managing free memory that is assigned to kernel processes:</p>
<h3>1. Buddy system –</h3>
<p>Buddy allocation system is an algorithm in which a larger memory block is divided into small parts to satisfy the request. This algorithm is used to give best fit. The two smaller parts of block are of equal size and called as buddies. In the same manner one of the two buddies will further divide into smaller parts until the request is fulfilled. Benefit of this technique is that the two buddies can combine to form the block of larger size according to the memory request.<br/>
<i>Example –</i> If the request of 25Kb is made then block of size 32Kb is allocated.</p>
<p><img alt="" class="aligncenter size-full" height="600" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/bud-1.jpg" width="800"/></p>
<p><b>Four Types of Buddy System –</b></p>
<ol>
<li>Binary buddy system</li>
<li>Fibonacci buddy system</li>
<li>Weighted buddy system</li>
<li>Tertiary buddy system</li>
</ol>
<p><b> Why buddy system?</b><br/>
If the  partition size and procees size are different then poor match occurs and may use space inefficiently.<br/>
It is easy to implement and efficient then dynamic allocation.</p>
<p><b>Binary buddy system –</b><br/>
The buddy system maintains a list of the free blocks of each size (called a free list), so that it is easy to find ablock of the desired size, if one is available. If no block of the requested size is available, Allocate searches for the first nonempty list for blocks of atleast the size requested. In either case, a block is removed from the free list.</p>
<p><b>Example –</b> Assume the size of memory segment is initially 256kb and the kernel rquests 25kb of memory. The segment is initially divided into two buddies. Let we call A1 and A2 each 128kb in size. One of these buddies is further divided into two 64kb buddies let say B1 and B2. But the next highest power of 25kb is 32kb so, either B1 or B2 is further divided into two 32kb buddies(C1 and C2) and finally one of these buddies is used to satisfy the 25kb request. A split block can only be merged with its unique buddy block, which then reforms the larger block they were split from.</p>
<p><b>Fibonacci buddy system –</b><br/>
This is the system in which blocks are divided into sizes which are fibonacci numbers. It satisfy the following relation:</p>
<pre>  Z<sub>i</sub> = Z<sub>(i-1)</sub>+Z<sub>(i-2)</sub></pre>
<p>0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 144, 233, 377, 610. The address calculation for the binary and weighted buddy systems is straight forward, but the original procedure for the Fibonacci buddy system was either limited to a small, fixed number of block sizes or a time consuming computation.</p>
<p><b>Advantages –</b></p>
<ul>
<li>In comparison to other simpler techniques such as dynamic allocation, the buddy memory system has little external fragmentation.</li>
<li>The buddy memory allocation system is implemented with the use of a binary tree to represent used or unused split memory blocks.</li>
<li>The buddy system is very fast to allocate or deallocate memory.</li>
<li>In buddy systems, the cost to allocate and free a block of memory is low compared to that of best-fit or first-fit algorithms. </li>
<li>Other advantage is coalescing.</li>
<li>Address calculation is easy.</li>
</ul>
<p><b>What is coalescing?</b><br/>
It is defined as how quickly adjacent buddies can be combined to form larger segments this is known as coalescing.<br/>
For example, when the kernel releases the C1 unit it was allocated, the system can coalesce C1 and C2 into a 64kb segment. This segment B1 can in turn be coalesced with its buddy B2 to form a 128kb segment. Ultimately we can end up with the original 256kb segment.</p>
<p><b>Drawback –</b><br/>
The main drawback in buddy system is internal fragmentation as larger block of memory is acquired then required. For example if a 36 kb request is made then it can only be satisfied by 64 kb segment and reamining memory is wasted.</p>
<h3>2. Slab Allocation –</h3>
<p>A second strategy for allocating kernel memory is known as slab allocation. It eliminates fragmentation caused by allocations and deallocations. This method is  used to retain allocated memory that contains a data object of a certain type for reuse upon subsequent allocations of objects of the same type. In slab allocation  memory chunks suitable to fit data objects of certain type or size are preallocated. Cache does not free the space immediately after use although it keeps track of data which are required frequently so that whenever request is made the data will reach very fast. Two terms required are:</p>
<ul>
<li><b>Slab –</b> A slab is made up of one or more physically contiguous pages.  The slab is the actual container of data associated with objects of the specific kind of the containing cache.</li>
<li><b>Cache –</b> Cache represents a small amount of very fast memory. A cache consists of one or more slabs. There is a single cache for each unique kernel data structure.</li>
</ul>
<p><img alt="12" class="aligncenter size-full wp-image-184308" height="429" sizes="(max-width: 583px) 100vw, 583px" src="https://www.geeksforgeeks.org/wp-content/uploads/12-3.jpg" srcset="https://www.geeksforgeeks.org/wp-content/uploads/12-3.jpg 583w, https://www.geeksforgeeks.org/wp-content/uploads/12-3-300x221.jpg 300w" width="583"/></p>
<p><b>Example –</b></p>
<ul>
<li>A separate cache for a data structure representing processes descriptors</li>
<li>Separate cache for file objects</li>
<li>Separate cache for semaphores etc.</li>
</ul>
<p>Each cache is populated with objects that are instantiations of the kernel data structure the cache represents. For example the cache representing semaphores stores instances of semaphore objects, the cache representing process descriptors stores instances of process descriptor objects.</p>
<p><b> Implementation –</b><br/>
The slab allocation algorithm uses caches to store kernel objects. When a cache is created a number of objects which are initially marked as free are allocated to the cache. The number of objects in the cache depends on size of the associated slab.<br/>
<i>Example –</i> A 12 kb slab (made up of three contiguous 4 kb pages) could store six 2 kb objects. Initially all objects in the cache are marked as free. When a new object for a kernel data structure is needed, the allocator can assign any free object from the cache to satisfy the request. The object assigned from the cache is marked as used.</p>
<p>In linux, a slab may in one of three possible states:</p>
<ol>
<li><b>Full –</b> All objects in the slab are marked as used</li>
<li><b>Empty –</b> All objects in the slab are marked as free</li>
<li><b>Partial –</b> The slab consists of both</li>
</ol>
<p>The slab allocator first attempts to satisfy the request with a free object in a partial slab. If none exists, a free object is assigned from an empty slab. If no empty slabs are available, a new slab is allocated from contiguous physical pages and assigned to a cache.</p>
<p><b>Benefits of slab allocator –</b></p>
<ul>
<li>No memory is wasted due to fragmentation because each unique kernel data structure has an associated cache.</li>
<li>Memory request can be satisfied quickly. </li>
<li>The slab allocating scheme is particularly effective for managing when objects are frequently allocated or deallocated. The act of allocating and releasing memory can be a time consuming process. However, objects are created in advance and thus can be quickly allocated from the cache. When the kernel has finished with an object and releases it, it is marked as free and return to its cache, thus making it immediately available for subsequent request from the kernel.</li>
</ul>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-183831 post type-post status-publish format-standard hentry category-operating-systems tag-os-cpu-scheduling" id="post-183831">
<header class="entry-header">
<h1 class="entry-title">Operating System | Selfish Round Robin Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – </p>
<p>In the traditional Round Robin scheduling algorithm all processes were treated equally for processing. The objective of the <strong>Selfish Round Robin</strong> is to give better service to processes that have been executing for a while than to newcomers. Its a more logical and superior implementation compared to the normal Round Robin algorithm.<br/>
<strong></strong><br/>
<strong>Implimentation :-</strong></p>
<ul>
<li>Processes in the ready list are partitioned into two lists: NEW and ACCEPTED.</li>
<li>The New processes wait while Accepted processes are serviced by the Round Robin.</li>
<li>Priority of a new process increases at rate ‘a’ while the priority of an accepted process increases at rate ‘b’.</li>
<li>When the priority of a new process reaches the priority of an accepted process, that new process becomes accepted.</li>
<li>If all accepted processes finish, the highest priority new process is accepted.</li>
</ul>
<p>Let’s trace out the general working of this algorithm :-</p>
<p><strong>STEP 1 : </strong>Assume that initially there are no ready processes, when the first one, A, arrives. It has priority 0 to begin with. Since there are no other accepted processes, A is accepted immediately.<br/>
<strong>STEP 2 : </strong>After a while another process, B, arrives. As long as b / a &lt; 1, B’s priority will eventually catch up to A’s, so it is accepted; now both A and B have the same priority.<br/>
<strong>STEP 3 : </strong>All accepted processes share a common priority (which rises at rate b ); that makes this policy easy to implement i.e any new process’s priority is bound to get accepted at some point. So no process has to experience starvation.<br/>
<strong>STEP 4 : </strong>Even if b / a &gt; 1, A will eventually finish, and then B can be accepted.</p>
<pre><strong>Adjusting the parameters a and b :</strong> 

          -&gt; If b / a &gt;= 1, a new process is not accepted 

                 until all the accepted processes have finished, so SRR becomes FCFS. 

          -&gt; If b / a = 0, all processes are accepted immediately, so SRR becomes RR. 

          -&gt; If 0 &lt; b / a &lt; 1, accepted processes are selfish, but not completely.

</pre>
<p><strong>Example on Selfish Round Robin –</strong></p>
<p><img alt="1" class="aligncenter size-full wp-image-183837" height="120" sizes="(max-width: 473px) 100vw, 473px" src="https://www.geeksforgeeks.org/wp-content/uploads/1-10.jpg" srcset="https://www.geeksforgeeks.org/wp-content/uploads/1-10.jpg 473w, https://www.geeksforgeeks.org/wp-content/uploads/1-10-300x76.jpg 300w" width="473"><br/>
<strong>Solution (where a = 2 and b = 1) – </strong></img></p>
<p><img alt="2" class="aligncenter size-full wp-image-183838" height="232" sizes="(max-width: 581px) 100vw, 581px" src="https://www.geeksforgeeks.org/wp-content/uploads/2-12.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/2-12.png 581w, https://www.geeksforgeeks.org/wp-content/uploads/2-12-300x120.png 300w" width="581"/></p>
<p><strong>Explanation –</strong></p>
<p>Process A gets accepted as soon as it comes at time t = 0. So its priority is increased only by ‘b’ i.e ‘1’ after each second. B enters at time t = 1 and goes to the waiting queue. So its priority gets increased by ‘a’ i.e. ‘2’ at time t = 2. At this point priority of A = priority of B = 2. </p>
<p>So now both process A &amp; B are in the accepted queue and are executed in a round robin fashion. At time t = 3 process C enters the waiting queue. At time t = 6 the priority of process C catches up to the priority of process B and then they start executing in a Round Robin manner. When B finishes execution at time t = 10, D is automatically promoted to the accepted queue. </p>
<p>Similarly  when D finishes execution at time t = 15, E is automatically promoted to the accepted queue.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-173233 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-cbse-class-11 tag-school-programming" id="post-173233">
<header class="entry-header">
<h1 class="entry-title">Operating System | Introduction of Operating System – Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>An operating system acts as an intermediary between the user of a computer and computer hardware. The purpose of an operating system is to provide an environment in which a user can execute programs in a convenient and efficient manner.</p>
<p>An operating system is a software that manages the computer hardware. The hardware must provide appropriate mechanisms to ensure the correct operation of the computer system and to prevent user programs from interfering with the proper operation of the system.</p>
<p><b>Operating System –</b> Definition:</p>
<ul>
<li>An operating system is a program that controls the execution of application programs and acts as an interface between the user of a computer and the computer hardware.</li>
<li>A more common definition is that the operating system is the one program running at all times on the computer (usually called the kernel), with all else being application programs.</li>
<li>An operating system is concerned with the allocation of resources and services, such as memory, processors, devices, and information. The operating system correspondingly includes programs to manage these resources, such as a traffic controller, a scheduler, memory management module, I/O programs, and a file system.</li>
</ul>
<p><b>Functions of Operating system –</b> Operating system performs three functions:</p>
<ol>
<li><b>Convenience:</b> An OS makes a computer more convenient to use.</li>
<li><b>Efficiency:</b> An OS allows the computer system resources to be used in an efficient manner.</li>
<li><b>Ability to Evolve:</b> An OS should be constructed in such a way as to permit the effective development, testing and introduction of new system functions without at the same time interfering with service.</li>
</ol>
<p>Operating system as User Interface –</p>
<ol>
<li>User</li>
<li>System and application programs</li>
<li>Operating system</li>
<li>Hardware</li>
</ol>
<p>Every general purpose computer consists of the hardware, operating system, system programs, and application programs. The hardware consists of memory, CPU, ALU, and I/O devices, peripheral device, and storage device. System program consists of compilers, loaders, editors, OS, etc. The application program consists of business programs, database programs.</p>
<p><img alt="" class="aligncenter size-full wp-image-302885" height="384" src="https://media.geeksforgeeks.org/wp-content/uploads/os.png" width="512"><br/>
Fig1: Conceptual view of a computer system</img></p>
<p>Every computer must have an operating system to run other programs. The operating system coordinates the use of the hardware among the various system programs and application programs for various users. It simply provides an environment within which other programs can do useful work.</p>
<p>The operating system is a set of special programs that run on a computer system that allows it to work properly. It performs basic tasks such as recognizing input from the keyboard, keeping track of files and directories on the disk, sending output to the display screen and controlling peripheral devices.<br/>
OS is designed to serve two basic purposes:</p>
<ol>
<li>It controls the allocation and use of the computing System’s resources among the various user and tasks.</li>
<li>It provides an interface between the computer hardware and the programmer that simplifies and makes feasible for coding, creation, debugging of application programs.</li>
</ol>
<p>The Operating system must support the following tasks. The task are:</p>
<ol>
<li>Provides the facilities to create, modification of programs and data files using an editor.</li>
<li>Access to the compiler for translating the user program from high level language to machine language.</li>
<li>Provide a loader program to move the compiled program code to the computer’s memory for execution.</li>
<li>Provide routines that handle the details of I/O programming.</li>
</ol>
<p><b>I/O System Management –</b><br/>
The module that keeps track of the status of devices is called the I/O traffic controller. Each I/O device has a device handler that resides in a separate process associated with that device.<br/>
The I/O subsystem consists of</p>
<ul>
<li>A memory Management component that includes buffering caching and spooling.</li>
<li>A general device driver interface.</li>
</ul>
<p>Drivers for specific hardware devices.</p>
<p><b>Assembler –</b><br/>
The input to an assembler is an assembly language program. The output is an object program plus information that enables the loader to prepare the object program for execution. At one time, the computer programmer had at his disposal a basic machine that interpreted, through hardware, certain fundamental instructions. He would program this computer by writing a series of ones and Zeros (Machine language), place them into the memory of the machine.</p>
<p><b>Compiler –</b><br/>
 The High-level languages- examples are FORTRAN, COBOL, ALGOL and PL/I are processed by compilers and interpreters. A compiler is a program that accepts a source program in a “high-level language “and produces a corresponding object program. An interpreter is a program that appears to execute a source program as if it was machine language. The same name (FORTRAN, COBOL, etc.) is often used to designate both a compiler and its associated language.</p>
<p><b>Loader –</b><br/>
A Loader is a routine that loads an object program and prepares it for execution. There are various loading schemes: absolute, relocating and direct-linking. In general, the loader must load, relocate and link the object program. The loader is a program that places programs into memory and prepares them for execution. In a simple loading scheme, the assembler outputs the machine language translation of a program on a secondary device and a loader is places in core. The loader places into memory the machine language version of the user’s program and transfers control to it. Since the loader program is much smaller than the assembler, those make more core available to the user’s program.</p>
<p><b>History of Operating system –</b><br/>
 Operating system has been evolving through the years. Following Table shows the history of OS.</p>
<table>
<tr>
<th>Generation</th>
<th>Year</th>
<th>Electronic device used</th>
<th>Types of OS Device</th>
</tr>
<tr>
<td>First</td>
<td>1945-55</td>
<td>Vaccum Tubes</td>
<td>Plug Boards</td>
</tr>
<tr>
<td>Secondt</td>
<td>1955-65</td>
<td>Transistors</td>
<td>Batch Systems</td>
</tr>
<tr>
<td>Third</td>
<td>1965-80</td>
<td>Integerated Circuits(IC)</td>
<td>Multiprogramming</td>
</tr>
<tr>
<td>Fourth</td>
<td>Since 1980</td>
<td>Large Scale Integration</td>
<td>PC</td>
</tr>
</table>
<p><b><a href="https://www.geeksforgeeks.org/operating-system-types-operating-systems-awaiting-author/">Types of Operating System</a> –</b></p>
<ul>
<li>Batch Operating System- Sequence of jobs in a program on a computer without manual interventions.</li>
<li>Time sharing operating System- allows many users to share the computer resources.(Max utilization of the resources).</li>
<li>Distributed operating System- Manages a group of different computers and make appear to be a single computer.</li>
<li>Network operating system- computers running in different operating system can participate in common network (It is used for security purpose).</li>
<li>Real time operating system – meant applications to fix the deadlines.</li>
</ul>
<p>Examples of Operating System are –</p>
<ul>
<li>Windows (GUI based, PC)</li>
<li>GNU/Linux (Personal, Workstations, ISP, File and print server, Three-tier client/Server)</li>
<li>macOS (Macintosh), used for Apple’s personal computers and work stations (MacBook, iMac).</li>
<li>Android (Google’s Operating System for smartphones/tablets/smartwatches)</li>
<li>iOS (Apple’s OS for iPhone, iPad and iPod Touch) </li>
</ul>
<p>
<b>References –</b><br/>
<br/>
</p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div><p>This article is contributed by <strong>Aluka Madhavi</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/hemanthhemanth/">hemanthhemanth</a>, <a href="https://auth.geeksforgeeks.org/user/rajatgupta1998/">rajatgupta1998</a>, <a href="https://auth.geeksforgeeks.org/user/AdityaRakhecha/">AdityaRakhecha</a>, <a href="https://auth.geeksforgeeks.org/user/ayushgangwar/">ayushgangwar</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-173222 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems category-technical-scripter" id="post-173222">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process-based and Thread-based Multitasking</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
A <strong>multitasking operating system</strong> is an operating system that gives you the perception of 2 or more tasks/jobs/processes running at the same time. It does this by dividing system resources amongst these tasks/jobs/processes and switching between the tasks/jobs/processes while they are executing over and over again. Usually CPU processes only one task at a time but the switching is so fast that it looks like CPU is executing multiple processes at a time. They can support either <b>preemptive</b> multitasking, where the OS doles out time to applications (virtually all modern OSes) or <b>cooperative</b> multitasking, where the OS waits for the program to give back control (Windows 3.x, Mac OS 9 and earlier), leading to hangs and crashes. Also known as <strong>Timesharing</strong>, multitasking is a logical extension of multiprogramming.</p>
<p><strong>Multitasking programming is of two types –</strong></p>
<ol>
<li>Process-based Multitasking </li>
<li>Thread-based Multitasking.</li>
</ol>
<p><strong>Process Based Multitasking Programming –</strong></p>
<ul>
<li>In process based multitasking two or more processes and programs can be run concurrently.</li>
<li>In process based multitasking a process or a program is the smallest unit.</li>
<li>Program is a bigger unit.</li>
<li>Process based multitasking requires more overhead.</li>
<li>Process requires its own address space.</li>
<li>Process to Process communication is expensive.</li>
<li>Here, it is unable to gain access over idle time of CPU.</li>
<li>It is comparatively heavy weight.</li>
<li>It has slower data rate multi-tasking.</li>
</ul>
<p><strong>Example –</strong> We can listen to music and browse internet at the same time. The processes in this example are the music player and browser.</p>
<p><strong>Thread Based Multitasking Programming –</strong></p>
<ul>
<li>In thread based multitasking two or more threads can be run concurrently.</li>
<li>In thread based multitasking a thread is the smallest unit.</li>
<li>Thread is a smaller unit.</li>
<li>Thread based multitasking requires less overhead.</li>
<li>Threads share same address space.</li>
<li>Thread to Thread communication is not expensive.</li>
<li>It allows taking gain access over idle time taken by CPU.</li>
<li>It is comparatively light weight.</li>
<li>It has faster data rate multi-tasking.</li>
</ul>
<p><strong>Examples –</strong> Using a browser we can navigate through the webpage and at the same time download a file. In this example, navigation is one thread and downloading is another thread. Also in a word-processing application like MS Word, we can type text in one thread and spell checker checks for mistakes in another thread.</p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-172498 post type-post status-publish format-standard hentry category-difference-between category-gate-cs category-operating-systems" id="post-172498">
<header class="entry-header">
<h1 class="entry-title">Operating System | Difference between multitasking, multithreading and multiprocessing</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<ol>
<li><b>Multiprogramming –</b> A computer running more than one program at a time (like running Excel and Firefox simultaneously).</li>
<li><b>Multiprocessing –</b> A computer using more than one CPU at a time.</li>
<li><b>Multitasking –</b> Tasks sharing a common resource (like 1 CPU).</li>
<li><b>Multithreading</b> is an extension of multitasking.</li>
</ol>
<h3><strong>1. Multi programming –</strong></h3>
<p>In a modern computing system, there are usually several concurrent application processes which want to execute. Now it is the responsibility of the Operating System to manage all the processes effectively and efficiently.<br/>
One of the most important aspects of an Operating System is to multi program.<br/>
In a computer system, there are multiple processes waiting to be executed, i.e. they are waiting when the CPU will be allocated to them and they begin their execution. These processes are also known as jobs. Now the main memory is too small to accommodate all of these processes or jobs into it. Thus, these processes are initially kept in an area called job pool. This job pool consists of all those processes awaiting allocation of main memory and CPU.<br/>
CPU selects one job out of all these waiting jobs, brings it from the job pool to main memory and starts executing it. The processor executes one job until it is interrupted by some external factor or it goes for an I/O task.</p>
<p><strong>Non-multi programmed system’s working –</strong></p>
<ul>
<li>In a non multi programmed system, As soon as one job leaves the CPU and goes for some other task (say I/O ), the CPU becomes idle. The CPU keeps waiting and waiting until this job (which was executing earlier) comes back and resumes its execution with the CPU. So CPU remains free for all this while.</li>
<li>Now it has a drawback that the CPU remains idle for a very long period of time. Also, other jobs which are waiting to be executed might not get a chance to execute because the CPU is still allocated to the earlier job.<br/>
This poses a very serious problem that even though other jobs are ready to execute, CPU is not allocated to them as the CPU is allocated to a job which is not even utilizing it (as it is busy in I/O tasks).</li>
<li>It cannot happen that one job is using the CPU for say 1 hour while the others have been waiting in the queue for 5 hours. To avoid situations like this and come up with efficient utilization of CPU, the concept of multi programming came up.</li>
</ul>
<p>The main idea of multi programming is to maximize the CPU time.<br/>
<strong>Multi programmed system’s working –</strong></p>
<ul>
<li>In a multi-programmed system, as soon as one job goes for an I/O task, the Operating System interrupts that job, chooses another job from the job pool (waiting queue), gives CPU to this new job and starts its execution. The previous job keeps doing its I/O operation while this new job does CPU bound tasks. Now say the second job also goes for an I/O task, the CPU chooses a third job and starts executing it. As soon as a job completes its I/O operation and comes back for CPU tasks, the CPU is allocated to it.</li>
<li>In this way, no CPU time is wasted by the system waiting for the I/O task to be completed.<br/>
Therefore, the ultimate goal of multi programming is to keep the CPU busy as long as there are processes ready to execute. This way, multiple programs can be executed on a single processor by executing a part of a program at one time, a part of another program after this, then a part of another program and so on, hence executing multiple programs. Hence, the CPU never remains idle.</li>
</ul>
<p>In the image below, program A runs for some time and then goes to waiting state. In the mean time program B begins its execution. So the CPU does not waste its resources and gives program B an opportunity to run.</p>
<p><img class="aligncenter size-full" height="573" src="https://www.geeksforgeeks.org/wp-content/uploads/multiprogramming.jpg" width="1360"/></p>
<h3><strong>2. Multiprocessing –</strong></h3>
<p>In a uni-processor system, only one process executes at a time.<br/>
Multiprocessing is the use of two or more CPUs (processors) within a single Computer system. The term also refers to the ability of a system to support more than one processor within a single computer system. Now since there are multiple processors available, multiple processes can be executed at a time. These multi processors share the computer bus, sometimes the clock, memory and peripheral devices also.</p>
<p><strong>Multi processing system’s working –</strong></p>
<ul>
<li>With the help of multiprocessing, many processes can be executed simultaneously. Say processes P1, P2, P3 and P4 are waiting for execution. Now in a single processor system, firstly one process will execute, then the other, then the other and so on.</li>
<li>But with multiprocessing, each process can be assigned to a different processor for its execution. If its a dual-core processor (2 processors), two processes can be executed simultaneously and thus will be two times faster, similarly a quad core processor will be four times as fast as a single processor. </li>
</ul>
<p><strong>Why use multi processing –</strong></p>
<ul>
<li>The main advantage of multiprocessor system is to get more work done in a shorter period of time. These types of systems are used when very high speed is required to process a large volume of data. Multi processing  systems can save money in comparison to single processor systems because the processors can share peripherals and power supplies.</li>
<li>It also provides increased reliability in the sense that if one processor fails, the work does not halt, it only slows down. e.g. if we have 10 processors and 1 fails, then the work does not halt, rather the remaining 9 processors can share the work of the 10th processor.  Thus the whole system runs only 10 percent slower, rather than failing altogether.</li>
</ul>
<p><img class="aligncenter size-full" height="573" src="https://www.geeksforgeeks.org/wp-content/uploads/multiPROCESSINGjpg.jpg" width="1360"/></p>
<p>Multiprocessing refers to the hardware (i.e., the CPU units) rather than the software (i.e., running processes). If the underlying hardware provides more than one processor then that is multiprocessing. It is the ability of the system to leverage multiple processors’ computing power.</p>
<p><strong>Difference between Multi programming and Multi processing –</strong></p>
<ul>
<li>A System can be both multi programmed by having multiple programs running at the same time and multiprocessing by having more than one physical processor.  The difference between multiprocessing and multi programming is that Multiprocessing is basically executing multiple processes at the same time on multiple processors, whereas multi programming is keeping several programs in main memory and executing them concurrently using a single CPU only.</li>
<li>Multiprocessing occurs by means of parallel processing whereas Multi programming occurs by switching from one process to other (phenomenon called as context switching).</li>
</ul>
<h3><strong>3. Multitasking –</strong></h3>
<p>As the name itself suggests, multi tasking refers to execution of multiple tasks (say processes, programs, threads etc.) at a time. In the modern operating systems, we are able to play MP3 music, edit documents in Microsoft Word, surf the Google Chrome all simultaneously, this is accomplished by means of multi tasking.</p>
<p>Multitasking is a logical extension of multi programming. The major way in which multitasking differs from multi programming is that multi programming works solely on the concept of context switching whereas multitasking is based on time sharing alongside the concept of context switching.</p>
<p><strong>Multi tasking system’s working –</strong></p>
<ul>
<li>In a time sharing system, each process is assigned some specific quantum of time for which a process is meant to execute. Say there are 4 processes P1, P2, P3, P4 ready to execute. So each of them are assigned some time quantum for which they will execute e.g time quantum of 5 nanoseconds (5 ns). As one process begins execution (say P2), it executes for that quantum of time (5 ns). After 5 ns the CPU starts the execution of the other process (say P3) for the specified quantum of time.</li>
<li>Thus the CPU makes the processes to share time slices between them and execute accordingly. As soon as time quantum of one process expires, another process begins its execution. </li>
<li>Here also basically a context switch is occurring but it is occurring so fast that the user is able to interact with each program separately while it is running. This way, the user is given the illusion that multiple processes/ tasks are executing simultaneously. But actually only one process/ task is executing at a particular instant of time. In multitasking, time sharing is best manifested because each running process takes only a fair quantum of the CPU time.</li>
</ul>
<p>In a more general sense, multitasking refers to having multiple programs, processes, tasks, threads running at the same time. This term is used in modern operating systems when multiple tasks share a common processing resource (e.g., CPU and Memory).</p>
<p><img class="aligncenter size-full" height="600" src="https://www.geeksforgeeks.org/wp-content/uploads/multitasking.jpg" width="1360"/></p>
<ul>
<li>As depicted in the above image, At any time the CPU is executing only one task while other tasks are waiting for their turn. The illusion of parallelism is achieved when the CPU is reassigned to another task. i.e all the three tasks A, B and C are appearing to occur simultaneously because of time sharing. </li>
<li>So for multitasking to take place, firstly there should be multiprogramming i.e. presence of multiple programs ready for execution. And secondly the concept of time sharing.</li>
</ul>
<h3><strong>4. Multi threading –</strong></h3>
<p>A thread is a basic unit of CPU utilization. Multi threading is an execution model that allows a single process to have multiple code segments (i.e., threads) running concurrently within the “context” of that process.<br/>
e.g. VLC media player, where one thread is used for opening the VLC media player, one thread for playing a particular song and another thread for adding new songs to the playlist.</p>
<p>Multi threading is the ability of a process to manage its use by more than one user at a time and to manage multiple requests by the same user without having to have multiple copies of the program.</p>
<p><strong>Multi threading system’s working –</strong></p>
<p><strong>Example 1 –</strong></p>
<ul>
<li>Say there is a web server which processes client requests. Now if it executes as a single threaded process, then it will not be able to process multiple requests at a time. Firstly one client will make its request and finish its execution and only then, the server will be able to process another client request. This is really costly, time consuming and tiring task. To avoid this, multi threading can be made use of.</li>
<li>Now, whenever a new client request comes in, the web server simply creates a new thread for processing this request and resumes its execution to hear more client requests. So the web server has the task of listening to new client requests and creating threads for each individual request. Each newly created thread processes one client request, thus reducing the burden on web server.</li>
</ul>
<p><strong>Example 2 –</strong></p>
<ul>
<li>We can think of threads as child processes that share the parent process resources but execute independently. Now take the case of a GUI. Say we are performing a calculation on the GUI (which is taking very long time to finish). Now we can not interact with the rest of the GUI until this command finishes its execution. To be able to interact with the rest of the GUI, this command of calculation should be assigned to a separate thread. So at this point of time, 2 threads will be executing i.e. one for calculation, and one for the rest of the GUI. Hence here in a single process, we used multiple threads for multiple functionality.</li>
</ul>
<p>The image below completely describes the VLC player example:</p>
<p><img class="aligncenter size-full" height="600" src="https://www.geeksforgeeks.org/wp-content/uploads/vlc.jpg" width="1360"/></p>
<p><strong>Advantages of Multi threading –</strong></p>
<ul>
<li>Benefits of Multi threading include increased responsiveness. Since there are multiple threads in a program, so if one thread is taking too long to execute or if it gets blocked, the rest of the threads keep executing without any problem. Thus the whole program remains responsive to the user by means of remaining threads.</li>
<li>Another advantage of multi threading is that it is less costly. Creating brand new processes and allocating resources is a time consuming task, but since threads share resources of the parent process, creating threads and switching between them is comparatively easy. Hence multi threading is the need of modern Operating Systems.</li>
</ul>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/Darshan L./">Darshan L.</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-172315 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-172315">
<header class="entry-header">
<h1 class="entry-title">Operating System | Reader-Writers solution using Monitors</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , , <br/>
Considering a shared Database our objectives are:</p>
<ul>
<li>Readers can access database only when there are no writers.</li>
<li>Writers can access database only when there are no readers or writers.</li>
<li>Only one thread can manipulate the state variables at a time.</li>
</ul>
<p><strong>Basic structure of a solution –</strong></p>
<pre>

<strong>Reader()</strong>

   Wait until no writers

   Access database

   Check out – wake up a waiting writer

<strong>Writer()</strong>

   Wait until no active readers or writers

   Access database

   Check out – wake up waiting readers or writer

</pre>
<p>–Now let’s suppose that a writer is active and a mixture of readers and writers now show up.<br/>
<strong>Who should get in next?</strong><br/>
–Or suppose that a writer is waiting and an endless of stream of readers keep showing up.<br/>
<strong>Would it be fair for them to become active?</strong><br/>
So we’ll implement a kind of back-and-forth form of fairness:<br/>
<strong></strong></p>
<ul>
<li>Once a reader is waiting, readers will get in next.</li>
<li>If a writer is waiting, one writer will get in next.</li>
</ul>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-171767 post type-post status-publish format-standard hentry category-c category-operating-systems tag-system-programming" id="post-171767">
<header class="entry-header">
<h1 class="entry-title">IPC through shared memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><a href="https://www.geeksforgeeks.org/inter-process-communication/">Inter Process Communication</a> through shared memory is a concept where two or more process can access the common memory. And communication is done via this shared memory where changes made by one process can be viewed by anther process.</p>
<p>The problem with pipes, fifo and message queue – is that for two process to exchange information. The information has to go through the kernel.</p>
<ul>
<li>Server reads from the input file.</li>
<li>The server writes this data in a message using either a pipe, fifo or message queue.</li>
<li>The client reads the data from the IPC channel,again requiring the data to be copied from kernel’s IPC buffer to the client’s buffer.</li>
<li>Finally the data is copied from the client’s buffer.</li>
<p> </p>
<p>A total of four copies of data are required (2 read and 2 write). So, shared memory provides a way by letting two or more processes share a memory segment. With Shared Memory the data is only copied twice – from input file into shared memory and from shared memory to the output file.</p>
<p>SYSTEM CALLS USED ARE:</p>
<blockquote><p>
<b>ftok()</b>: is use to generate a unique key.</p>
<p><b>shmget()</b>:  int shmget(key_t,size_tsize,intshmflg); upon successful completion, shmget() returns an identifier for the shared memory segment.</p>
<p><b>shmat()</b>: Before you can use a shared memory segment, you have to attach yourself<br/>
to it using shmat(). void *shmat(int shmid ,void *shmaddr ,int shmflg);<br/>
shmid is shared memory id. shmaddr specifies specific address to use but we should set<br/>
it to zero and OS will automatically choose the address.</p>
<p><b>shmdt()</b>: When you’re done with the shared memory segment, your program should<br/>
detach itself from it using shmdt(). int shmdt(void *shmaddr);</p>
<p><b>shmctl()</b>: when you detach from shared memory,it is not destroyed. So, to destroy<br/>
shmctl() is used.  shmctl(int shmid,IPC_RMID,NULL);
</p></blockquote>
<p>SHARED MEMORY FOR WRITER PROCESS</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-171724 post type-post status-publish format-standard hentry category-c category-operating-systems tag-system-programming" id="post-171724">
<header class="entry-header">
<h1 class="entry-title">IPC using Message Queues</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite : <a href="https://www.geeksforgeeks.org/inter-process-communication/">Inter Process Communication</a><br/>
A message queue is a linked list of messages stored within the kernel and identified by a message queue identifier. A new queue is created or an existing queue opened by <b>msgget()</b>.<br/>
New messages are added to the end of a queue by <b>msgsnd()</b>. Every message has a positive long integer type field, a non-negative length, and the actual data bytes (corresponding to the length), all of which are specified to msgsnd() when the message is added to a queue. Messages are fetched from a queue by <b>msgrcv()</b>. We don’t have to fetch the messages in a first-in, first-out order. Instead, we can fetch messages based on their type field.</p>
<p>All processes can exchange information through access to a common system message queue. The sending process places a message (via some (OS) message-passing module) onto a queue which can be read by another process. Each message is given an identification or type so that processes can select the appropriate message. Process must share a common key in order to gain access to the queue in the first place.</p>
<p><img alt="" class="alignnone size-full wp-image-298531" height="441" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/message-queue1.png" width="479"/></p>
<p>System calls used for message queues:</p>
<pre>

<b>ftok()</b>: is use to generate a unique key.



<b>msgget()</b>: either returns the message queue identifier for a newly created message 

queue or returns the identifiers for a queue which exists with the same key value.



<b>msgsnd()</b>: Data is placed on to a message queue by calling msgsnd().



<b>msgrcv()</b>: messages are retrieved from a queue.



<b>msgctl()</b>: It performs various operations on a queue. Generally it is use to 

destroy message queue.

</pre>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p>MESSAGE QUEUE FOR WRITER PROCESS</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-170859 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-170859">
<header class="entry-header">
<h1 class="entry-title">Operating System | Bakery Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , , </p>
<p>The <b>Bakery algorithm</b> is one of the simplest known solutions to the mutual exclusion problem for the general case of N process. Bakery Algorithm is a critical section solution for <strong>N</strong> processes. The algorithm preserves the first come first serve property.</p>
<ul>
<li>Before entering its critical section, the process receives a number. Holder of the smallest number enters the critical section.</li>
<li> If processes Pi and Pj receive the same number,
<pre>if i &lt; j 

Pi is served first; 

else 

Pj is served first.</pre>
</li>
<li>The numbering scheme always generates numbers in increasing order of enumeration; i.e., 1, 2, 3, 3, 3, 3, 4, 5, …</li>
</ul>
<p><b>Notation –</b>  lexicographical order (ticket #, process id #) – Firstly the ticket number is compared. If same then the process ID is compared next, i.e.-</p>
<pre>– (a, b) &lt; (c, d) if a &lt; c or if a = c and b &lt; d

– max(a [0], . . ., a [n-1]) is a number, k, such that k &gt;= a[i]  for i = 0, . . ., n - 1</pre>
<p>Shared data – choosing is an array [0..n – 1] of boolean values; &amp; number is an array [0..n – 1] of integer values. Both are initialized to <strong>False &amp; Zero</strong> respectively.</p>
<p><strong>Algorithm Pseudocode –</strong></p>
<pre>

repeat

    choosing[i] := true;

    number[i] := max(number[0], number[1], ..., number[n - 1])+1;

    choosing[i] := false;

    for j := 0 to n - 1

        do begin

            while choosing[j] do no-op;

            while number[j] != 0

                and (number[j], j) &lt; (number[i], i) do no-op;

        end;



        critical section

    

    number[i] := 0;

    

        remainder section



until false;

</pre>
<p><strong>Explanation –</strong><br/>
Firstly the process sets its “choosing” variable to be TRUE indicating its intent to enter critical section. Then it gets assigned the highest ticket number corresponding to other processes. Then the “choosing” variable is set to FALSE indicating that it now has a new ticket number. This is in-fact the most important and confusing part of the algorithm.</p>
<p>It is actually a small critical section in itself ! The very purpose of the first three lines is that if a process is modifying its TICKET value then at that time some other process should not be allowed to check its old ticket value which is now obsolete. This is why inside the for loop before checking ticket value we first make sure that all other processes have the “choosing” variable as FALSE. </p>
<p>After that we proceed to check the ticket values of processes where process with least ticket number/process id gets inside the critical section. The exit section just resets the ticket value to zero.</p>
<p><b>Code –</b> Here’s the C code implementation of the Bakery Algorithm. Run the following in a <b>UNIX environment</b> –</p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-170554 post type-post status-publish format-standard hentry category-algorithm category-gate-cs category-operating-systems" id="post-170554">
<header class="entry-header">
<h1 class="entry-title">Operating System | Dekker’s algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , <br/>
To obtain such a mutual exclusion, bounded waiting, and progress there have been several algorithms implemented, one of which is Dekker’s Algorithm. To understand the algorithm let’s understand the solution to the critical section problem first.<br/>
A process is generally represented as :</p>
<pre>

do {

    //entry section

        critical section

    //exit section

        remainder section

} while (TRUE);

</pre>
<p>The solution to critical section problem must ensure following three conditions: </p>
<ol>
<li>Mutual Exclusion</li>
<li>Progress</li>
<li>Bounded Waiting</li>
</ol>
<p>One of solution for ensuring above all factors is <a href="https://www.geeksforgeeks.org/petersons-algorithm-for-mutual-exclusion-set-1/">Peterson’s solution</a>.</p>
<p>Another one is <b>Dekker’s Solution</b>. Dekker’s algorithm was the first provably-correct solution to the critical section problem. It allows two threads to share a single-use resource without conflict, using only shared memory for communication. It avoids the strict alternation of a naïve turn-taking algorithm, and was one of the first mutual exclusion algorithms to be invented.</p>
<p>Although there are many versions of Dekker’s Solution, the final or 5th version is the one that satisfies all of the above conditions and is the most efficient of them all. </p>
<p><b>Note –</b> Dekker’s Solution, mentioned here, ensures mutual exclusion between two processes only, it could be extended to more than two processes with the proper use of arrays and variables.</p>
<p><b>Algorithm –</b> It requires both an array of Boolean values and an integer variable:</p>
<pre>

var flag: array [0..1] of boolean;

turn: 0..1;

repeat



        flag[i] := true;

        while flag[j] do

                if turn = j then

                begin

                        flag[i] := false;

                        while turn = j do no-op;

                        flag[i] := true;

                end;



                critical section



        turn := j;

        flag[i] := false;



                remainder section



until false;

</pre>
<p><strong>First Version of Dekker’s Solution –</strong> The idea is to use common or shared thread number between processes and stop the other process from entering its critical section if the shared thread indicates the former one already running.</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-170376 post type-post status-publish format-standard hentry category-operating-systems" id="post-170376">
<header class="entry-header">
<h1 class="entry-title">Operating System | Introduction of System Call</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In computing, a <b>system call</b> is the programmatic way in which a computer program requests a service from the kernel of the operating system it is executed on. A system call is a way for programs to <b>interact with the operating system</b>. A computer program makes a system call when it makes a request to the operating system’s kernel. System call <b>provides</b> the services of the operating system to the user programs via Application Program Interface(API). It provides an interface between a process and operating system to allow user-level processes to request services of the operating system. System calls are the only entry points into the kernel system. All programs needing resources must use system calls.</p>
<p><strong>Services Provided by System Calls :</strong></p>
<ol>
<li> Process creation and management</li>
<li> Main memory management</li>
<li> File Access, Directory and File system management</li>
<li> Device handling(I/O)</li>
<li> Protection</li>
<li> Networking, etc.</li>
</ol></div></article><hr style="border: 2px dashed black;" /><article class="post-170398 post type-post status-publish format-standard hentry category-algorithm category-gate-cs category-matrix category-operating-systems" id="post-170398">
<header class="entry-header">
<h1 class="entry-title">Operating System | Banker’s Algorithm : Print all the safe state (or safe sequences)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – , , <br/>
Banker’s Algorithm is a resource allocation and deadlock avoidance algorithm. This algorithm test for safety simulating the allocation for predetermined maximum possible amounts of all resources, then makes an “s-state” check to test for possible activities, before deciding whether allocation should be allowed to continue.</p>
<p>In simple terms, it checks if allocation of any resource will lead to deadlock or not, OR is it safe to allocate a resource to a process and if not then resource is not allocated to that process. Determining a safe sequence(even if there is only 1) will assure that system will not go into deadlock.</p>
<p>Banker’s algorithm is generally used to find if a safe sequence exist or not. But here we will determine the total number of safe sequences and print all safe sequences.</p>
<p>The data structure used are: </p>
<ul>
<li>Available vector</li>
<li>Max Matrix</li>
<li>Allocation Matrix</li>
<li>Need Matrix</li>
</ul>
<p>Example:</p>
<pre>

Input :  

<img alt="" class="alignnone size-full wp-image-289749" height="57" src="https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-12-28-21-02-46.png" width="464"> 

<img alt="" class="alignnone size-full wp-image-288942" height="187" src="https://media.geeksforgeeks.org/wp-content/uploads/banker1.png" width="577">



Output : Safe sequences are:

P2--&gt; P4--&gt; P1--&gt; P3

P2--&gt; P4--&gt; P3--&gt; P1

P4--&gt; P2--&gt; P1--&gt; P3

P4--&gt; P2--&gt; P3--&gt; P1



There are total 4 safe-sequences

</img></img></pre>
<p><b>Explanation –</b><br/>
Total resources are R1 = 10, R2 = 5, R3 = 7 and allocated resources are R1 = (0+2+3+2 =) 7, R2 = (1+0+0+1 =) 2, R3 = (0+0+2+1 =) 3. Therefore, remaining resources are R1 = (10 – 7 =) 3, R2 = (5 – 2 =) 3, R3 = (7 – 3 =) 4. </p>
<p>Remaining available = Total resources – allocated resources<br/>
and<br/>
Remaining need = max – allocated</p>
<p><img alt="" class="aligncenter size-full wp-image-293832" height="138" src="https://media.geeksforgeeks.org/wp-content/uploads/Capture-41.png" width="639"/></p>
<p>So, we can start from either P2 or P4. We can not satisfy remaining need from available resources of either P1 or P3 in first or second attempt step of Banker’s algorithm. There are only four possible safe sequences. These are :<br/>
P2–&gt; P4–&gt; P1–&gt; P3<br/>
P2–&gt; P4–&gt; P3–&gt; P1<br/>
P4–&gt; P2–&gt; P1–&gt; P3<br/>
P4–&gt; P2–&gt; P3–&gt; P1</p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p>Code –<br/>
</p></div><h2 class="tabtitle">C++</h2>
<div class="tabcontent">
</div></article><hr style="border: 2px dashed black;" /><article class="post-168466 post type-post status-publish format-standard hentry category-operating-systems" id="post-168466">
<header class="entry-header">
<h1 class="entry-title">Operating System | Multiple-Processor Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In multiple-processor scheduling <b>multiple CPU’s</b> are available and hence <b>Load Sharing</b> becomes possible. However multiple processor scheduling is more <b>complex</b> as compared to single processor scheduling. In multiple processor scheduling there are cases when the processors are identical i.e. HOMOGENEOUS, in terms of their functionality, we can use any processor available to run any process in the queue.</p>
<h3>Approaches to Multiple-Processor Scheduling –</h3>
<p>One approach is when all the scheduling decisions and I/O processing are handled by a single processor which is called the <b>Master Server</b> and the other processors executes only the <b>user code</b>. This is simple and reduces the need of data sharing. This entire scenario is called <b>Asymmetric Multiprocessing</b>.</p>
<p>A second approach uses <b>Symmetric Multiprocessing</b> where each processor is <b>self scheduling</b>. All processes may be in a common ready queue or each processor may have its own private queue for ready processes. The scheduling proceeds further by having the scheduler for each processor examine the ready queue and select a process to execute.</p>
<h3>Processor Affinity –</h3>
<p>Processor Affinity means a processes has an <b>affinity</b> for the processor on which it is currently running.<br/>
When a process runs on a specific processor there are certain effects on the cache memory. The data most recently accessed by the process populate the cache for the processor and as a result successive memory access by the process are often satisfied in the cache memory. Now if the process migrates to another processor, the contents of the cache memory must be invalidated for the first processor and the cache for the second processor must be repopulated. Because of the high cost of invalidating and repopulating caches, most of the SMP(symmetric multiprocessing) systems try to avoid migration of processes from one processor to another and try to keep a process running on the same processor. This is known as <b>PROCESSOR AFFINITY</b>.</p>
<p>There are two types of processor affinity:</p>
<ol>
<li><b>Soft Affinity –</b> When an operating system has a policy of attempting to keep a process running on the same processor but not guaranteeing it will do so, this situation is called soft affinity.</li>
<li><b>Hard Affinity –</b> Some systems such as Linux also provide some system calls that support Hard Affinity which allows a process to migrate between processors.</li>
</ol>
<h3>Load Balancing –</h3>
<p>Load Balancing is the <b>phenomena</b> which keeps the <b>workload</b> evenly <b>distributed</b> across all processors in an SMP system. Load balancing is necessary only on systems where each processor has its own private queue of process which are eligible to execute. Load balancing is unnecessary because once a processor becomes idle it immediately extracts a runnable process from the common run queue. On SMP(symmetric multiprocessing), it is important to keep the workload balanced among all processors to fully utilize the benefits of having more than one processor else one or more processor will sit idle while other processors have high workloads along with lists of processors awaiting the CPU.</p>
<p>There are two general approaches to load balancing :</p>
<ol>
<li><b>Push Migration –</b> In push migration a task routinely checks the load on each processor and if it finds an imbalance then it evenly distributes load on each processors by moving the processes from overloaded to idle or less busy processors.</li>
<li><b>Pull Migration –</b> Pull Migration occurs when an idle processor pulls a waiting task from a busy processor for its execution.</li>
</ol>
<h3>Multicore Processors –</h3>
<p>In multicore processors <b>multiple processor</b> cores are places on the same physical chip. Each core has a register set to maintain its architectural state and thus appears to the operating system as a separate physical processor. <b>SMP systems</b> that use multicore processors are faster and consume <b>less power</b> than systems in which each processor has its own physical chip.</p>
<p>However multicore processors may <b>complicate</b> the scheduling problems. When processor accesses memory then it spends a significant amount of time waiting for the data to become available. This situation is called <b>MEMORY STALL</b>. It occurs for various reasons such as cache miss, which is accessing the data that is not in the cache memory. In such cases the processor can spend upto fifty percent of its time waiting for data to become available from the memory. To solve this problem recent hardware designs have implemented multithreaded processor cores in which two or more hardware threads are assigned to each core. Therefore if one thread stalls while waiting for the memory, core can switch to another thread.</p>
<p>There are two ways to multithread a processor :</p>
<ol>
<li><b>Coarse-Grained Multithreading –</b> In coarse grained multithreading a thread executes on a processor until a long latency event such as a memory stall occurs, because of the delay caused by the long latency event, the processor must switch to another thread to begin execution. The cost of switching between threads is high as the instruction pipeline must be terminated before the other thread can begin execution on the processor core. Once this new thread begins execution it begins filling the pipeline with its instructions.</li>
<li><b>Fine-Grained Multithreading –</b> This multithreading switches between threads at a much finer level mainly at the boundary of an instruction cycle. The architectural design of fine grained systems include logic for thread switching and as a result the cost of switching between threads is small.</li>
</ol>
<h3>Virtualization and Threading –</h3>
<p>In this type of <b>multiple-processor</b> scheduling even a single CPU system acts like a multiple-processor system. In a system with Virtualization, the virtualization presents one or more virtual CPU’s to each of virtual machines running on the system and then schedules the use of physical CPU’S among the virtual machines. Most virtualized environments have one host operating system and many guest operating systems. The host operating system creates and manages the virtual machines and each virtual machine has a guest operating system installed and applications running within that guest.Each guest operating system may be assigned for specific use cases,applications, and users,including time sharing or even real-time operation. Any guest operating-system scheduling algorithm that assumes a certain amount of progress in a given amount of time will be negatively impacted by the virtualization. In a time sharing operating system that tries to allot 100 milliseconds to each time slice to give users a reasonable response time. A given 100 millisecond time slice may take much more than 100 milliseconds of virtual CPU time. Depending on how busy the system is, the time slice may take a second or more which results in a very poor response time for users logged into that virtual machine. The net effect of such scheduling layering is that individual virtualized operating systems receive only a portion of the available CPU cycles, even though they believe they are receiving all cycles and that they are scheduling all of those cycles.Commonly, the time-of-day clocks in virtual machines are incorrect because timers take no longer to trigger than they would on dedicated CPU’s. </p>
<p><b>Virtualizations</b> can thus undo the good scheduling-algorithm efforts of the operating systems within virtual machines.  </p>
<p><b>Reference –</b><br/>
</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br/>
<!-- .entry-meta -->
</br></div></article><hr style="border: 2px dashed black;" /><article class="post-168252 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-168252">
<header class="entry-header">
<h1 class="entry-title">Operating System | Buddy System – Memory allocation technique</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <br/>
<b>Static partition</b> schemes suffer from the <b>limitation</b> of having the fixed number of active processes and the usage of space may also not be optimal. The <b>buddy system</b> is a memory allocation and management algorithm that manages memory in <b>power of two increments</b>. Assume the memory size is 2<sup>U</sup>, suppose a size of S is required.</p>
<ul>
<li><strong>If 2<sup>U-1</sup>&lt;S&lt;=2<sup>U</sup>:</strong> Allocate the whole block</li>
<li><strong>Else:</strong> Recursively divide the block equally and test the condition at each time, when it satisfies, alloacate the block and get out the loop.</li>
</ul>
<p>System also keep the record of all the unallocated blocks each and can merge these different size blocks to make one big chunk.<br/>
<strong>Advantage –</strong></p>
<ul>
<li>Easy to implement a buddy system</li>
<li>Allocates block of correct size</li>
<li>It is easy to merge adjacent holes</li>
<li>Fast to allocate memory and de-allocating memory</li>
</ul>
<p><strong>Disadvantage –</strong></p>
<ul>
<li>It requires all allocation unit to be powers of two</li>
<li>It leads to  internal fragmentation</li>
</ul>
<p><strong>Example –</strong><br/>
Consider a system having buddy system with physical address space 128 KB.Calculate the size of partition for 18 KB process.<br/>
<strong>Solution –</strong></p>
<p><img alt="" class="aligncenter size-full wp-image-284309" height="460" src="https://media.geeksforgeeks.org/wp-content/uploads/Capture-34.png" width="651"><br/>
So, size of partition for 18 KB process = 32 KB. It divides by 2, till possible to get minimum block to fit 18 KB. </img></p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/soumya7/">soumya7</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-165768 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-165768">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Table and Process Control Block (PCB)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>While creating a process the operating system performs several operations. To identify these process, it must identify each process, hence it assigns a process identification number (PID) to each process. As the operating system supports multi-programming, it needs to keep track of all the processes. For this task, the process control block (PCB) is used to track the process’s execution status. Each block of memory contains information about the process state, program counter, stack pointer, status of opened files, scheduling algorithms, etc. All these information is required and must be saved when the process is switched from one state to another. When the process made transitions from one state to another, the operating system must update information in the process’s PCB.</p>
<p>A process control block (PCB) contains information about the process, i.e. registers, quantum, priority, etc. The process table is an array of PCB’s, that means logically contains a PCB for all of the current processes in the system.</p>
<p><img alt="" class="aligncenter size-full wp-image-270470" height="243" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/process-table.jpg" width="244"/></p>
<ul>
<li><b>Pointer –</b> It is a stack pointer which is required to be saved when the process is switched from one state to another to retain the current position of the process.</li>
<li><b>Process state –</b> It stores the respective state of the process.</li>
<li><b>Process number –</b> Every process is assigned with a unique id known as process ID or PID which stores the process identifier.</li>
<li><b>Program counter –</b> It stores the counter which contains the address of the next instruction that is to be executed for the process.</li>
<li><b>Register –</b> These are the CPU registers which includes: accumulator, base, registers and general purpose registers.</li>
<li><b>Memory limits –</b> This field contains the information about memory management system used by operating system. This may include the page tables, segment tables etc.</li>
<li><b>Open files list –</b> This information includes the list of files opened for a process.</li>
</ul>
<p><b>Miscellaneous accounting and status data –</b> This field includes information about the amount of CPU used, time constraints, jobs or process number, etc.<br/>
The process control block stores the register content also known as execution content of the processor when it was blocked from running. This execution content architecture enables the operating system to restore a process’s execution context when the process returns to the running state. When the process made transitions from one state to another, the operating system update its information in the process’s PCB. The operating system maintains pointers to each process’s PCB in a process table so that it can access the PCB quickly.</p>
<p><img alt="" class="aligncenter size-full wp-image-270471" height="273" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/process-control-block.jpg" width="512"/></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div><p>This article is contributed by <strong>Rajshree Srivastava</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/magbene/">magbene</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-164690 post type-post status-publish format-standard hentry category-difference-between category-operating-systems" id="post-164690">
<header class="entry-header">
<h1 class="entry-title">Difference between 32-bit and 64-bit operating systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In computing, there exist two type processor i.e., 32-bit and 64-bit. These processor tells us how much memory a processor can have access from a CPU register. For instance,</p>
<blockquote><p>A 32-bit system can access 2<sup>32</sup> memory addresses, i.e 4 GB of RAM or physical memory.<br/>
A 64-bit system can access 2<sup>64</sup> memory addresses, i.e actually 18-Quintillion GB of RAM. In short, any amount of memory greater than 4 GB can be easily handled by it.</p></blockquote>
<p>Most computers made in the 1990s and early 2000s were 32-bit machines. The CPU register stores memory addresses, which is how the processor accesses data from RAM. One bit in the register can reference an individual byte in memory, so a <strong>32-bit</strong> system can address a maximum of 4 GB (4,294,967,296 bytes) of RAM. <em>The actual limit is often less around <strong>3.5 GB</strong>, since part of the register is used to store other temporary values besides memory addresses</em>. Most computers released over the past two decades were built on a 32-bit architecture, hence most operating systems were designed to run on a 32-bit processor.</p>
<p>A <strong>64-bit</strong> register can theoretically reference 18,446,744,073,709,551,616 bytes, or 17,179,869,184 GB (16 exabytes) of memory. This is several million times more than an average workstation would need to access. What’s important is that a 64-bit computer (which means it has a 64-bit processor) can access more than 4 GB of RAM. If a computer has 8 GB of RAM, it better have a 64-bit processor. Otherwise, at least 4 GB of the memory will be inaccessible by the CPU.</p>
<p>A major difference between <strong>32-bit processors and 64-bit processors</strong> is the number of calculations per second they can perform, which affects the speed at which they can complete tasks. 64-bit processors can come in <strong>dual core, quad core, six core, and eight core versions</strong> for home computing. Multiple cores allow for an increased number of calculations per second that can be performed, which can increase the processing power and help make a computer run faster. Software programs that require many calculations to function smoothly can operate faster and more efficiently on the multi-core 64-bit processors, for the most part.</p>
<p style="text-align: center"><strong><u>Advantages of 64-bit over 32-bit</u></strong></p>
<ul>
<li>
    Using 64-bit one can do a lot in multi-tasking, user can easily switch between various applications without any windows hanging problems.
</li>
<li>
    Gamers can easily plays High graphical games like Modern Warfare, GTA V, or use high-end softwares like Photoshop or CAD which takes a lot of memory, since it makes multi-tasking with big softwares easy and efficient for users. However upgrading the  instead of getting a 64-bit processor would be more beneficial.
</li>
</ul>
<p><strong>Note</strong>:</p>
<ul>
<li>A computer with a 64-bit processor can have a 64-bit or 32-bit version of an operating system installed. However, with a 32-bit operating system, the 64-bit processor would not run at its full capability.</li>
<li>
    On a computer with a 64-bit processor, we can’t run a 16-bit legacy program. Many 32-bit programs will work with a 64-bit processor and operating system, but some older 32-bit programs may not function properly, or at all, due to limited or no compatibility.
</li>
</ul>
<p><strong>References:</strong> </p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<hr/><hr/><div><p>If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="https://contribute.geeksforgeeks.org/">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p><p>Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.</p><br/></div><div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/flick07/">flick07</a>, <a href="https://auth.geeksforgeeks.org/user/DeepaBharti1/">DeepaBharti1</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-163931 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-163931">
<header class="entry-header">
<h1 class="entry-title">Operating System | Dining Philosopher Problem Using Semaphores</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite –</b> , , </p>
<p><strong>The Dining Philosopher Problem –</strong> The Dining Philosopher Problem states that K philosophers seated around a circular table with one chopstick between each pair of philosophers. There is one chopstick between each philosopher. A philosopher may eat if he can pickup the two chopsticks adjacent to him. One chopstick may be picked up by any one of its adjacent followers but not both. </p>
<p><img class="aligncenter size-full" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/dining_philosopher_problem.png"/></p>
<p><strong>Semaphore Solution to Dining Philosopher –</strong></p>
<p>Each philosopher is represented by the following pseudocode:</p>
<pre>

process P[i]

 while true do

   {  THINK;

      PICKUP(CHOPSTICK[i], CHOPSTICK[i+1 mod 5]);

      EAT;

      PUTDOWN(CHOPSTICK[i], CHOPSTICK[i+1 mod 5])

   }

</pre>
<p>There are three states of philosopher : <b>THINKING, HUNGRY and EATING</b>. Here there are two semaphores : Mutex and a semaphore array for the philosophers. Mutex is used such that no two philosophers may access the pickup or putdown at the same time. The array is used to control the behavior of each philosopher. But, semaphores can result in deadlock due to programming errors.</p>
<p><b>Code –</b></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-164096 post type-post status-publish format-standard hentry category-greedy category-operating-systems" id="post-164096">
<header class="entry-header">
<h1 class="entry-title">Program for Optimal Page Replacement Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="https://www.geeksforgeeks.org/operating-system-page-replacement-algorithm/">Page Replacement Algorithms</a></p>
<p>In operating systems, whenever a new page is referred and not present in memory, page fault occurs and Operating System replaces one of the existing pages with newly needed page. Different page replacement algorithms suggest different ways to decide which page to replace. The target for all algorithms is to reduce number of page faults.<br/>
In this algorithm, OS replaces the page that will not be used for the longest period of time in future.</p>
<p>Examples :</p>
<pre>

Input : Number of frames, fn = 3

        Reference String, pg[] = {7, 0, 1, 2,

               0, 3, 0, 4, 2, 3, 0, 3, 2, 1,

               2, 0, 1, 7, 0, 1};

Output : No. of hits = 11 

         No. of misses = 9



Input : Number of frames, fn = 4 

        Reference String, pg[] = {7, 0, 1, 2, 

                  0, 3, 0, 4, 2, 3, 0, 3, 2};

Output : No. of hits = 7

         No. of misses = 6

</pre>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p>The idea is simple, for every reference we do following :     </p>
<ol>
<li>If referred page is already present, increment hit count.</li>
<li>If not present, find if a page that is never referenced in future. If such a page exists, replace this page with new page. If no such page exists, find a page that is referenced farthest in future. Replace this page with new page.</li>
</ol>
<p><img alt="" class="alignnone size-full wp-image-258327" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/optimal_page.png"/></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-163256 post type-post status-publish format-standard hentry category-algorithm category-gate-cs category-java category-operating-systems" id="post-163256">
<header class="entry-header">
<h1 class="entry-title">Operating System | Priority Scheduling with different arrival time – Set 2</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>
<b>Prerequisite –</b> <br/>
Priority scheduling is a non-preemptive algorithm and one of the most common scheduling algorithms in batch systems. Each process is assigned first arrival time (less arrival time process first) if two processes have same arrival time, then compare to priorities (highest process first). Also, if two processes have same priority then compare to process number (less process number first). This process is repeated while all process get executed.</p>
<p><b>Implementation –</b></p>
<ol>
<li>First input the processes with their arrival time, burst time and priority.</li>
<li>Sort the processes, according to arrival time if two process arrival time is same then sort according process priority if two process priority are same then sort according to process number.</li>
<li>Now simply apply FCFS algorithm.</li>
</ol>
<p><img alt="" class="aligncenter size-full wp-image-253729" height="149" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/opSystemScheduling.png" width="506"><br/>
<strong>Gantt Chart – </strong><br/>
<img alt="" class="aligncenter size-full wp-image-253730" height="95" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/gantchart2.jpg" width="452"/></img></p>
<p><b>Examples –</b></p>
<pre>

<b>Input :</b>

process no-&gt; 1 2 3 4 5 

arrival time-&gt; 0 1 3 2 4

burst time-&gt; 3 6 1 2 4

priority-&gt; 3 4 9 7 8

<b>Output :</b>

Process_no Start_time Complete_time Trun_Around_Time Wating_Time

1          0           3            3           0

2          3           9            8           2

4          9           11           9           7

3          11          12           9           8

5          12          16           12          8

Average Wating Time is : 5.0

Average Trun Around time is : 8.2



</pre>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
</div><h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-162478 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-162478">
<header class="entry-header">
<h1 class="entry-title">Operating System | Lock variable synchronization mechanism</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisites –</b> </p>
<p>A lock variable provides the simplest synchronization mechanism for processes. Some noteworthy points regarding Lock Variables are-</p>
<ol>
<li>Its a <b>software mechanism</b> implemented in user mode, i.e. no support required from the Operating System.</li>
<li>Its a busy waiting solution (keeps the CPU busy even when its technically waiting).</li>
<li>It can be used for more than two processes.</li>
</ol>
<p>When Lock = 0 implies critical section is vacant (initial value ) and Lock = 1 implies critical section occupied.</p>
<p>The pseudocode looks something like this –</p>
<pre>

Entry section - while(lock != 0);

                Lock = 1;

//critical section

Exit section - Lock = 0;

</pre>
<p>A more formal approach to the Lock Variable method for process synchronization can be seen in the following code snippet :</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-162354 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-162354">
<header class="entry-header">
<h1 class="entry-title">Operating System | Page Table Entries</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Prerequisite –</strong> <a href="https://www.geeksforgeeks.org/operating-system-paging/"> Paging</a></p>
<p>Page table has page table entries where each page table entry stores a frame number and optional status (like protection) bits. Many of status bits used in the virtual memory system. The most <b>important</b> thing in PTE is <b>frame Number</b>.</p>
<p><strong>Page table entry has the following information –</strong></p>
<p><img alt="" class="aligncenter size-full wp-image-249663" height="388" src="https://media.geeksforgeeks.org/wp-content/uploads/Capture-24.png" width="994"/></p>
<ol>
<li><strong>Frame Number –</strong> It gives the frame number in which the current page you are looking for is present. The number of bits required depends on the number of frames.Frame bit is also known as address translation bit.
<pre>

Number of bits for frame = Size of physical memory/frame size

</pre>
</li>
<li><strong>Present/Absent bit –</strong> Present or absent bit says whether a particular page you are looking for is present or absent. In case if it is not present, that is called Page Fault. It is set to 0 if the corresponding page is not in memory. Used to control page fault by the operating system to support virtual memory. Sometimes this bit is also known as <b>valid/invalid</b> bits.</li>
<li><strong>Protection bit –</strong> Protection bit says that what kind of protection you want on that page. So, these bit for the protection of the page frame (read, write etc).</li>
<li><strong>Referenced bit –</strong> Referenced bit will say whether this page has been referred in the last clock cycle or not. It is set to 1 by hardware when the page is accessed.</li>
<li><strong>Caching enabled/disabled –</strong> Some times we need the fresh data. Let us say the user is typing some information from the keyboard and your program should run according to the input given by the user. In that case, the information will come into the main memory. Therefore main memory contains the latest information which is typed by the user. Now if you try to put that page in the cache, that cache will show the old information. So whenever freshness is required, we don’t want to go for caching or many levels of the memory.The information present in the closest level to the CPU and the information present in the closest level to the user might be different. So we want the information has to be consistency, which means whatever information user has given, CPU should be able to see it as first as possible. That is the reason we want to disable caching. So, this bit <b>enables or disable</b> caching of the page.</li>
<li><strong>Modified bit –</strong> Modified bit says whether the page has been modified or not. Modified means sometimes you might try to write something on to the page. If a page is modified, then whenever you should replace that page with some other page, then the modified information should be kept on the hard disk or it has to be written back or it has to be saved back. It is set to 1 by hardware on write-access to page which is used to avoid writing when swapped out. Sometimes this modified bit is also called as the <b>Dirty bit</b>.</li>
<p></p></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-162213 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-162213">
<header class="entry-header">
<h1 class="entry-title">Operating System | Overlays in Memory Management</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The main problem in Fixed partitioning is the size of a process has to be limited by the maximum size of the partition, which means a process can never be span over another.In order to solve this problem, earlier people have used some solution which is called as Overlays.</p>
<p>The concept of <b>overlays</b> is that whenever a process is running it will not use the complete program at the same time, it will use only some part of it.Then overlays concept says that whatever part you required, you load it an once the part is done, then you just unload it, means just pull it back and get the new part you required and run it.<br/>
Formally,<br/>
“The process of <b>transferring a block</b> of program code or other data into internal memory, replacing what is already stored”.<br/>
Sometimes it happens that compare to the size of the biggest partition, the size of the program will be even more, then, in that case, you should go with overlays.</p>
<p>So overlay is a technique to run a program that is bigger than the size of the physical memory by keeping only those instructions and data that are needed at any given time.Divide the program into modules in such a way that not all modules need to be in the memory at the same time.</p>
<p><strong>Advantage –</strong></p>
<ul>
<li>Reduce memory requirement</li>
<li>Reduce time requirement</li>
</ul>
<p><strong>Disadvantage –</strong></p>
<ul>
<li>Overlap map must be specified by programmer</li>
<li>Programmer must know memory requirement</li>
<li>Overlaped module must be completely disjoint</li>
<li>Programmming design of overlays structure is complex and not possible in all cases</li>
</ul>
<p><strong>Example –</strong><br/>
The best example of overlays is assembler.Consider the assembler has 2 passes, 2 pass means at any time it will be doing only one thing, either the 1st pass or the 2nd pass.Which means it will finish 1st pass first and then 2nd pass.Let assume that available main memory size is 150KB and total code size is 200KB</p>
<pre>

Pass 1.......................70KB

Pass 2.......................80KB

Symbol table.................30KB

Common routine...............20KB

</pre>
<p>As the total code size is 200KB and main memory size is 150KB, it is not possible to use 2 passes together.So, in this case, we should go with the overlays technique.According to the overlays concept at any time only one pass will be used and both the passes always need symbol table and common routine.Now the question is if overlays-driver* is 10KB, then what is the minimum partition size required?For pass 1 total memory needed is = (70KB + 30KB + 20KB + 10KB) = 130KB and for pass 2 total memory needed is = (80KB + 30KB + 20KB + 10KB) = 140KB.So if we have minimum 140KB size partition then we can run this code very easily.</p>
<p>*Overlays driver:-It is the user responsibility to take care of overlaying, the operating system will not provide anything.Which means the user should write even what part is required in the 1st pass and once the 1st pass is over, the user should write the code to pull out the pass 1 and load the pass 2.That is what is the responsibility of the user, that is known as the Overlays driver.Overlays driver will just help us to move out and move in the various part of the code.</p>
<p><strong>Question –</strong><br/>
The overlay tree for a program is as shown below:<br/>
<img alt="" class="aligncenter size-medium wp-image-180322" sizes="(max-width: 524px) 100vw, 524px" src="https://www.geeksforgeeks.org/wp-content/uploads/os_overlaymemory.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/os_overlaymemory.png 524w, https://www.geeksforgeeks.org/wp-content/uploads/os_overlaymemory-300x159.png 300w"><br/>
What will be the size of the partition (in physical memory) required to load (and<br/>
run) this program?<br/>
(a) 12 KB (b) 14 KB (c) 10 KB (d) 8 KB<br/>
<strong>Explanation –</strong><br/>
Using the overlay concept we need not actually have the entire program inside the main memory.Only we need to have the part which are required at that instance of time, either we need Root-A-D or Root-A-E or Root-B-F or Root-C-G part.</img></p>
<pre>

Root+A+D = 2KB + 4KB + 6KB = 12KB

Root+A+E = 2KB + 4KB + 8KB = 14KB

Root+B+F = 2KB + 6KB + 2KB = 10KB

Root+C+G = 2KB + 8KB + 4KB = 14KB

</pre>
<p>So if we have 14KB size of partition then we can run any of them.<br/>
Answer -(b) 14KB</p>
<p>This article is contributed by <a href="https://auth.geeksforgeeks.org/profile.php?user=Samit Mandal"><strong>Samit Mandal</strong></a>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.<br/>
</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-162170 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-162170">
<header class="entry-header">
<h1 class="entry-title">Operating System | Unix File System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Unix file system is a logical method of <b>organizing and storing</b> large amounts of information in a way that makes it easy to manage. A file is a smallest unit in which the information is stored. Unix file system has several important features. All data in Unix is organized into files. All files are organized into directories. These directories are organized into a tree-like structure called the file system. </p>
<p>Files in Unix System are organized into multi-level hierarchy structure known as a directory tree. At the very top of the file system is a directory called “root” which is represented by a “/”. All other files are “descendants” of root.</p>
<p><img alt="" class="aligncenter size-medium wp-image-177503" sizes="(max-width: 791px) 100vw, 791px" src="https://www.geeksforgeeks.org/wp-content/uploads/unix.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/unix.png 791w, https://www.geeksforgeeks.org/wp-content/uploads/unix-300x165.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/unix-768x421.png 768w, https://www.geeksforgeeks.org/wp-content/uploads/unix-660x362.png 660w"/></p>
<p><strong>Directories or Files and their description –</strong></p>
<ul>
<li><strong>/ : </strong>    The slash / character alone denotes the root of the filesystem tree.</li>
<li><strong>/bin : </strong>Stands for “binaries” and contains certain fundamental utilities, such as ls or cp, which are generally needed by all users.</li>
<li><strong>/boot : </strong>Contains all the files that are required for successful booting process.</li>
<li><strong>/dev : </strong>Stands for “devices”. Contains file representations of peripheral devices and pseudo-devices.</li>
<li><strong>/etc : </strong>Contains system-wide configuration files and system databases. Originally also contained “dangerous maintenance utilities” such as init,but these have typically been moved to /sbin or elsewhere.</li>
<li><strong>/home : </strong>Contains the home directories for the users. </li>
<li><strong>/lib : </strong>Contains system libraries, and some critical files such as kernel modules or device drivers.</li>
<li><strong>/media : </strong>Default mount point for removable devices, such as USB sticks, media players, etc.</li>
<li><strong>/mnt : </strong>Stands for “mount”. Contains filesystem mount points. These are used, for example, if the system uses multiple hard disks or hard disk partitions. It is also often used for remote (network) filesystems, CD-ROM/DVD drives, and so on.</li>
<li><strong>/proc : </strong>procfs virtual filesystem showing information about processes as files.</li>
<li><strong>/root : </strong>The home directory for the superuser “root” – that is, the system administrator. This account’s home directory is usually on the initial filesystem, and hence not in /home (which may be a mount point for another filesystem) in case specific maintenance needs to be performed, during which other filesystems are not available. Such a case could occur, for example, if a hard disk drive suffers physical failures and cannot be properly mounted.</li>
<li><strong>/tmp : </strong>A place for temporary files. Many systems clear this directory upon startup; it might have tmpfs mounted atop it, in which case its contents do not survive a reboot, or it might be explicitly cleared by a startup script at boot time.</li>
<li><strong>/usr : </strong>Originally the directory holding user home directories,its use has changed. It now holds executables, libraries, and shared resources that are not system critical, like the X Window System, KDE, Perl, etc. However, on some Unix systems, some user accounts may still have a home directory that is a direct subdirectory of /usr, such as the default as in Minix. (on modern systems, these user accounts are often related to server or system use, and not directly used by a person).</li>
<li><strong>/usr/bin : </strong>This directory stores all binary programs distributed with the operating system not residing in /bin, /sbin or (rarely) /etc.</li>
<li><strong>/usr/include : </strong>Stores the development headers used throughout the system. Header files are mostly used by the <strong>#include </strong>directive in C/C++ programming language.</li>
<li><strong>/usr/lib : </strong>Stores the required libraries and data files for programs stored within /usr or elsewhere.</li>
<li><strong>/var : </strong>A short for “variable.” A place for files that may change often – especially in size, for example e-mail sent to users on the system, or process-ID lock files.</li>
<li><strong>/var/log : </strong>Contains system log files.</li>
<li><strong>/var/mail : </strong>The place where all the incoming mails are stored. Users (other than root) can access their own mail only. Often, this directory is a symbolic link to /var/spool/mail.</li>
<li><strong>/var/spool : </strong>Spool directory. Contains print jobs, mail spools and other queued tasks.</li>
<li><strong>/var/tmp : </strong>A place for temporary files which should be preserved between system reboots.</li>
</ul>
<p><b>Types of Unix files –</b> The UNIX files system contains several different types of files : </p>
<p><img alt="" class="aligncenter size-medium wp-image-180252" sizes="(max-width: 425px) 100vw, 425px" src="https://www.geeksforgeeks.org/wp-content/uploads/unix-file-system.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/unix-file-system.png 425w, https://www.geeksforgeeks.org/wp-content/uploads/unix-file-system-300x232.png 300w"/></p>
<p><strong>1. Ordinary files – </strong> An ordinary file is a file on the system that contains data, text, or program instructions.</p>
<ul>
<li>Used to store your information, such as some text you have written or an image you have drawn. This is the type of file that you usually work with.</li>
<li>Always located within/under a directory file.</li>
<li>Do not contain other files.</li>
<li>In long-format output of ls -l, this type of file is specified by the “-” symbol.</li>
</ul>
<p><strong>2. Directories – </strong> Directories store both special and ordinary files. For users familiar with Windows or Mac OS, UNIX directories are equivalent to folders. A directory file contains an entry for every file and subdirectory that it houses. If you have 10 files in a directory, there will be 10 entries in the directory. Each entry has two components.<br/>
(1) The Filename<br/>
(2) A unique identification number for the file or directory (called the inode number)</p>
<li>Branching points in the hierarchical tree.</li>
<li>Used to organize groups of files.</li>
<li>May contain ordinary files, special files or other directories.</li>
<li>Never contain “real” information which you would work with (such as text). Basically, just used for organizing files. </li>
<li>All files are descendants of the root directory, ( named / ) located at the top of the tree. </li>
<p>In long-format output of ls –l , this type of file is specified by the “d” symbol.</p>
<p><strong>3. Special Files – </strong> Used to represent a real physical device such as a printer, tape drive or terminal, used for Input/Ouput (I/O) operations. <b>Device or special files</b> are used for device Input/Output(I/O) on UNIX and Linux systems. They appear in a file system just like an ordinary file or a directory.<br/>
On UNIX systems there are two flavors of special files for each device, character special files and block special files :</p>
<ul>
<li>When a character special file is used for device Input/Output(I/O), data is transferred one character at a time. This type of access is called raw device access.</li>
<li>When a block special file is used for device Input/Output(I/O), data is transferred in large fixed-size blocks. This type of access is called block device access.</li>
</ul>
<p>For terminal devices, it’s one character at a time. For disk devices though, raw access means reading or writing in whole chunks of data – blocks, which are native to your disk.</p>
<ul>
<li>In long-format output of ls -l, character special files are marked by the “c” symbol.</li>
<li>In long-format output of ls -l, block special files are marked by the “b” symbol.</li>
</ul>
<p><strong>4. Pipes – </strong>  UNIX allows you to link commands together using a pipe. The pipe acts a temporary file which only exists to hold data from one command until it is read by another.A Unix pipe provides a one-way flow of data.The output or result of the first command sequence is used as the input to the second command sequence. To make a pipe, put a vertical bar (|) on the command line between two commands.For example: <strong>who | wc -l </strong></p>
<p>In long-format output of ls –l , named pipes are marked by the “p” symbol.</p>
<p><strong>5. Sockets – </strong> A Unix socket (or Inter-process communication socket) is a special file which allows for advanced inter-process communication. A Unix Socket is used in a client-server application framework. In essence, it is a stream of data, very similar to network stream (and network sockets), but all the transactions are local to the filesystem.</p>
<p>In long-format output of ls -l, Unix sockets are marked by “s” symbol.</p>
<p><strong>6. Symbolic Link – </strong> Symbolic link is  used for referencing some other file of the file system.Symbolic link is also known as Soft link. It contains a text form of the path to the file it references. To an end user, symbolic link will appear to have its own name, but when you try reading or writing data to this file, it will instead reference these operations to the file it points to. If we delete the soft link itself , the data file would still be there.If we delete the source file or move it to a different location, symbolic file will not function properly. </p>
<p>In long-format output of ls –l , Symbolic link are marked by the “l” symbol (that’s a lower case L). </p>
<p><strong>Reference –</strong></p>
<p> | Sumitabha Das |Tata McGraw Hill |4th Edition</p>
<p>This article is contributed by <strong>Saloni Gupta</strong> . If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/OmkarManjrekar/">OmkarManjrekar</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-162116 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-162116">
<header class="entry-header">
<h1 class="entry-title">Operating System | Page Fault Handling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>
A page fault occurs when a program attempts to access data or code that is in its address space, but is not currently located in the system RAM. So when page fault occurs then following sequence of events happens :</p>
<p><img alt="" class="aligncenter size-medium wp-image-248596" src="http://contribute.geeksforgeeks.org/wp-content/uploads/121-1.png"/></p>
<ul>
<li>The computer hardware traps to the kernel and program counter (PC) is saved on the stack. Current instruction state information is saved in CPU registers.</li>
<li>An assembly program is started to save the general registers and other volatile information to keep the OS from destroying it.</li>
<li>Operating system finds that a page fault has occurred and tries to find out which virtual page is needed. Some times hardware register contains this required information. If not, the operating system must retrieve PC, fetch instruction and find out what it was doing when the fault occurred.</li>
<li>Once virtual address caused page fault is known, system checks to see if address is valid and checks if there is no protection access problem.</li>
<li>If the virtual address is valid, the system checks to see if a page frame is free. If no frames are free, the page replacement algorithm is run to remove a page.</li>
<li>If frame selected is dirty, page is scheduled for transfer to disk, context switch takes place, fault process is suspended and another process is made to run until disk transfer is completed.</li>
<li>As soon as page frame is clean, operating system looks up disk address where needed page is, schedules disk operation to bring it in.</li>
<li>When disk interrupt indicates page has arrived, page tables are updated to reflect its position, and frame marked as being in normal state.</li>
<li>Faulting instruction is backed up to state it had when it began and PC is reset. Faulting is scheduled, operating system returns to routine that called it.</li>
<li>Assembly Routine reloads register and other state information, returns to user space to continue execution.</li>
</ul>
<p><b>References –</b><br/>
<br/>
</p>
<p>This article is contributed by <b>Swasthik</b>. If you like GeeksforGeeks and would like to contribute, you can also write an article using contribute.geeksforgeeks.org or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-160942 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-160942">
<header class="entry-header">
<h1 class="entry-title">Operating System  | Resource Allocation Graph (RAG)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>As  using some kind of table like allocation, request, available all that thing to understand what is the state of the system. Similarly, if you want to understand the state of the system instead of using those table, actually tables are very easy to represent and understand it, but then still you could even represent the same information in the graph. That graph is called <b>Resource Allocation Graph (RAG)</b>.</p>
<p>So, resource allocation graph is explained to us what is the state of the system in terms of <b>processes and resources</b>. Like how many resources are available, how many are allocated and what is the request of each process. Everything can be represented in terms of the diagram. One of the advantages of having a diagram is, sometimes it is possible to see a deadlock directly by using RAG, but then you might not be able to know that by looking at the table. But the tables are better if the system contains lots of process and resource and Graph is better if the system contains less number of process and resource.<br/>
      We know that any graph contains vertices and edges. So RAG also contains vertices and edges. In RAG vertices are two type –</p>
<p><strong>1. Process vertex –</strong> Every process will be represented as a process vertex.Generally, the process will be represented with a circle.<br/>
<strong>2. Resource vertex –</strong> Every resource will be represented as a resource vertex. It is also two type –</p>
<ul>
<li><strong>Single instance type resource –</strong> It represents as a box, inside the box, there will be one dot.So the number of dots indicate how many instances are present of each resource type.</li>
<li><strong>Multi-resource instance type resource –</strong> It also represents as a box, inside the box, there will be many dots present.</li>
</ul>
<p><img alt="" class="aligncenter size-medium wp-image-242764" src="http://contribute.geeksforgeeks.org/wp-content/uploads/Prjjj1-1.jpg"/></p>
<p>Now coming to the edges of RAG.There are two types of edges in RAG –</p>
<p><strong>1. Assign Edge – </strong> If you already assign a resource to a process then it is called Assign edge.<br/>
<strong>2. Request Edge – </strong> It means in future the process might want some resource to complete the execution, that is called request edge.</p>
<p><img alt="" class="aligncenter size-medium wp-image-242764" src="http://contribute.geeksforgeeks.org/wp-content/uploads/Slide6-1.jpg"/></p>
<p>So, if a process is using a resource, an arrow is drawn from the resource node to the process node. If a process is requesting a resource, an arrow is drawn from the process node to the resource node.</p></div></article><hr style="border: 2px dashed black;" /><article class="post-160840 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-160840">
<header class="entry-header">
<h1 class="entry-title">Operating System | Lottery Process Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite –</b> <a href="https://www.geeksforgeeks.org/gate-notes-operating-system-process-scheduling/">CPU Scheduling</a>, <a href="https://www.geeksforgeeks.org/gate-notes-operating-system-process-management-introduction/">Process Management</a><br/>
<b>Lottery Scheduling</b> is type of process scheduling, somewhat different from other Scheduling. Processes are scheduled in a random manner. Lottery scheduling can be <b>preemptive or non-preemptive</b>. It also solves the problem of starvation. Giving each process at least one lottery ticket guarantees that it has non-zero probability of being selected at each scheduling operation.</p>
<p>In this scheduling every process have some tickets and scheduler picks a random ticket and process having that ticket is the winner and it is executed for a time slice and then another ticket is picked by the scheduler. These tickets represent the share of processes. A process having a higher number of tickets give it more chance to get chosen for execution.</p>
<p><b>Example –</b> If we have two processes A and B having 60 and 40 tickets respectively out of total 100 tickets. CPU share of A is 60% and that of B is 40%.These shares are calculated probabilistically and not deterministically. </p>
<p><b>Explanation –</b></p>
<ol>
<li>We have two processes A and B. A has 60 tickets (ticket number 1 to 60) and B have 40 tickets (ticket no. 61 to 100).</li>
<li>Scheduler picks a random number from 1 to 100. If the picked no. is from 1 to 60 then A is executed otherwise B is executed.</li>
<li>An example of 10 tickets picked by Scheduler may look like this –
<pre>

Ticket number -  73 82 23 45 32 87 49 39 12 09.

Resulting Schedule -  B  B  A  A  A  B  A  A  A  A.

</pre>
</li>
<li>A is executed 7 times and B is executed 3 times. As you can see that A takes 70% of CPU and B takes 30% which is not the same as what we need as we need A to have 60% of CPU and B should have 40% of CPU.This happens because shares are calculated probabilistically but in a long run(i.e when no. of tickets picked is more than 100 or 1000) we can achieve a share percentage of approx. 60 and 40 for A and B respectively.</li>
</ol>
<p><strong>Ways to manipulate tickets –</strong></p>
<ul>
<li><strong>Ticket Currency –</strong><br/>
Scheduler give a certain number of tickets to different users in a currency and users can give it to there processes in a different currency. E.g. Two users A and B are given 100 and 200 tickets respectively. User A is running two process and give 50 tickets to each in A’s own currency. B is running 1 process and gives it all 200 tickets in B’s currency. Now at the time of scheduling tickets of each process are converted into global currency i.e A’s process will have 50 tickets each and B’s process will have 200 tickets and scheduling is done on this basis.</li>
<li><strong>Transfer Tickets –</strong><br/>
A process can pass its tickets to another process.</li>
<li><strong>Ticket inflation –</strong><br/>
With this technique a process can temporarily raise or lower the number of tickets it own.</li>
</ul>
<p><b>References –</b><br/>
<br/>
</p>
<p>This article is contributed by <strong>Ashish Sharma</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/dk619/">dk619</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-160296 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-160296">
<header class="entry-header">
<h1 class="entry-title">Operating System | Highest Response Ratio Next (HRRN) Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite –</b> <br/>
Given n processes with their Arrival times and Burst times, the task is to find average waiting time and average turn around time using HRRN scheduling algorithm.<br/>
The name itself states that we need to find the response ratio of all available processes and select the one with the highest Response Ratio. A process once selected will run till completion.</p>
<p><strong>Criteria – Response Ratio</strong><br/>
<strong> Mode – Non-Preemptive</strong></p>
<pre> Response Ratio = (W + S)/S</pre>
<p>Here, <strong>W</strong> is the waiting time of the process so far and <strong>S</strong> is the Burst time of the process.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-160247 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-160247">
<header class="entry-header">
<h1 class="entry-title">Operating System | Multilevel Feedback Queue Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite –</b> , <br/>
This Scheduling is like Multilevel Queue(MLQ) Scheduling but in this process can move between the queues. <b> Multilevel Feedback Queue Scheduling (MLFQ)</b> keep analyzing the behavior (time of execution) of processes and according to which it changes its priority.Now, look at the diagram and explanation below to understand it properly.<br/>
<img alt="" class="aligncenter size-medium wp-image-234378" height="269" src="http://contribute.geeksforgeeks.org/wp-content/uploads/Multilevel-Feedback-Queue-Scheduling-300x269.png" width="300"><br/>
Now let us suppose that queue 1 and 2 follow round robin with time quantum 4 and 8 respectively and queue 3 follow FCFS.One implementation of MFQS is given below –</img></p>
<ol>
<li>When a process starts executing then it first enters queue 1.</li>
<li>In queue 1 process executes for 4 unit and if it completes in this 4 unit or it gives CPU for I/O operation in this 4 unit than the priority of this process does not change and if it again comes in the ready queue than it again starts its execution in Queue 1.</li>
<li>If a process in queue 1 does not complete in 4 unit then its priority gets reduced and it shifted to queue 2.</li>
<li>Above points 2 and 3 are also true for queue 2 processes but the time quantum is 8 unit.In a general case if a process does not complete in a time quantum than it is shifted to the lower priority queue.</li>
<li>In the last queue, processes are scheduled in FCFS manner.</li>
<li>A process in lower priority queue can only execute only when higher priority queues are empty.</li>
<li>A process running in the lower priority queue is interrupted by a process arriving in the higher priority queue.</li>
</ol>
<p>Well, above implementation may differ for example the last queue can also follow Round-robin Scheduling.</p>
<p><strong>Problems in the above implementation –</strong> A process in the lower priority queue can suffer from starvation due to some short processes taking all the CPU time.<br/>
<strong>Solution –</strong> A simple solution can be to boost the priority of all the process after regular intervals and place them all in the highest priority queue.</p>
<p><strong>What is the need of such complex Scheduling?</strong></p>
<ul>
<li>Firstly, it is more flexible than the multilevel queue scheduling.</li>
<li>To optimize turnaround time algorithms like SJF is needed which require the running time of processes to schedule them. But the running time of the process is not known in advance. MFQS runs a process for a time quantum and then it can change its priority(if it is a long process). Thus it learns from past behavior of the process and then predicts its future behavior.This way it tries to run shorter process first thus optimizing turnaround time.</li>
<li>MFQS also reduces the response time.</li>
</ul>
<p><strong>Example –</strong><br/>
Consider a system which has a CPU bound process, which requires the burst time of 40 seconds.The multilevel Feed Back Queue scheduling algorithm is used and the queue time quantum ‘2’ seconds and in each level it is incremented by ‘5’ seconds.Then how many times the process will be interrupted and on which queue the process will terminate the execution?</p>
<p><strong>Solution –</strong><br/>
Process P needs 40 Seconds for total execution.<br/>
At Queue 1 it is executed for 2 seconds and then interrupted and shifted to queue 2.<br/>
At Queue 2 it is executed for 7 seconds and then interrupted and shifted to queue 3.<br/>
At Queue 3 it is executed for 12 seconds and then interrupted and shifted to queue 4.<br/>
At Queue 4 it is executed for 17 seconds and then interrupted and shifted to queue 5.<br/>
At Queue 5 it executes for 2 seconds and then it completes.<br/>
Hence the process is interrupted 4 times and completes on queue 5.</p>
<p>This article is contributed by <strong>Ashish Sharma</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-159480 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-159480">
<header class="entry-header">
<h1 class="entry-title">Operating System | Shortest Job First scheduling with predicted burst time</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Prerequisite –</b> , , </p>
<p><strong>Shortest Job First (SJF) </strong> is an optimal scheduling algorithm as it gives maximum Throughput and minimum average waiting time(WT) and turn around time (TAT) but it is not practically implementable because Burst-Time of a process can’t be predicted in advance.</p>
<p>We may not know the length of the next CPU burst, but we may be able to predict its value. We expect the next CPU burst will be similar in length to the previous ones. By computing an approximation of the length of the next CPU burst, we can pick the process with the shortest predicted CPU burst.</p>
<p>There are two methods by which we can predict the burst time of the process :</p>
<p><strong>1. Static method –</strong> We can predict the Burst-Time by two factors :</p>
<ul>
<li><strong>Process size –</strong><br/>
Let say we have Process P<sub>old</sub> having size 200 KB which is already executed and its Burst-time is 20 Units of time, now lets say we have a New Process P<sub>new</sub> having size 201 KB which is yet to be executed.<br/>
We take Burst-Time of already executed process P<sub>old</sub> which is almost of same size as that of New process as Burst-Time of New Process P<sub>new</sub>.</li>
<li><strong>Process type –</strong><br/>
We can predict Burst-Time depending on the Type of Process. Operating System process(like scheduler, dispatcher, segmentation, fragmentation) are faster than User process( Gaming, application softwares ). Burst-Time for any New O.S process can be predicted from any old O.S process of similar type and same for User process.</li>
<p><strong>Note –</strong> Static method for burst time prediction is not reliable as it is always not predicted correctly.</p>
<p><strong>2. Dynamic method –</strong> Let t<sub>i</sub></p></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-159223 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-159223">
<header class="entry-header">
<h1 class="entry-title">Operating System | Multilevel Queue Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite : <br/>
It may happen that processes in the ready queue can be divided into different classes where each class has its own scheduling needs. For example, a common division is a <b>foreground (interactive)</b> process and <b>background (batch)</b> processes.These two classes have different scheduling needs. For this kind of situation Multilevel Queue Scheduling is used.Now, let us see how it works.</p>
<p><b>Ready Queue</b> is divided into separate queues for each class of processes. For example, let us take three different types of process System processes, Interactive processes and Batch Processes. All three process have there own queue. Now,look at the below figure.</p>
<p><img alt="" class="aligncenter size-medium wp-image-227027" height="217" src="http://contribute.geeksforgeeks.org/wp-content/uploads/multilevel-queue-schedueling-1-300x217.png" width="300"/></p>
<p>All three different type of processes have there own queue. Each queue have its own Scheduling algorithm. For example, queue 1 and queue 2 uses <b>Round Robin</b> while queue 3 can use <b>FCFS</b> to schedule there processes.   </p>
<p><strong>Scheduling among the queues :</strong> What will happen if all the queues have some processes? Which process should get the cpu? To determine this Scheduling among the queues is necessary. There are two ways to do so –</p>
<ol>
<li><strong>Fixed priority preemptive scheduling method –</strong> Each queue has absolute priority over lower priority queue. Let us consider following priority order <strong>queue 1 &gt; queue 2 &gt; queue 3</strong>.According to this algorithm no process in the batch queue(queue 3) can run unless queue 1 and 2 are empty. If any batch process (queue 3) is running and any system (queue 1) or Interactive process(queue 2) entered the ready queue the batch process is preempted.</li>
<li><strong>Time slicing</strong> – In this method each queue gets certain portion of CPU time and can use it to schedule its own processes.For instance, queue 1 takes 50 percent of CPU time queue 2 takes 30 percent and queue 3 gets 20 percent of CPU time.</li>
</ol>
<p><strong>Example Problem :</strong><br/>
Consider below table of four processes under Multilevel queue scheduling.Queue number denotes the queue of the process.</p>
<p><img alt="" class="alignnone wp-image-232985" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Multilevel-Process-Queue-1.png"/></p>
<p>Priority of queue 1 is greater than queue 2. queue 1 uses Round Robin (Time Quantum = 2) and queue 2 uses FCFS.</p>
<p>Below is the <b>gantt chart</b> of the problem :</p>
<p><img alt="" class="alignnone wp-image-232986" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Gantt-Chart-Multilevel-Queue.png"/></p>
<p>At starting both queues have process so process in queue 1 (P1, P2) runs first (because of higher priority) in the round robin fashion and completes after 7 units then process in queue 2 (P3) starts running (as there is no process in queue 1) but while it is running P4 comes in queue 1 and interrupts P3 and start running for 5 second and after its completion P3 takes the CPU and completes its execution.</p>
<p>This article is contributed by <strong>Ashish Sharma</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-157820 post type-post status-publish format-standard hentry category-greedy category-operating-systems" id="post-157820">
<header class="entry-header">
<h1 class="entry-title">Operating System | Program for Next Fit algorithm in Memory Management</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="http://quiz.geeksforgeeks.org/operating-system-memory-management-partition-allocation-method/">Partition allocation methods</a><br/>
<strong>What is Next Fit ?</strong><br/>
Next fit is a modified version of <a href="https://www.geeksforgeeks.org/program-first-fit-algorithm-memory-management/">‘first fit’</a>. It begins as the first fit to find a free partition but when called next time it starts searching from where it left off, not from the beginning. This policy makes use of a roving pointer. The pointer moves along the memory chain to search for a next fit. This helps in, to avoid the usage of memory always from the head (beginning) of the free block chain. </p>
<p><strong>What are its advantage over first fit ?</strong></p>
<ul>
<li>First fit is a straight and fast algorithm, but tends to cut large portion of free parts into small pieces due to which, processes that need a large portion of memory block would not get anything even if the sum of all small pieces is greater than it required which is so-called external fragmentation problem.</li>
<li>Another problem of the first fit is that it tends to allocate memory parts at the beginning of the memory, which may lead to more internal fragments at the beginning. Next fit tries to address this problem by starting the search for the free portion of parts not from the start of the memory, but from where it ends last time.</li>
<li>Next fit is a very fast searching algorithm and is also comparatively faster than First Fit and Best Fit Memory Management Algorithms.</li>
</ul>
<pre>

<strong>Example:</strong>

Input :  blockSize[] = {5, 10, 20};

     processSize[] = {10, 20, 30};

Output:

Process No.     Process Size    Block no.

 1              10              2

 2              20              3

 3              30              Not Allocated



</pre>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p><strong>Algorithm:</strong> </p>
<ol>
<li>Input the number of memory blocks and their sizes and initializes all the blocks as free.</li>
<li>Input the number of processes and their sizes.</li>
<li>Start by picking each process and check if it can be assigned to the current block, if yes, allocate it the required memory and check for next process but from the block where we left not from starting.</li>
<li>
If the current block size is smaller then keep checking the further blocks.</li>
</ol>
<p><a href="https://media.geeksforgeeks.org/wp-content/uploads/next-fit-algorithm-operating-system.png"><img alt="Next-Fit" class="alignnone size-full wp-image-176290" height="521" src="https://media.geeksforgeeks.org/wp-content/uploads/next-fit-algorithm-operating-system.png" width="870"/></a></p>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-157257 post type-post status-publish format-standard hentry category-algorithm category-gate-cs category-operating-systems" id="post-157257">
<header class="entry-header">
<h1 class="entry-title">Operating System | Peterson’s Algorithm (Using processes and shared memory)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite – <a href="https://www.geeksforgeeks.org/process-synchronization-set-1/">synchronization</a>, <a href="https://www.geeksforgeeks.org/g-fact-70/">Critical Section</a></p>
<p><!-- Problem Statement --></p>
<p><b>Problem:</b>The producer consumer problem (or bounded buffer problem) describes two processes, the producer and the consumer, which share a common, fixed-size buffer used as a queue. Producer produce an item and put it into buffer. If buffer is already full then producer will have to wait for an empty block in buffer. Consumer consume an item from buffer. If buffer is already empty then consumer will have to wait for an item in buffer. Implement Peterson’s Algorithm for the two processes using shared memory such that there is mutual exclusion between them. The solution should have free from synchronization problems.</p>
<p><img alt="Producer-Consumer" src="http://contribute.geeksforgeeks.org/wp-content/uploads/producer-consumer.png"/></p>
<p><b>Peterson’s algorithm –</b></p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-157176 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-157176">
<header class="entry-header">
<h1 class="entry-title">Operating System | Memory management – mapping virtual address to physical addresses</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Memory consists of large array of words or arrays, each of which has address associated with it. Now the work of CPU is to fetch instructions from the memory based program counter. Now further these instruction may cause loading or storing to specific memory address. </p>
<p>Address binding is the process of mapping from one address space to another address space. Logical address is address generated by CPU during execution whereas Physical Address refers to location in memory unit(the one that is loaded into memory).Note that user deals with only logical address(Virtual address). The logical address undergoes translation by the MMU or address translation unit in particular. The output of this process is the appropriate physical address or the location of code/data in RAM. </p>
<p>An address binding can be done in three different ways:</p>
<p><b> Compile Time –</b> If you know that during compile time where process will reside in memory then absolute address is generated i.e physical address is embedded to the executable of the program during compilation. Loading the executable as a process in memory is very fast. But if the generated address space is preoccupied by other process, then the program crashes and it becomes necessary to recompile the program to change the address space.</p>
<p><b> Load time –</b> If it is not known at the compile time where process will reside then relocatable address will be generated. Loader translates the relocatable address to absolute address. The base address of the process in main memory is added to all logical addresses by the loader to generate absolute address. In this if the base address of the process changes then we need to reload the process again. </p>
<p><b> Execution time-</b> The instructions are in memory and are being processed by the CPU. Additional memory may be allocated and/or deallocated at this time. This is used if process can be moved from one memory to another during execution(dynamic linking-Linking that is done during load or run time). e.g – Compaction.</p>
<p><b>MMU(Memory Management Unit)-</b><br/>
The run time mapping between Virtual address and Physical Address is done by hardware device known as MMU.</p>
<p>In memory management, Operating System will handle the processes and moves the processes between disk and memory for execution . It keeps the track of available and used memory.</p>
<p><b>Instruction-execution cycle Follows steps:</b></p>
<ol>
<li> First instruction is fetched from memory e.g. ADD A,B </li>
<li> Then these instructions are decoded i.e., Addition of A and B </li>
<li> And further loading or storing at some particular memory location takes place. </li>
</ol>
<p><b>Basic Hardware</b></p>
<p>As main memory and registers are built into processor and CPU can access these only.So every instructions should be written in direct access storage<br/>
devices.</p>
<ol>
<li> If CPU access instruction from register then it can be done in one CPU clock cycle as registers are built into CPU.</li>
<li> If instruction resides in main memory then it will be accessed via memory bus that will take lot of time. So remedy to this add fast memory in between CPU and main memory i.e. adding cache for transaction.</li>
<li> Now we should insure that process resides in legal address.</li>
<li> Legal address  consists of base register(holds smallest physical address) and limit register(size of range).</li>
</ol>
<p>For example:</p>
<pre>

Base register = 300040

limit register = 120900 

then legal address = (300040+120900)= 420940(inclusive).

legal address = base register+ limit register

</pre>
<p><b>How processes are  mapped from disk to memory</b></p>
<ol>
<li> Usually process resides in disk in form of binary executable file.</li>
<li> So to execute process it should reside in main memory.</li>
<li> Process is moved from disk to memory based on memory management in use.</li>
<li> The processes waits in disk in form of ready queue to acquire memory.</li>
</ol>
<p><b>Procedure of mapping of disk and memory </b> </p>
<p>Normal procedure is that process is selected from input queue and loaded in memory. As process executes it accesses data and instructions from memory and  as soon as it completes it will release memory and now memory will be available for other processes.</p>
<p><b>MMU scheme –</b></p>
<pre> CPU------- MMU------Memory </pre>
<p><img alt="MMU scheme" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operating_system.png"/></p>
<ol>
<li> CPU will generate logical address for eg: 346 </li>
<li> MMU will generate relocation register(base register) for eg:14000 </li>
<li> In Memory physical address is located eg:(346+14000= 14346) </li>
</ol>
<p><b>Reference and Image Source</b>:<br/>
<a href="https://users.dimi.uniud.it/~antonio.dangelo/OpSys/materials/Operating_System_Concepts.pdf">https://users.dimi.uniud.it/~antonio.dangelo/OpSys/materials/Operating_System_Concepts.pdf</a><br/>
This article is contributed by <b>Vaishali Bhatia</b>.If you like GeeksforGeeks and would like to contribute, you can also write an article using contribute.geeksforgeeks.org or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/NEERAJ NEGI/">NEERAJ NEGI</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-157124 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-157124">
<header class="entry-header">
<h1 class="entry-title">Operating System | Semaphores in operating system</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="https://www.geeksforgeeks.org/process-synchronization-set-1/">process-synchronization</a>, <a href="https://www.geeksforgeeks.org/mutex-vs-semaphore/">Mutex vs Semaphore</a></p>
<p>Semaphore is simply a variable. This variable is used to solve the critical section problem and to achieve process synchronization in the multiprocessing environment.<br/>
The two most common kinds of semaphores are counting semaphores and binary semaphores. Counting semaphore can take non-negative integer values and Binary semaphore can take the value 0 &amp; 1. only. </p>
<p>Now let us see how it do so.</p>
<p>First, look at two operations which can be used to access and change the value of the semaphore variable.</p>
<p><img alt="P-and-V-operation-in-OS" class="aligncenter size-full wp-image-157196" height="271" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/Semaphores_1.png" width="316"/></p>
<p><strong>Some point regarding P and V operation</strong></p>
<ol>
<li>P operation is also called wait, sleep or down operation and V operation is also called signal, wake-up or up operation.</li>
<li>Both operations are atomic and semaphore(s) is always initialized to one.</li>
<li>A critical section is surrounded by both operations to implement process synchronization.See below image.critical section of Process P is in between P and V operation.</li>
</ol>
<p><img alt="" class="aligncenter size-full wp-image-220407" height="209" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/Semaphores_2.png" width="233"/></p>
<p>Now, let us see how it implements mutual exclusion. Let there be two processes P1 and P2 and a semaphore s is initialized as 1. Now if suppose P1 enters in its critical section then the value of semaphore s becomes 0. Now if P2 wants to enter its critical section then it will wait until s &gt; 0, this can only happen when P1 finishes its critical section and calls V operation on semaphore s. This way mutual exclusion is achieved. Look at the below image for details.</p>
<p><img alt="" class="aligncenter size-medium wp-image-220486" height="380" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/Semaphores_3.jpg" width="238"/></p>
<p>The description above is for binary semaphore which can take only two values 0 and 1. There is one other type of semaphore called counting semaphore which can take values greater than one.</p>
<p>Now suppose there is a resource whose number of instance is 4. Now we initialize S = 4 and rest is same as for binary semaphore. Whenever process wants that resource it calls  P or wait function and when it is done it calls V or signal function. If the value of S becomes zero then a process has to wait until S becomes positive. For example, Suppose there are 4 process P1, P2, P3, P4 and they all call wait operation on S(initialized with 4). If another process P5 wants the resource then it should wait until one of the four processes calls signal function and value of semaphore becomes positive.</p>
<p><strong>Problem in this implementation of semaphore </strong></p>
<p>Whenever any process waits then it continuously checks for semaphore value (look at this line while (s==0); in P operation) and waste CPU cycle. To avoid this another implementation is provided below.</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-157094 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-157094">
<header class="entry-header">
<h1 class="entry-title">Operating System | Dining-Philosophers Solution Using Monitors</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="https://www.geeksforgeeks.org/monitors/">Monitor</a>, <a href="https://www.geeksforgeeks.org/process-synchronization-set-1/">Process Synchronization</a></p>
<p><b>Dining-Philosophers Problem – </b> N philosophers seated around a circular table </p>
<p><img alt="" class="aligncenter size-medium wp-image-220413" height="300" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operating_system_din.png" width="300"/></p>
<ul>
<li> There is one chopstick between each philosopher </li>
<li> A philosopher must pick up its two nearest chopsticks in order to eat </li>
<li> A philosopher must pick up first one chopstick, then the second one, not both at once </li>
</ul>
<p>We need an algorithm for allocating these limited resources(chopsticks) among several processes(philosophers) such that solution is free from deadlock and free from starvation. </p>
<p>There exist some algorithm to solve Dining – Philosopher Problem, but they may have deadlock situation. Also, a deadlock-free solution is not necessarily starvation-free. Semaphores can result in deadlock due to programming errors. Monitors alone are not sufficiency to solve this, we need monitors with <em>condition variables</em> </p>
<p><b> Monitor-based Solution to Dining Philosophers </b></p>
<p>We illustrate monitor concepts by presenting a deadlock-free solution to the dining-philosophers problem. Monitor is used to control access to state variables and condition variables. It only tells when to enter and exit the segment. This solution imposes the restriction that a philosopher may pick up her chopsticks only if both of them are available.</p>
<p>To code this solution, we need to distinguish among three states in which we may find a philosopher. For this purpose, we introduce the following data structure: </p>
<p><b>THINKING – </b> When philosopher doesn’t want to gain access to either fork.</p>
<p><b>HUNGRY – </b> When philosopher wants to enter the critical section.</p>
<p><b>EATING – </b> When philosopher has got both the forks, i.e., he has entered the section.</p>
<p>Philosopher i can set the variable state[i] = EATING only if her two neighbors are not eating<br/>
(state[(i+4) % 5] != EATING) and (state[(i+1) % 5] != EATING).</p>
<div class="noIdeBtnDiv">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-156511 post type-post status-publish format-standard hentry category-operating-systems" id="post-156511">
<header class="entry-header">
<h1 class="entry-title">Operating System | Remote Procedure call (RPC)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Remote Procedure Call (RPC)</strong> is a powerful technique for constructing <strong>distributed, client-server based applications</strong>. It is based on extending the conventional local procedure calling, so that the <strong>called procedure need not exist in the same address space as the calling procedure</strong>. The two processes may be on the same system, or they may be on different systems with a network connecting them. </p>
<p><strong><u> When making a Remote Procedure Call:</u></strong></p>
<p><img alt="" class="alignnone size-full wp-image-198340" height="353" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operating-system-remote-procedure-call-1.png" width="500"/></p>
<p><strong>1.</strong> The calling environment is suspended, procedure parameters are transferred across the network to the environment where the procedure is to execute, and the procedure is executed there.</p>
<p><strong>2.</strong> When the procedure finishes and produces its results, its results are transferred back to the calling environment, where execution resumes as if returning from a regular procedure call.</p>
<p><strong>NOTE: RPC</strong> is especially well suited for client-server<strong> (e.g. query-response) </strong> interaction in which the flow of control <strong>alternates between the caller and callee</strong>. Conceptually, the client and server do not both execute at the same time. Instead, the thread of execution jumps from the caller to the callee and then back again.</p>
<p> <u><strong>Working of RPC</strong></u></p>
<p><img alt="" class="alignnone size-full wp-image-198375" height="388" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operating-system-remote-call-procedure-working.png" width="500"/></p>
<p><strong>The following steps take place during a RPC:</strong></p>
<p><strong>1.</strong> A client invokes a <strong>client stub procedure</strong>, passing parameters in the usual way. The client stub resides within the client’s own address space.</p>
<p><strong>2.</strong> The client stub <strong>marshalls(pack)</strong> the parameters into a message. Marshalling includes converting the representation of the parameters into a standard format, and copying each parameter into the message.</p>
<p><strong>3.</strong> The client stub passes the message to the transport layer, which sends it to the remote server machine.</p>
<p><strong>4.</strong> On the server, the transport layer passes the message to a server stub, which <strong>demarshalls(unpack)</strong> the parameters and calls the desired server routine using the regular procedure call mechanism.</p>
<p><strong>5.</strong> When the server procedure completes, it returns to the server stub <strong>(e.g., via a normal procedure call return)</strong>, which marshalls the return values into a message. The server stub then hands the message to the transport layer.</p>
<p><strong>6.</strong> The transport layer sends the result message back to the client transport layer, which hands the message back to the client stub.</p>
<p><strong>7.</strong> The client stub demarshalls the return parameters and execution returns to the caller.</p>
<p><u><strong>RPC ISSUES</strong></u></p>
<ul>
<li><strong>Issues that must be addressed:</strong></li>
</ul>
<p><strong>1. RPC Runtime:</strong> RPC run-time system, is a library of routines and a set of services that handle the network communications that underlie the RPC mechanism. In the course of an RPC call, client-side and server-side run-time systems’ code handle <strong>binding, establish communications over an appropriate protocol, pass call data between the client and server, and handle communications errors.</strong></p>
<p><strong>2. Stub:</strong> The function of the stub is to <strong>provide transparency to the programmer-written application code</strong>. </p>
<p><strong>On the client side</strong>, the stub handles the interface between the client’s local procedure call and the run-time system, marshaling and unmarshaling data, invoking the RPC run-time protocol, and if requested, carrying out some of the binding steps. </p>
<p><strong>On the server side</strong>, the stub provides a similar interface between the run-time system and the local manager procedures that are executed by the server.</p>
<p><strong>3. Binding: How does the client know who to call, and where the service resides?</strong> </p>
<p>The most flexible solution is to use dynamic binding and find the server at run time when the RPC is first made. The first time the client stub is invoked, it contacts a name server to determine the transport address at which the server resides.</p>
<p><strong> Binding consists of two parts:</strong></p>
<ul>
<li><u>Naming:</u></li>
<p>  Remote procedures are named through interfaces. <strong>An interface uniquely identifies a particular service, describing the types and numbers of its arguments</strong>. It is similar in purpose to a type definition in programming languauges.</p>
<li><u>Locating:</u></li>
<p> Finding the transport address at which the server actually resides. Once we have the transport address of the service, we can send messages directly to the server.
</p></ul>
<p><strong>A Server</strong> having a service to offer exports an interface for it. Exporting an interface registers it with the system so that clients can use it.</p>
<p><strong>A Client</strong> must import an (exported) interface before communication can begin.</p>
<p><u><strong>ADVANTAGES</strong></u></p>
<p><strong>1.</strong> RPC provides <strong>ABSTRACTION</strong>  i.e message-passing nature of network communication is hidden from the user.</p>
<p><strong>2.</strong> RPC often omits many of the protocol layers to improve performance. Even a small performance improvement is important because a program may invoke RPCs often. </p>
<p><strong>3.</strong> RPC enables the usage of the applications in the distributed environment, not only in the local environment.</p>
<p><strong>4.</strong> With RPC code re-writing / re-developing effort is minimized.</p>
<p><strong>5.</strong> Process-oriented and thread oriented models supported by RPC.</p>
<p><strong>Refrences:</strong></p>
<ul>
<li><a href="https://web.cs.wpi.edu/~cs4514/b98/week8-rpc/week8-rpc.html">https://web.cs.wpi.edu/~cs4514/b98/week8-rpc/week8-rpc.html</a></li>
<li><a href="https://users.cs.cf.ac.uk/Dave.Marshall/C/node33.html">https://users.cs.cf.ac.uk/Dave.Marshall/C/node33.html</a></li>
</ul>
<p>This article is contributed by <strong>Yash Singla</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-155379 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems tag-linux-command" id="post-155379">
<header class="entry-header">
<h1 class="entry-title">Tracing memory usage in Linux</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Often it’s necessary to trace memory usage of the system in order to determine the program that consumes all CPU resources or the program that is responsible to slowing down the activities of the CPU. Tracing memory usage also becomes necessary to determine the load on the server. Parsing the usage data enables the servers to be able to balance the load and serve the user’s request without slowing down the system.</p>
<ol>
<li><strong>free </strong> Displays the amount of memory which is currently available and used by the system(both physical and swapped). free command gathers this data by parsing /proc/meminfo. By default, the amount of memory is display in kilobytes.
<p align="center"><strong>free command in UNIX</strong></p>
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-16-35-e1496478387353.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-16-35-e1496478387353.png"/></a></p>
<pre><strong>watch -n 5 free -m</strong> watch command is used to execute a program periodically.</pre>
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-46-53-e1496478442792.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-46-53-e1496478442792.png"/></a></p>
<p>    According to the image above, there is a total of 2000 MB of RAM and 1196 MB of swap space allotted to Linux system. Out of this 2000 MB of RAM, 834 MB is currently used where as 590 MB is free. Similarly for swap space, out of 1196 MB, 0 MB is use and 1196 MB is free currently in the system.</p>
</li>
<li><strong>vmstat</strong>  vmstat command is used to display virtual memory statistics of the system. This command reports data about the memory, paging, disk and CPU activities, etc. The first use of this command returns the data averages since the last reboot. Further uses returns the data based on sampling periods of length delays.
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-21-16-e1496478359885.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-21-16-e1496478359885.png"/></a></p>
<pre><strong>vmstat -d</strong> Reports disk statistics</pre>
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-21-50.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-21-50.png"/></a></p>
<pre><strong>vmstat -s </strong>Displays the amount of memory used and available</pre>
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-22-54-e1496478489876.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-22-54-e1496478489876.png"/></a></p>
</li>
<li><strong>top</strong>  top command displays all the currently running process in the system. This command displays the list of processes and thread currently being handled by the kernel. top command can also be used to monitor the total amount of memory usage.
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-31-08.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-31-08.png"/></a></p>
<pre><strong> top -H</strong> Threads-mode operation

    Displays individual thread that are currently in the system. Without this command 

option, a summation of all thread in each process is displayed.</pre>
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-34-39.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-34-39.png"/></a></p>
</li>
<li><strong>/proc/meminfo</strong>  This file contains all the data about the memory usage. It provides the current memory usage details rather than old stored values.
<p> <a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-42-25-e1496478415564.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-11-42-25-e1496478415564.png"/></a></p>
</li>
<li><strong>htop </strong> htop is an interactive process viewer. This command is similar to top command except that it allows to scroll vertically and horizontally to allows users to view all processes running on the system, along with their full command line as well as viewing them as a process tree, selecting multiple processes and acting on them all at once.
<p align="center"><strong>working of htop command in UNIX:</strong></p>
<p><a href="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-13-48-49.png"><img src="http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-06-03-13-48-49.png"/></a></p>
</li></ol>
<p><strong>Reference:</strong></p>
<ul>
<li><strong><a href="http://manpages.ubuntu.com/">Ubuntu Manual</a></strong></li>
</ul>
<p>This article is contributed by <strong><a href="https://www.linkedin.com/in/mayank-kumar-a9058b137/">Mayank Kumar</a></strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-153943 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems" id="post-153943">
<header class="entry-header">
<h1 class="entry-title">Operating System | Starvation and Aging  in Operating Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Prerequisites : </strong> </p>
<p>We have already discussed about the priority scheduling in  post. It is one of the most common scheduling algorithms in batch systems. Each process is assigned a priority. Process with the highest priority is to be executed first and so on.</p>
<p>In this post we will discuss a major problem related to priority scheduling and it’s solution.</p>
<p><strong>Starvation</strong> or indefinite blocking is phenomenon associated with the Priority scheduling algorithms, in which a process ready to run for CPU can wait indefinitely because of low priority. In heavily loaded computer system, a steady stream of higher-priority processes can prevent a low-priority process from ever getting the CPU.</p>
<p>There has been rumors that in 1967 Priority Scheduling was used in IBM 7094 at MIT , and  they found a low-priority process that had not been submitted till 1973.</p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/starvationAndAging.jpg"><img alt="prior" class="alignnone size-full wp-image-164878" height="251" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/starvationAndAging.jpg" width="1170"/></a></p>
<p>As we see in the above example process having higher priority than other processes getting CPU earlier. We can think of a scenario in which only one process is having very low-priority (for example 127) and we are giving other process with high-priority, this can lead indefinitely waiting for the process for CPU which is having low-priority, this leads to <strong>Starvation</strong>. Further we have also discuss about the solution of starvation.</p>
<p><strong>Differences between  and Starvation in OS :</strong></p>
<ol>
<li>
Deadlock occurs when none of the processes in the set is able to move ahead due to occupancy of the required resources by some other process as shown in the figure below, on the other hand Starvation occurs when a process waits for an indefinite period of time to get the resource it requires.
</li>
<li>
Other name of deadlock is <strong>Circular Waiting</strong>. Other name of starvation is <strong>Lived lock</strong>.
</li>
<li>
When deadlock occurs no process can make progress, while in starvation apart from the victim process other processes can progress or proceed.
</li>
</ol>
<p><strong>Solution to Starvation : Aging</strong></p>
<p>Aging is a technique of gradually increasing the priority of processes that wait in the system for a long time.For example, if priority range from 127(low) to 0(high), we could increase the priority of a waiting process by 1 Every 15 minutes. Eventually even a process with an initial priority of 127 would take no more than 32 hours for priority 127 process to age to a priority-0 process.</p>
<p><img alt="" class="size-medium wp-image-207906" height="400" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/startvationAndAging.jpg" width="600"> </img></p>
<p>This article is contributed by <strong>Saloni Gupta</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-151429 post type-post status-publish format-standard hentry category-greedy category-operating-systems tag-cpu-scheduling" id="post-151429">
<header class="entry-header">
<h1 class="entry-title">Program for Shortest Job First (SJF) scheduling | Set 2 (Preemptive)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><!-- Problem Statement --><br/>
In previous post, we have discussed <a href="https://www.geeksforgeeks.org/program-shortest-job-first-sjf-scheduling-set-1-non-preemptive/">Set 1</a> of SJF i.e. non-preemptive. In this post we will discuss the preemptive version of SJF known as Shortest Remaining Time First (SRTF).</p>
<p>In this scheduling algorithm, the process with the smallest amount of time remaining until completion is selected to execute. Since the currently executing process is the one with the shortest amount of time remaining by definition, and since that time should only reduce as execution progresses, processes will always run until they complete or a new process is added that requires a smaller amount of time.</p>
<h3>Preemptive SJF: Example</h3>
<table width="100%">
<thead>
<tr>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Process</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Duration</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Order</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Arrival Time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P1</td>
<td style="text-align:center">9</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td>P2</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<p><img alt="Preemptive-SJF-Diagram" class="aligncenter size-full wp-image-198028" height="446" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Preemptive-SJF-Diagram.png" width="595"/></p>
<p><b>P1 waiting time: 4-2 = 2<br/>P2 waiting time: 0<br/>The average waiting time(AWT): (0 + 2) / 2 = 1</b></p>
<p><b>Advantage:</b><br/>
1- Short processes are handled very quickly.<br/>
2- The system also requires very little overhead since it only makes a decision when a process completes or a new process is added.<br/>
3- When a new process is added the algorithm only needs to compare the currently executing process with the new process, ignoring all other processes currently waiting to execute.</p>
<p><b>Disadvantage:</b><br/>
1- Like shortest job first, it has the potential for process starvation.<br/>
2- Long processes may be held off indefinitely if short processes are continually added.</p>
<p>Source:<a href="https://en.wikipedia.org/wiki/Shortest_remaining_time">Wiki</a></p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<pre>

<b>Implementation:</b>

1- Traverse until all process gets completely

   executed.

   a) Find process with minimum remaining time at

     every single time lap.

   b) Reduce its time by 1.

   c) Check if its remaining time becomes 0 

   d) Increment the counter of process completion.

   e) Completion time of current process = 

     current_time +1;

   e) Calculate waiting time for each completed 

     process.

   wt[i]= Completion time - arrival_time-burst_time

   f)Increment time lap by one.

2- Find turnaround time (waiting_time+burst_time).

</pre>
<div class="responsive-tabs">
<h2 class="tabtitle">C/C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-149314 post type-post status-publish format-standard hentry category-gate-cs category-java category-operating-systems tag-java-multithreading tag-os-process-synchronization" id="post-149314">
<header class="entry-header">
<h1 class="entry-title">Producer-Consumer solution using Semaphores in Java | Set 2</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisites – <a href="https://www.geeksforgeeks.org/semaphore-in-java/">Semaphore in Java</a>, , </p>
<p>In computing, the producer–consumer problem (also known as the bounded-buffer problem) is a classic example of a multi-process synchronization problem. The problem describes two processes, the producer and the consumer, which share a common, fixed-size buffer used as a queue.</p>
<ul>
<li>The producer’s job is to generate data, put it into the buffer, and start again.</li>
<li>At the same time, the consumer is consuming the data (i.e. removing it from the buffer), one piece at a time.</li>
</ul>
<p><strong>Problem : </strong>To make sure that the producer won’t try to add data into the buffer if it’s full and that the consumer won’t try to remove data from an empty buffer.</p>
<p><strong>Solution : </strong>The producer is to either go to sleep or discard data if the buffer is full. The next time the consumer removes an item from the buffer, it notifies the producer, who starts to fill the buffer again. In the same way, the consumer can go to sleep if it finds the buffer to be empty. The next time the producer puts data into the buffer, it wakes up the sleeping consumer.<br/>
<strong>An inadequate solution could result in a deadlock</strong> where both processes are waiting to be awakened.</p>
<p>In the post <a href="https://www.geeksforgeeks.org/producer-consumer-solution-using-threads-java/">Producer-Consumer solution using threads in Java,</a> we have discussed above solution by using  <a href="https://www.geeksforgeeks.org/inter-thread-communication-java/">inter-thread communication</a>(wait(), notify(), sleep()). In this post, we will use <a href="https://www.geeksforgeeks.org/semaphore-in-java/">Semaphores</a> to implement the same.</p>
<p><strong>The below solution consists of four classes:</strong></p>
<ol>
<li><strong>Q</strong> : the queue that you’re trying to synchronize</li>
<li><strong>Producer :</strong> the threaded object that is producing queue entries</li>
<li><strong>Consumer : </strong>the threaded object that is consuming queue entries</li>
<li><strong>PC : </strong>the driver class that creates the single Q, Producer, and Consumer.</li>
</ol>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-148812 post type-post status-publish format-standard hentry category-gate-cs category-greedy category-operating-systems" id="post-148812">
<header class="entry-header">
<h1 class="entry-title">Program for Page Replacement Algorithms | Set 1 ( LRU)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="https://www.geeksforgeeks.org/operating-system-page-replacement-algorithm/">Page Replacement Algorithms</a></p>
<p>In operating systems that use paging for memory management, page replacement algorithm are needed to decide which page needed to be replaced when new page comes in. Whenever a new page is referred and not present in memory, page fault occurs and Operating System replaces one of the existing pages with newly needed page.  Different page replacement algorithms suggest different ways to decide which page to replace. The target for all algorithms is to reduce number of page faults.</p>
<p>In <strong>L</strong>east <strong>R</strong>ecently <strong>U</strong>sed (LRU) algorithm is a Greedy algorithm where the page to be replaced is least recently used. The idea is based on locality of reference, the least recently used page is not likely </p>
<p>Let say the page reference string 7 0 1 2 0 3 0 4 2 3 0 3 2 . Initially we have 4 page slots empty.<br/>
Initially all slots are empty, so when 7 0 1 2 are allocated to the empty slots —&gt;<strong> 4 Page faults</strong><br/>
0 is already their so —&gt; <strong>0 Page fault.</strong><br/>
when 3 came it will take the place of 7 because it is least recently used —&gt;<strong>1 Page fault</strong><br/>
0 is already in memory so —&gt;<strong> 0 Page fault</strong>.<br/>
4 will takes place of 1 —&gt;<strong> 1 Page Fault</strong><br/>
Now for the further page reference string —&gt;<strong> 0 Page fault</strong> because they are already available in the memory.</p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/LRU-page-replacement.png"><img alt="LRU" class="alignnone size-full wp-image-148815" height="231" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/LRU-page-replacement.png" width="468"/></a></p>
<p><em><strong>Given memory capacity (as number of pages it can hold) and a string representing pages to be referred, write a function to find number of page faults.</strong></em></p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2>
<a href="https://practice.geeksforgeeks.org/problems/page-faults-in-lru/0">Recommended: Please solve it on “<b><i><u>PRACTICE</u></i></b> ” first, before moving on to the solution.</a><br/>
</h2>
</div></div></article><hr style="border: 2px dashed black;" /><article class="post-148364 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems tag-linux-command" id="post-148364">
<header class="entry-header">
<h1 class="entry-title">Important Linux Commands (leave, diff, cal, ncal, locate and ln)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Linux provides some important tricks. Here’s a few and important one’s:</p>
<ol>
<li><strong>leave</strong> — remind you when you have to leave<br/>
<strong>Syntax:</strong></li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-148353 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems tag-linux-command tag-linux-misc-commands" id="post-148353">
<header class="entry-header">
<h1 class="entry-title">‘crontab’ in Linux with Examples</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>The <strong>crontab</strong> is a list of commands that you want to run on a regular schedule, and also the name of the command used to manage that list. Crontab stands for “cron table, ” because it uses the job scheduler <em>cron</em> to execute tasks; <em>cron</em> itself is named after “chronos, ” the Greek word for time.<em>cron</em> is the system process which will automatically perform tasks for you according to a set schedule. The schedule is called the crontab, which is also the name of the program used to edit that schedule.</p>
<p><strong>Linux Crontab Format</strong></p>
<pre>

MIN HOUR DOM MON DOW CMD

</pre>
<p><strong>Crontab Fields and Allowed Ranges (Linux Crontab Syntax)</strong></p>
<pre>

<strong>Field    Description    Allowed Value</strong>

MIN      Minute field    0 to 59

HOUR     Hour field      0 to 23

DOM      Day of Month    1-31

MON      Month field     1-12

DOW      Day Of Week     0-6

CMD      Command         Any command to be executed.

</pre>
<p><strong>Examples of Cron jobs</strong><br/>
<strong>1. Scheduling a Job For a Specific Time</strong></p>
<p>The basic usage of cron is to execute a job in a specific time as shown below. This will execute the Full backup shell script (full-backup) on 10th June 08:30 AM.</p>
<p>The time field uses 24 hours format. So, for 8 AM use 8, and for 8 PM use 20.</p>
<pre>

30 08 10 06 * /home/maverick/full-backup

</pre>
<p>30 – 30th Minute<br/>
08 – 08 AM<br/>
10 – 10th Day<br/>
06 – 6th Month (June)<br/>
* – Every day of the week</p>
<p><strong>2.To view the Crontab entries</strong></p>
<ul>
<li>View Current Logged-In User’s Crontab entries : To view your crontab entries type crontab -l from your unix account.<br/>
<img alt="" class="alignnone size-medium wp-image-188578" height="411" src="https://media.geeksforgeeks.org/wp-content/uploads/cron1-1.png" width="647"/></li>
<li>View Root Crontab entries : Login as root user (su – root) and do crontab -l.
<p><img alt="" class="alignnone size-medium wp-image-188583" height="119" src="https://media.geeksforgeeks.org/wp-content/uploads/cron2.png" width="505"/></p></li>
<li>To view crontab entries of other Linux users : Login to root and use -u {username} -l.<br/>
<img alt="" class="alignnone size-medium wp-image-188586" height="437" src="https://media.geeksforgeeks.org/wp-content/uploads/cron3.png" width="736"/></li>
</ul>
<p><strong>3.To edit Crontab Entries</strong><br/>
Edit Current Logged-In User’s Crontab entries.To edit a crontab entries, use crontab -e. By default this will edit the current logged-in users crontab.<br/>
<img alt="" class="alignnone size-medium wp-image-188591" height="435" src="https://media.geeksforgeeks.org/wp-content/uploads/cron4.png" width="736"><br/>
<strong>4.To schedule a job for every minute using Cron.</strong><br/>
Ideally you may not have a requirement to schedule a job every minute. But understanding this example will will help you understand the other examples.</img></p>
<pre>

* * * * * CMD

</pre>
<p>The * means all the possible unit — i.e every minute of every hour through out the year. More than using this * directly, you will find it very useful in the following cases.</p>
<p>When you specify */5 in minute field means every 5 minutes.<br/>
When you specify 0-10/2 in minute field mean every 2 minutes in the first 10 minute.<br/>
Thus the above convention can be used for all the other 4 fields.<br/>
<strong>5.To schedule a job for more than one time (e.g. Twice a Day)</strong></p>
<p>The following script take a incremental backup twice a day every day.</p>
<p>This example executes the specified incremental backup shell script (incremental-backup) at 11:00 and 16:00 on every day. The comma separated value in a field specifies that the command needs to be executed in all the mentioned time.</p>
<pre>

00 11, 16 * * * /home/maverick/bin/incremental-backup

</pre>
<p>00 – 0th Minute (Top of the hour)<br/>
11, 16 – 11 AM and 4 PM<br/>
* – Every day<br/>
* – Every month<br/>
* – Every day of the week</p>
<p><strong>6.To schedule a job for certain range of time (e.g. Only on Weekdays)</strong></p>
<p>If you wanted a job to be scheduled for every hour with in a specific range of time then use the following.</p>
<ul>
<li>Cron Job everyday during working hours :<br/>
This example checks the status of the database everyday (including weekends) during the working hours 9 a.m – 6 p.m</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-147567 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems" id="post-147567">
<header class="entry-header">
<h1 class="entry-title">Mutex lock for Linux Thread Synchronization</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Prerequisite : </strong><a href="https://www.geeksforgeeks.org/multithreading-c-2/">Multithreading in C</a></p>
<p><strong>Thread synchronization</strong> is defined as a mechanism which ensures that two or more concurrent processes or threads do not simultaneously execute some particular program segment known as critical section. Processes’ access to critical section is controlled by using synchronization techniques. When one thread starts executing the <a href="https://www.geeksforgeeks.org/g-fact-70/">critical section</a> (serialized segment of the program) the other thread should wait until the first thread finishes. If proper synchronization techniques are not applied, it may cause a<a href="https://practice.geeksforgeeks.org/problems/what-is-race-condition"> race condition</a> where the values of variables may be unpredictable and vary depending on the timings of context switches of the processes or threads.</p>
<p><strong>Thread Synchronization Problems</strong><br/>
An example code to study synchronization problems :</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-147588 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems" id="post-147588">
<header class="entry-header">
<h1 class="entry-title">Introduction to Linux Shell and Shell Scripting</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>If you are using any major operating system you are indirectly interacting to <strong>shell</strong>. If you are running Ubuntu, Linux Mint or any other Linux distribution, you are interacting to shell every time you use terminal. In this article I will discuss about linux shells and shell scripting so before understanding shell scripting we have to get familiar with following terminologies – </p>
<ul>
<li>Kernel</li>
<li>Shell</li>
<li>Terminal</li>
<ul>
<p align="center"><strong>What is Kernel</strong></p>
<p>The kernel is a computer program that is the core of a computer’s operating system, with complete control over everything in the system. It manages following resources of the Linux system – </p>
<ul>
<li>File management</li>
<li>Process management</li>
<li>I/O management</li>
<li>Memory management</li>
<li>Device management etc.</li>
<ul>
It is often mistaken that  has developed Linux OS, but actually he is only responsible for development of Linux kernel.<br/>
Complete Linux system =  Kernel +  system utilities and libraries + other management scripts + installation scripts.</ul></ul></ul></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-147400 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems tag-linux-command" id="post-147400">
<header class="entry-header">
<h1 class="entry-title">mindepth and maxdepth in Linux find() command for limiting search to a specific directory.</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>How to limit search a specified directory in Linux?</strong><br/>
There is a command in Linux to search for files in a directory hierarchy known as <strong><em>‘find’</em></strong>. It searches the directory tree rooted at each given starting-point by evaluating the given expression from left to right, according to the rules of precedence, until the outcome is known (the left-hand side is false for and operations, true for or), at which point find moves on to the next file name.  If no starting-point is specified, `.’ is assumed.<br/>
The find command by default travels down the entire directory tree recursively, which is time and resource consuming. However the depth of directory traversal can be specified(which are <em>mindepth</em> and <em>maxdepth</em>).</p>
<p><strong>What are mindepth and maxdepth levels?</strong></p>
<ul>
<li><strong>maxdepth levels</strong> : Descend at most levels (a non-negative integer) levels of          directories below the starting-points. <em>-maxdepth 0</em> means only apply the tests and actions to the starting-points themselves.</li>
<li><strong>mindepth levels</strong> : Do not apply any tests or actions at levels less than levels            (a non-negative integer).  -mindepth 1 means process all files except the starting-points.</li>
</ul>
<p><strong>Given below some examples to illustrate how depth of the directory traversal can be specified using <em>mindepth</em> and <em>maxdepth</em></strong></p>
<ul>
<li>Find the passwd file under all sub-directories starting from the root directory.
<pre><strong>find / -name passwd</strong></pre>
<pre><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/step1-1.png"><img alt="step1-1" class="alignnone size-full wp-image-147401" height="416" sizes="(max-width: 736px) 100vw, 736px" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/step1-1.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/step1-1.png 736w, https://www.geeksforgeeks.org/wp-content/uploads/step1-1-300x170.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/step1-1-660x373.png 660w" width="736"/></a></pre>
</li>
<li>Find the passwd file under root and one level down. (i.e root — level 1, and one sub-directory — level 2)
<pre><strong>find / -maxdepth 2 -name passwd</strong></pre>
<pre><img alt="" class="alignnone size-medium wp-image-184228" height="442" src="https://media.geeksforgeeks.org/wp-content/uploads/step2-1.png" width="734"/></pre>
</li>
<li>Find the passwd file under root and two levels down. (i.e root — level 1, and two sub-directories — level 2 and 3 )
<pre><strong>find / -maxdepth 3 -name passwd</strong></pre>
<pre><img alt="" class="alignnone size-medium wp-image-184229" height="441" src="https://media.geeksforgeeks.org/wp-content/uploads/step3-1.png" width="736"/></pre>
</li>
<li>Find the password file between sub-directory level 2 and 4.
<pre><strong>find / -mindepth 3 -maxdepth 5 -name passwd</strong></pre>
<pre><img alt="" class="alignnone size-medium wp-image-184230" height="436" src="https://media.geeksforgeeks.org/wp-content/uploads/step4-1.png" width="822"/></pre>
</li>
</ul>
<p><strong>There are two other ways to limit search a directory in linux :</strong></p>
<ol>
<strong></strong></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-147394 post type-post status-publish format-standard hentry category-linux-unix category-operating-systems" id="post-147394">
<header class="entry-header">
<h1 class="entry-title">Maximum number of Zombie process a system can handle</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b><a href="https://www.geeksforgeeks.org/zombie-and-orphan-processes-in-c/">Zombie Process</a></b> or <b>Defunct Process</b> are those Process which has completed their execution by exit() system call but still has an entry in <b>Process Table</b>. It is a process in terminated state.</p>
<p>When child process is created in <b>UNIX</b> using <b>fork()</b> system call, then if somehow parent process were not available to reap child process from Process Table, then this situation arise. Basically, <b>Zombie Process</b> is neither completely <b>dead</b> nor completely <b>alive</b> but it has having some state in between.</p>
<p>Since, there is an entry for all the <b>process</b> in <b>process table</b>, even for <b>Zombie Processes</b>. It is obvious that size of process table is <b>Finite</b>. So, if zombie process is created in large amount, then <b>Process Table</b> will get filled up and program will stop without completing their task.</p>
<p>Here, our task is <b>to find out Maximum Number of Zombie Process created so that Program will not stop its execution</b>. Approach for this problem is to create a zombie process within a loop and count it until the program does not stop the execution.</p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<p>Below is the implementation in <b>C</b> of above idea :</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-147040 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-147040">
<header class="entry-header">
<h1 class="entry-title">Program for Priority Scheduling | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Priority scheduling is a non-preemptive algorithm and one of the most common scheduling algorithms in batch systems. Each process is assigned a priority. Process with the highest priority is to be executed first and so on.<br/>
Processes with the same priority are executed on first come first served basis. Priority can be decided based on memory requirements, time requirements or any other resource requirement.</p>
<p><strong>Implementation :</strong></p>
<pre>

1- First input the processes with their burst time 

   and priority.

2- Sort the processes, burst time and priority

   according to the priority.

3- Now simply apply <a href="https://www.geeksforgeeks.org/program-fcfs-scheduling-set-1/">FCFS</a> algorithm.

</pre>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/PRIORITYsCHEDULING.jpg"><img alt="prior" class="alignnone size-full wp-image-164878" height="251" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/PRIORITYsCHEDULING.jpg" width="370"/></a></p>
<p>Note: A major problem with priority scheduling is indefinite blocking or starvation. A solution to the problem of indefinite blockage of the low-priority process is aging. Aging is a technique of gradually increasing the priority of processes that wait in the system for a long period of time.</p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-146869 post type-post status-publish format-standard hentry category-c category-linux-unix category-operating-systems" id="post-146869">
<header class="entry-header">
<h1 class="entry-title">Named Pipe or FIFO with example C program</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In computing, a named pipe (also known as a <strong>FIFO</strong>) is one of the methods for intern-process communication.  </p>
<ul>
<li>It is an extension to the traditional pipe concept on Unix. A traditional pipe is “unnamed” and lasts only as long as the process.</li>
<li> A named pipe, however, can last as long as the system is up, beyond the life of the process. It can be deleted if no longer used.</li>
<li> Usually a named pipe appears as a file, and generally processes attach to it for inter-process communication. A FIFO file is a special kind of file on the local storage which allows two or more processes to communicate with each other by reading/writing to/from this file. </li>
<li>A FIFO special file is entered into the filesystem by calling mkfifo() in C. Once we have created a FIFO special file in this way, any process can open it for reading or writing, in the same way as an ordinary file. However, it has to be open at both ends simultaneously before you can proceed to do any input or output operations on it.</li>
</ul>
<p><strong>Creating a FIFO file</strong><br/>
In order to create a FIFO file, a function calls i.e. mkfifo is used.</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-141991 post type-post status-publish format-standard hentry category-operating-systems category-technical-scripter tag-os-file-disk-management" id="post-141991">
<header class="entry-header">
<h1 class="entry-title">File Allocation Methods</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>The allocation methods define how the files are stored in the disk blocks. There are three main disk space or file allocation methods.</p>
<ul>
<li>Contiguous Allocation</li>
<li>Linked Allocation</li>
<li>Indexed Allocation</li>
</ul>
<p>The main idea behind these methods is to provide:</p>
<ul>
<li>Efficient disk space utilization.</li>
<li>Fast access to the file blocks.</li>
</ul>
<p>All the three methods have their own advantages and disadvantages as discussed below:</p>
<p><strong>1. Contiguous Allocation</strong></p>
<p>In this scheme, each file occupies a contiguous set of blocks on the disk. For example, if a file requires n blocks and is given a block b as the starting location, then the blocks assigned to the file will be:<em> b, b+1, b+2,……b+n-1.</em> This means that given the starting block address and the length of the file (in terms of blocks required), we can determine the blocks occupied by the file.<br/>
The directory entry for a file with contiguous allocation contains</p>
<ul>
<li>Address of starting block</li>
<li>Length of the allocated portion.</li>
</ul>
<p>The<em> file ‘mail’</em> in the following figure starts from the block 19 with length = 6 blocks. Therefore, it occupies <em>19, 20, 21, 22, 23, 24</em> blocks.</p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Contiguous-Allocation.jpg"><img alt="pic" class="alignnone size-medium wp-image-174514" height="350" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Contiguous-Allocation.jpg" width="450"/></a><br/>
<strong>Advantages:</strong></p>
<ul>
<li>Both the Sequential and Direct Accesses are supported by this. For direct access, the address of the kth block of the file which starts at block b can easily be obtained as (b+k).</li>
<li>This is extremely fast since the number of seeks are minimal because of contiguous allocation of file blocks.</li>
</ul>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>This method suffers from both internal and external fragmentation. This makes it inefficient in terms of memory utilization.</li>
<li>Increasing file size is difficult because it depends on the availability of contiguous memory at a particular instance.</li>
</ul>
<p><strong>2. Linked List Allocation</strong></p>
<p>In this scheme, each file is a linked list of disk blocks which<strong> need not be </strong>contiguous. The disk blocks can be scattered anywhere on the disk.<br/>
The directory entry contains a pointer to the starting and the ending file block. Each block contains a pointer to the next block occupied by the file.</p>
<p><em>The file ‘jeep’ in following image shows how the blocks are randomly distributed. The last block (25) contains -1 indicating a null pointer and does not point to any other block. </em><br/>
<a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/linkedListAllocation.jpg"><img alt="linked" class="alignnone size-medium wp-image-174517" height="350" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/linkedListAllocation.jpg" width="450"/></a></p>
<p><strong>Advantages:</strong></p>
<ul>
<li>This is very flexible in terms of file size. File size can be increased easily since the system does not have to look for a contiguous chunk of memory.</li>
<li>This method does not suffer from external fragmentation. This makes it relatively better in terms of memory utilization.</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Because the file blocks are distributed randomly on the disk, a large number of seeks are needed to access every block individually. This makes linked allocation slower.</li>
<li>It does not support random or direct access. We can not directly access the blocks of a file. A block k of a file can be accessed by traversing k blocks sequentially (sequential access ) from the starting block of the file via block pointers.</li>
<li>Pointers required in the linked allocation incur some extra overhead.</li>
</ul>
<p><strong>3. Indexed Allocation</strong></p>
<p>In this scheme, a special block known as the <strong>Index block</strong> contains the pointers to all the blocks occupied by a file. Each file has its own index block. The ith entry in the index block contains the disk address of the ith file block. The directory entry contains the address of the index block as shown in the image:</p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/indexedAllocation.jpg"><img alt="indexed" class="alignnone size-medium wp-image-174515" height="350" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/indexedAllocation.jpg" width="450"/></a><br/>
<strong>Advantages:</strong></p>
<ul>
<li>This supports direct access to the blocks occupied by the file and therefore provides fast access to the file blocks.</li>
<li>It overcomes the problem of external fragmentation.</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>The pointer overhead for indexed allocation is greater than linked allocation.</li>
<li>For very small files, say files that expand only 2-3 blocks, the indexed allocation would keep one entire block (index block) for the pointers which is inefficient in terms of memory utilization. However, in linked allocation we lose the space of only 1 pointer per block.</li>
</ul>
<p>For files that are very large, single index block may not be able to hold all the pointers.<br/>
Following mechanisms can be used to resolve this:</p>
<ol>
<li><strong>Linked scheme:</strong> This scheme links two or more index blocks together for holding the pointers. Every index block would then contain a pointer or the address to the next index block.</li>
<li><strong>Multilevel index:</strong> In this policy, a first level index block is used to point to the second level index blocks which inturn points to the disk blocks occupied by the file. This can be extended to 3 or more levels depending on the maximum file size.</li>
<li><strong>Combined Scheme:</strong> In this scheme, a special block called the <strong>Inode (information Node)</strong> contains all the information about the file such as the name, size, authority, etc and the remaining space of Inode is used to store the Disk Block addresses which contain the actual file<em> as shown in the image below.</em> The first few of these pointers in Inode point to the <strong>direct blocks</strong> i.e the pointers contain the addresses of the disk blocks that contain data of the file. The next few pointers point to indirect blocks. Indirect blocks may be single indirect, double indirect or triple indirect. <strong>Single Indirect block</strong> is the disk block that does not contain the file data but the disk address of the blocks that contain the file data. Similarly, <strong>double indirect blocks</strong> do not contain the file data but the disk address of the blocks that contain the address of the blocks containing the file data.<br/>
<a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Combined-Scheme.jpg"><img alt="inode" class="alignnone size-medium wp-image-174516" height="225" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Combined-Scheme.jpg" width="300"/></a></li>
</ol>
<p>This article is contributed by <strong>Saloni Baweja</strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-141732 post type-post status-publish format-standard hentry category-guestblogs category-operating-systems category-school-programming category-technical-scripter tag-cbse-class-11 tag-os-basics" id="post-141732">
<header class="entry-header">
<h1 class="entry-title">What happens when we turn on computer?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>A computer without a program running is just an inert hunk of electronics. The first thing a computer has to do when it is turned on is to start up a special program called an operating system. The operating system’s job is to help other computer programs to work by handling the messy details of controlling the computer’s hardware.</p>
<p><strong>An overview of the boot process</strong><br/>
<br/>
<img alt="sequence" class="alignnone size-full wp-image-170817" height="300" src="https://media.geeksforgeeks.org/wp-content/uploads/boot_process.png" width="529"/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-141276 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling tag-os-process-synchronization" id="post-141276">
<header class="entry-header">
<h1 class="entry-title">Program for Banker’s Algorithm | Set 1 (Safety Algorithm)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisite: <a href="http://quiz.geeksforgeeks.org/operating-system-bankers-algorithm/">Banker’s Algorithm</a></p>
<p>The banker’s algorithm is a resource allocation and deadlock avoidance algorithm that tests for safety by simulating the allocation for predetermined maximum possible amounts of all resources, then makes an “s-state” check to test for possible activities, before deciding whether allocation should be allowed to continue.</p>
<p>Following <strong>Data structures</strong> are used to implement the Banker’s Algorithm:</p>
<p>Let <strong>‘n’ </strong>be the number of processes in the system and <strong>‘m’ </strong>be the number of resources types.</p>
<p><strong>Available : </strong></p>
<ul>
<li>It is a 1-d array of size <strong>‘m’</strong> indicating the number of available resources of each type.</li>
<li>Available[ j ] = k means there are <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
</ul>
<p><strong>Max :</strong></p>
<ul>
<li>It is a 2-d array of size ‘<strong>n*m’ </strong>that defines the maximum demand of each process in a system.</li>
<li>Max[ i, j ] = k means process <strong>P<sub>i</sub></strong> may request at most <strong>‘k’</strong> instances of resource type <strong>R<sub>j.</sub></strong></li>
</ul>
<p><strong>Allocation :</strong></p>
<ul>
<li>It is a 2-d array of size<strong> ‘n*m’ </strong>that defines the number of resources of each type currently allocated to each process.</li>
<li>Allocation[ i, j ] = k means process <strong>P<sub>i</sub></strong> is currently allocated <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
</ul>
<p><strong>Need :</strong></p>
<ul>
<li> It is a 2-d array of size <strong>‘n*m’</strong> that indicates the remaining resource need of each process.</li>
<li>Need [ i,  j ] = k means process <strong>P<sub>i</sub></strong> currently allocated <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
<li>Need [ i,  j ] = Max [ i,  j ] – Allocation [ i,  j ]</li>
</ul>
<p>Allocation<sub>i</sub> specifies the resources currently allocated to process P<sub>i</sub> and Need<sub>i</sub> specifies the additional resources that process P<sub>i</sub> may still request to complete its task.</p>
<p>Banker’s algorithm consist of Safety algorithm and Resource request algorithm</p>
<p><b><span style="font-family: arial,helvetica,sans-serif">Safety Algorithm</span></b></p>
<p> The algorithm for finding out whether or not a system is in a safe state can be described as follows:</p>
<ol>
<li> Let Work and Finish be vectors of length ‘m’ and ‘n’ respectively.<br/>
 Initialize: Work= Available<br/>
 Finish [i]=false; for i=1,2,……,n</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-141636 post type-post status-publish format-standard hentry category-operating-systems category-technical-scripter tag-cpu-scheduling" id="post-141636">
<header class="entry-header">
<h1 class="entry-title">Convoy Effect in Operating Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Prerequisites :</strong> Basics of FCFS Scheduling (, )</p>
<p>Convoy Effect is phenomenon associated with the First Come First Serve (FCFS) algorithm, in which the whole Operating System slows down due to few slow processes.  </p>
<p><img alt="" class="aligncenter size-full" height="190" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/222-2.png" width="693"/></p>
<p>FCFS algorithm is non-preemptive in nature, that is, once CPU time has been allocated to a process, other processes can get CPU time only after the current process has finished. This property of FCFS scheduling leads to the situation called Convoy Effect.</p>
<p>Suppose there is one CPU intensive (large burst time) process in the ready queue, and several other processes with relatively less burst times but are Input/Output (I/O) bound (Need I/O operations frequently).</p>
<p>Steps are as following below: </p>
<ul>
<li>The I/O bound processes are first allocated CPU time. As they are less CPU intensive, they quickly get executed and goto I/O queues.</li>
<li>Now, the CPU intensive process is allocated CPU time. As its burst time is high, it takes time to complete.</li>
<li>While the CPU intensive process is being executed, the I/O bound processes complete their I/O operations and are moved back to ready queue.</li>
<li>However, the I/O bound processes are made to wait as the CPU intensive process still hasn’t finished. <strong>This leads to I/O devices being idle.</strong></li>
<li>When the CPU intensive process gets over, it is sent to the I/O queue so that it can access an I/O device.</li>
<li>Meanwhile, the I/O bound processes get their required CPU time and move back to I/O queue.</li>
<li>However, they are made to wait because the CPU intensive process is still accessing an I/O device. As a result, <strong>the CPU is sitting idle now</strong>.</li>
</ul>
<p>Hence in Convoy Effect, one slow process slows down the performance of the entire set of processes, and leads to wastage of CPU time and other devices.</p>
<p>To avoid Convoy Effect, preemptive scheduling algorithms like Round Robin Scheduling can be used – as the smaller processes don’t have to wait much for CPU time – making their execution faster and leading to less resources sitting idle.</p>
<p>References – </p>
<ul>
<li>A. Silberschatz, P. Galvin, G. Gagne, “Operating Systems Concepts (8th Edition)”, Wiley India Pvt. Ltd.</li>
</ul>
<p>This article is contributed by <strong></strong>. If you like GeeksforGeeks and would like to contribute, you can also write an article using <a href="http://www.contribute.geeksforgeeks.org">contribute.geeksforgeeks.org</a> or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/anish3007/">anish3007</a>, <a href="https://auth.geeksforgeeks.org/user/saurabhhjjain/">saurabhhjjain</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-141606 post type-post status-publish format-standard hentry category-c category-linux-unix category-operating-systems tag-os-processes-threads tag-system-programming" id="post-141606">
<header class="entry-header">
<h1 class="entry-title">Zombie Processes and their Prevention</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Prerequisites: <a href="http://geeksquiz.com/fork-system-call/">fork() in C</a>, <a href="https://www.geeksforgeeks.org/zombie-and-orphan-processes-in-c/">Zombie Process</a></p>
<p><strong>Zombie state</strong> : When a process is created in UNIX using fork() system call, the address space of the Parent process is replicated. If the parent process calls wait() system call, then the execution of parent is suspended until the child is terminated. At the termination of the child, a ‘SIGCHLD’ signal is generated which is delivered to the parent by the kernel. Parent, on receipt of ‘SIGCHLD’ reaps the status of the child from the process table. Even though, the child is terminated, there is an entry in the process table corresponding to the child where the status is stored. When parent collects the status, this entry is deleted. Thus, all the traces of the child process are removed from the system. If the parent decides not to wait for the child’s termination and it executes its subsequent task, then at the termination of the child, the exit status is not read. Hence, there remains an entry in the process table even after the termination of the child. This state of the child process is known as the Zombie state. </p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-141217 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-141217">
<header class="entry-header">
<h1 class="entry-title">Program for FCFS Scheduling | Set 2 (Processes with different arrival times)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>We have already discussed <a href="https://www.geeksforgeeks.org/program-fcfs-scheduling-set-1/">FCFS Scheduling of processes with same arrival time</a>. In this post, scenario when processes have different arrival times are discussed. Given n processes with their burst times and arrival times, the task is to find average waiting time and average turn around time using FCFS scheduling algorithm.<br/>
FIFO simply queues processes in the order they arrive in the ready queue. Here, the process that comes first will be executed first and next process will start only after the previous gets fully executed.</p>
<ol>
<li>Completion Time:    Time at which process completes its execution.</li>
<li>Turn Around Time:   Time Difference between completion time and arrival time.  Turn Around Time = Completion Time – Arrival Time </li>
<li>Waiting Time(W.T): Time Difference between turn around time and burst time.<br/>
     Waiting Time = Turn Around Time – Burst Time</li>
</ol>
<p><a href="https://media.geeksforgeeks.org/wp-content/uploads/os1.png"><img alt="ff2_" class="alignnone size-full wp-image-164867" height="341" src="https://media.geeksforgeeks.org/wp-content/uploads/os1.png" width="1217"/></a><br/>
<a href="https://media.geeksforgeeks.org/wp-content/uploads/ghant-chart.png"><img alt="ff23_" class="alignnone size-full wp-image-164866" height="196" src="https://media.geeksforgeeks.org/wp-content/uploads/ghant-chart.png" width="1292"/></a></p>
<pre>

Process     Wait Time : Service Time - Arrival Time

   P0                        0 - 0   = 0

   P1                        5 - 1   = 4

   P2                        8 - 2   = 6

   P3                        16 - 3  = 13



Average Wait Time: (0 + 4 + 6 + 13) / 4 = 5.75

</pre>
<p><strong>Service Time :</strong> Service time means amount of time after which a process can start  execution. It is  summation of burst time of previous processes (Processes that came before)</p>
<p><strong>Changes in code as compare to <a href="https://www.geeksforgeeks.org/program-fcfs-scheduling-set-1/">code of FCFS with same arrival time</a>:</strong><br/>
To find waiting time: Time taken by all processes before the current process to be started (i.e. burst time of all previous processes) – arrival time of current process<br/>
<strong>wait_time[i] = (bt[0] + bt[1] +…… bt[i-1] ) – arrival_time[i]</strong></p>
<p><b>Implementation:</b></p>
<pre>

1- Input the processes along with their burst time(bt)

   and arrival time(at)

2- Find waiting time for all other processes i.e. for

   a given process  i:

       wt[i] = (bt[0] + bt[1] +...... bt[i-1]) - at[i] 

3- Now find <strong>turn around time </strong>

          = waiting_time + burst_time for all processes

4- <strong>Average waiting time</strong> = 

                    total_waiting_time / no_of_processes

5- <strong>Average turn around time</strong> = 

                 total_turn_around_time / no_of_processes

</pre>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-142482 post type-post status-publish format-standard hentry category-operating-systems tag-os-memory-management" id="post-142482">
<header class="entry-header">
<h1 class="entry-title">Virtual Memory | Questions</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Advantages</strong></p>
<ul>
<li>Large virtual memory.</li>
<li>More efficient use of memory.</li>
<li>Unconstrained multiprogramming. There is no limit on degree of multiprogramming.</li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li>Number of tables and amount of processor overhead for handling page interrupts are greater than in the case of the simple paged management techniques.</li>
<li>Due to lack of an explicit constraint on a job’s address space size.</li>
</ul>
<p><strong>A way to control Thrashing </strong></p>
<p>Set the lower and upper bounds of page fault rate for each process. Using the above step, establish ‘acceptable’ page fault rate.</p>
<ul>
<li>If actual rate is lower than lower bound, decrease the number of frames</li>
<li>If actual rate is larger than upper bound, increase the number of frames.</li>
</ul>
<p><strong>Q1.</strong> Virtual memory is <br/>
<strong>(a)</strong> Large secondary memory<br/>
<strong>(b)</strong> Large main memory<br/>
<strong>(c)</strong> Illusion of large main memory<br/>
<strong>(d)</strong> None of the above<br/>
</p></div></article><hr style="border: 2px dashed black;" /><article class="post-141107 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-141107">
<header class="entry-header">
<h1 class="entry-title">Program for Round Robin scheduling | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>Round Robin is a <a href="http://quiz.geeksforgeeks.org/gate-notes-operating-system-process-scheduling/">CPU scheduling algorithm</a> where each process is assigned a fixed time slot in a cyclic way.</p>
<ul>
<li>It is simple, easy to implement, and starvation-free as all processes get fair share of CPU.</li>
<li>One of the most commonly used technique in CPU scheduling as a core.</li>
<li>It is preemptive as processes are assigned CPU only for a fixed slice of time at most.</li>
<li>The disadvantage of it is more overhead of context switching.</li>
</ul>
<p><strong>Illustration:</strong><br/>
<img alt="round-robin" class="alignnone size-full wp-image-141108" height="400" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/round-robin-1.jpg" width="600"/></p>
<p><strong>How to compute below times in Round Robin using a program?</strong></p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<ol>
<li>Completion Time:    Time at which process completes its execution.</li>
<li>Turn Around Time:   Time Difference between completion time and arrival time.  Turn Around Time = Completion Time – Arrival Time </li>
<li>Waiting Time(W.T): Time Difference between turn around time and burst time.<br/>
     Waiting Time = Turn Around Time – Burst Time</li>
</ol>
<p><em><strong>In this post, we have assumed arrival times as 0, so turn around and completion times are same.</strong></em></p>
<p>The tricky part is to compute waiting times. Once waiting times are computed, turn around times can be quickly computed.</p>
<p><strong>Steps to find waiting times of all processes:</strong></p>
<pre>

1- Create an array <strong>rem_bt[]</strong> to keep track of remaining

   burst time of processes. This array is initially a 

   copy of bt[] (burst times array)

2- Create another array <strong>wt[]</strong> to store waiting times

   of processes. Initialize this array as 0.

3- Initialize time : t = 0

4- Keep traversing the all processes while all processes

   are not done. Do following for i'th process if it is

   not done yet.

    a- If rem_bt[i] &gt; quantum

       (i)  t = t + quantum

       (ii) bt_rem[i] -= quantum;

    c- Else // Last cycle for this process

       (i)  t = t + bt_rem[i];

       (ii) wt[i] = t - bt[i]

       (ii) bt_rem[i] = 0; // This process is over

</pre>
<p>Once we have waiting times, we can compute turn around time tat[i] of a process as sum of waiting and burst times, i.e., wt[i] + bt[i]</p>
<p>Below is implementation of above steps.                </p>
<div class="responsive-tabs">
<h2 class="tabtitle">C/C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-141075 post type-post status-publish format-standard hentry category-greedy category-operating-systems tag-cpu-scheduling" id="post-141075">
<header class="entry-header">
<h1 class="entry-title">Program for Shortest Job First (or SJF) scheduling | Set 1 (Non- preemptive)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>Shortest job first (SJF) or shortest job next, is a scheduling policy that selects the waiting process with the smallest execution time to execute next. SJN is a non-preemptive algorithm. </p>
<ul>
<li>Shortest Job first has the advantage of having minimum average waiting time among all scheduling algorithms.</li>
<li>It is a Greedy Algorithm. </li>
<li>It may cause starvation if shorter processes keep coming. This problem can be solved using the concept of aging.</li>
<li>It is practically infeasible as Operating System may not know burst time and therefore may not sort them.  While it is not possible to predict execution time, several methods can be used to estimate the execution time for a job, such as a weighted average of previous execution times. SJF can be used in specialized environments where accurate estimates of running time are available.</li>
</ul>
<p><strong>Algorithm:</strong></p>
<pre>

1- Sort all the processes in increasing order 

   according to burst time.

2- Then simply, apply <a href="https://www.geeksforgeeks.org/program-fcfs-scheduling-set-1/">FCFS</a>.

</pre>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><img alt="" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/SJF1-1.png"/></p>
<p><strong>How to compute below times in SJF using a program?</strong></p>
<ol>
<li>Completion Time:    Time at which process completes its execution.</li>
<li>Turn Around Time:   Time Difference between completion time and arrival time.  Turn Around Time = Completion Time – Arrival Time </li>
<li>Waiting Time(W.T): Time Difference between turn around time and burst time.<br/>
     Waiting Time = Turn Around Time – Burst Time</li>
</ol>
<p><em><strong>In this post, we have assumed arrival times as 0, so turn around and completion times are same.</strong></em></p>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-141058 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-141058">
<header class="entry-header">
<h1 class="entry-title">Program for FCFS Scheduling | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>Given n processes with their burst times, the task is to find average waiting time and average turn around time using FCFS scheduling algorithm.<br/>
First in, first out (FIFO), also known as first come, first served (FCFS), is the simplest scheduling algorithm. FIFO simply queues processes in the order that they arrive in the ready queue.<br/>
 In this, the process that comes first will be executed first and next process starts only after the previous gets fully executed.<br/>
Here we are considering that arrival time for all processes is 0.</p>
<p><strong>How to compute below times in Round Robin using a program?</strong></p>
<ol>
<li>Completion Time:    Time at which process completes its execution.</li>
<li>Turn Around Time:   Time Difference between completion time and arrival time.  Turn Around Time = Completion Time – Arrival Time </li>
<li>Waiting Time(W.T): Time Difference between turn around time and burst time.<br/>
     Waiting Time = Turn Around Time – Burst Time</li>
</ol>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><em><br/>
<strong>In this post, we have assumed arrival times as 0, so turn around and completion times are same.</strong></em></p>
<p><img alt="" src="https://media.geeksforgeeks.org/wp-content/uploads/FCFS.png"/></p>
<p><b>Implementation:</b></p>
<pre>

1-  Input the processes along with their burst time (bt).

2-  Find waiting time (wt) for all processes.

3-  As first process that comes need not to wait so 

    waiting time for process 1 will be 0 i.e. wt[0] = 0.

4-  Find <strong>waiting time</strong> for all other processes i.e. for

     process i -&gt; 

       wt[i] = bt[i-1] + wt[i-1] .

5-  Find <strong>turnaround time</strong> = waiting_time + burst_time 

    for all processes.

6-  Find <strong>average waiting time</strong> = 

                 total_waiting_time / no_of_processes.

7-  Similarly, find <strong>average turnaround time</strong> = 

                 total_turn_around_time / no_of_processes.

</pre>
<p><!-- To show strongly recommend and practice link    --></p>
<div id="practiceLinkDiv">
<h2><a href="https://ide.geeksforgeeks.org/">Recommended: Please try your approach on <b><i><u>{IDE}</u></i></b> first, before moving on to the solution.</a></h2>
</div>
<div class="responsive-tabs">
<h2 class="tabtitle">C++</h2>
<div class="tabcontent">
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-142480 post type-post status-publish format-standard hentry category-operating-systems tag-os-file-disk-management" id="post-142480">
<header class="entry-header">
<h1 class="entry-title">File Systems | Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A file is a collection of related information that is recorded on secondary storage. Or file is a collection of logically related entities. From user’s perspective a file is the smallest allotment of logical secondary storage.</p>
<table style="width:50% !important">
<thead>
<tr>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Attributes</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Types</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Operations</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Name</td>
<td style="text-align:center">Doc</td>
<td style="text-align:center">Create</td>
</tr>
<tr>
<td>Type</td>
<td>Exe</td>
<td>Open</td>
</tr>
<tr>
<td style="text-align:center">Size</td>
<td style="text-align:center">Jpg</td>
<td style="text-align:center">Read</td>
</tr>
<tr>
<td>Creation Data</td>
<td>Xis</td>
<td>Write</td>
</tr>
<tr>
<td style="text-align:center">Author</td>
<td style="text-align:center">C</td>
<td style="text-align:center">Append</td>
</tr>
<tr>
<td>Last Modified</td>
<td>Java</td>
<td>Truncate</td>
</tr>
<tr>
<td style="text-align:center">protection</td>
<td style="text-align:center">class</td>
<td style="text-align:center">Delete</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Close</td>
</tr>
</tbody>
</table>
<p></p>
<table style="width:50% !important">
<thead>
<tr>
<th style="padding:8px;background-color:#4CB96B;text-align:center">File type</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Usual extension</th>
<th style="padding:8px;background-color:#4CB96B;text-align:center">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Executable</td>
<td style="text-align:center">exe, com, bin</td>
<td style="text-align:center">Read to run machine language program</td>
</tr>
<tr>
<td>Object</td>
<td>obj, o</td>
<td>Compiled, machine language not linked</td>
</tr>
<tr>
<td style="text-align:center">Source Code</td>
<td style="text-align:center">C, java, pas, asm, a</td>
<td style="text-align:center">Source code in various languages</td>
</tr>
<tr>
<td>Batch</td>
<td>bat, sh</td>
<td>Commands to the command interpreter</td>
</tr>
<tr>
<td style="text-align:center">Text</td>
<td style="text-align:center">txt, doc</td>
<td style="text-align:center">Textual data, documents</td>
</tr>
<tr>
<td>Word Processor</td>
<td>wp, tex, rrf, doc</td>
<td>Various word processor formats</td>
</tr>
<tr>
<td style="text-align:center">Archive</td>
<td style="text-align:center">arc, zip, tar</td>
<td style="text-align:center">Related files grouped into one compressed file</td>
</tr>
<tr>
<td>Multimedia</td>
<td>mpeg, mov, rm</td>
<td>For containing audio/video information</td>
</tr>
</tbody>
</table>
<p>
<strong>FILE DIRECTORIES:</strong><br/>
Collection of files is a file directory. The directory contains information about the files, including attributes, location and ownership. Much of this information, especially that is concerned with storage, is managed by the operating system. The directory is itself a file, accessible by various file management routines.<br/>
<br/>
<strong>Information contained in a device directory are:</strong></p>
<ul>
<li>Name</li>
<li>Type</li>
<li>Address</li>
<li>Current length</li>
<li>Maximum length</li>
<li>Date last accessed</li>
<li>Date last updated</li>
<li>Owner id</li>
<li>Protection information</li>
</ul>
<p><strong>Operation performed on directory are:</strong></p>
<ul>
<li>Search for a file</li>
<li>Create a file</li>
<li>Delete a file</li>
<li>List a directory</li>
<li>Rename a file</li>
<li>Traverse the file system</li>
</ul>
<p>
<strong>Advantages of maintaining directories are:</strong></p>
<ul>
<li><strong>Efficiency:</strong> A file can be located more quickly.</li>
<li><strong>Naming:</strong> It becomes convenient for users as two users can have same name for different files or may have different name for same file.</li>
<li><strong>Grouping:</strong> Logical grouping of files can be done by properties e.g. all java programs, all games etc.</li>
</ul>
<p>
<strong>SINGLE-LEVEL DIRECTORY</strong><br/>
In this a single directory is maintained for all the users.</p>
<ul>
<li><strong>Naming problem:</strong> Users cannot have same name for two files.</li>
<li><strong>Grouping problem:</strong> Users cannot group files according to their need.</li>
</ul>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory.jpg"><img alt="file_sys_5" class="alignnone size-full wp-image-30972" height="233" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory.jpg" width="762"/></a><br/>
<br/>
<strong>TWO-LEVEL DIRECTORY</strong><br/>
In this separate directories for each user is maintained.</p>
<ul>
<li>Path name:Due to two levels there is a path name for every file to locate that file.</li>
<li>Now,we can have same file name for different user.</li>
<li>Searching is efficient in this method.</li>
</ul>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-user-level.jpg"><img alt="file_sys_6" class="alignnone size-full wp-image-30976" height="308" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-user-level.jpg" width="698"/></a><br/>
<br/>
<strong>TREE-STRUCTURED DIRECTORY :</strong><br/>
Directory is maintained in the form of a tree. Searching is efficient and also there is grouping capability. We have absolute or relative path name for a file.<br/>
<a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-tree-format.jpg"><img alt="file_sys_7" class="alignnone size-full wp-image-30978" height="519" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-tree-format.jpg" width="683"/></a><br/>
<br/>
<strong>FILE ALLOCATION METHODS</strong><br/>
<strong>1. Continuous Allocation:</strong> A single continuous set of blocks is allocated to a file at the time of file creation. Thus, this is a pre-allocation strategy, using variable size portions. The file allocation table needs just a single entry for each file, showing the starting block and the length of the file. This method is best from the point of view of the individual sequential file. Multiple blocks can be read in at a time to improve I/O performance for sequential processing. It is also easy to retrieve a single block. For example, if a file starts at block b, and the ith block of the file is wanted, its location on secondary storage is simply b+i-1.<br/>
<a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-file-allocation.jpg"><img alt="file_sys_8" class="alignnone size-full wp-image-30982" height="100" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-file-allocation.jpg" width="300"/></a><br/>
<br/>
<strong>Disadvantage</strong></p>
<ul>
<li>External fragmentation will occur, making it difficult to find contiguous blocks of space of sufficient length. Compaction algorithm will be necessary to free up additional space on disk.</li>
<li>Also, with pre-allocation, it is necessary to declare the size of the file at the time of creation.</li>
</ul>
<p><strong>2. Linked Allocation(Non-contiguous allocation) :</strong> Allocation is on an individual block basis. Each block contains a pointer to the next block in the chain. Again the file table needs just a single entry for each file, showing the starting block and the length of the file. Although pre-allocation is possible, it is more common simply to allocate blocks as needed. Any free block can be added to the chain. The blocks need not be continuous. Increase in file size is always possible if free disk block is available. There is no external fragmentation because only one block at a time is needed but there can be internal fragmentation but it exists only in the last disk block of file.<br/>
<br/>
<strong>Disadvantage:</strong></p>
<ul>
<li>Internal fragmentation exists in last disk block of file.</li>
<li>There is an overhead of maintaining the pointer in every disk block.</li>
<li>If the pointer of any disk block is lost, the file will be truncated.</li>
<li>It supports only the sequencial access of files.</li>
</ul>
<p>
<strong>3. Indexed Allocation:</strong><br/>
It addresses many of the problems of contiguous and chained allocation. In this case, the file allocation table contains a separate one-level index for each file: The index has one entry for each block allocated to the file. Allocation may be on the basis of fixed-size blocks or variable-sized blocks. Allocation by blocks eliminates external fragmentation, whereas allocation by variable-size blocks improves locality. This allocation technique supports both sequential and direct access to the file and thus is the most popular form of file allocation.<br/>
<a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-indexing.jpg"><img alt="file_sys_9" class="alignnone size-full wp-image-30998" height="100" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/directory-indexing.jpg" width="300"/></a><br/>
</p>
<p align="center"><strong>Disk Free Space Management</strong></p>
<p>Just as the space that is allocated to files must be managed ,so the space that is not currently allocated to any file must be managed. To perform any of the file allocation techniques,it is necessary to know what blocks on the disk are available. Thus we need a disk allocation table in addition to a file allocation table.The following are the approaches used for free space management.</p>
<ol>
<li><strong>Bit Tables</strong> : This method uses a vector containing one bit for each block on the disk. Each entry for a 0 corresponds to a free block and each 1 corresponds to a block in use.<br/>
For example: 00011010111100110001</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-142481 post type-post status-publish format-standard hentry category-operating-systems tag-memory-management" id="post-142481">
<header class="entry-header">
<h1 class="entry-title">Virtual Memory | Operating System</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div></div>
<p>Virtual Memory is a storage allocation scheme in which secondary memory can be addressed as though it were part of main memory. The addresses a program may use to reference memory are distinguished from the addresses the memory system uses to identify physical storage sites, and program generated addresses are translated automatically to the corresponding machine addresses.<br/>
The size of virtual storage is limited by the addressing scheme of the computer system and amount of secondary memory is available not by the actual number of the main storage locations.</p>
<p>It is a technique that is implemented using both hardware and software. It maps memory addresses used by a program, called virtual addresses, into physical addresses in computer memory.</p>
<ol>
<li>All memory references within a process are logical addresses that are dynamically translated into physical addresses at run time. This means that a process can be swapped in and out of main memory such that it occupies different places in main memory at different times during the course of execution.</li>
<li>A process may be broken into number of pieces and these pieces need not be continuously located in the main memory during execution. The combination of dynamic run-time address translation and use of page or segment table permits this.</li>
</ol>
<p>If these characteristics are present then, it is not necessary that all the pages or segments are present in the main memory during execution. This means that the required pages need to be loaded into memory whenever required. Virtual memory is implemented using Demand Paging or Demand Segmentation.</p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><strong>Demand Paging :</strong><br/>
The process of loading the page into memory on demand (whenever page fault occurs) is known as demand paging.<br/>
The process includes the following steps :<br/>
<a href="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-1.png"><img alt="virtual_mem" class="alignnone size-full wp-image-31014" src="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-1.png"/></a></p>
<ol>
<li>If CPU try to refer a page that is currently not available in the main memory, it generates an interrupt indicating memory access fault.</li>
<li>The OS puts the interrupted process in a blocking state. For the execution to proceed the OS must bring the required page into the memory.</li>
<li>The OS will search for the required page in the logical address space.</li>
<li>The required page will be brought from logical address space to physical address space. The page replacement algorithms are used for the decision making of replacing the page in physical address space.</li>
<li>The page table will updated accordingly.</li>
<li>The signal will be sent to the CPU to continue the program execution and it will place the process back into ready state.</li>
</ol>
<p>Hence whenever a page fault occurs these steps are followed by the operating system and the required page is brought into memory.</p>
<p>
<strong>Advantages :</strong></p>
<ul>
<li>More processes may be maintained in the main memory: Because we are going to load only some of the pages of any particular process, there is room for more processes. This leads to more efficient utilization of the processor because it is more likely that at least one of the more numerous processes will be in the ready state at any particular time.</li>
<li>A process may be larger than all of main memory: One of the most fundamental restrictions in programming is lifted. A process larger than the main memory can be executed because of demand paging. The OS itself loads pages of a process in main memory as required.</li>
<li>It allows greater multiprogramming levels by using less of the available (primary) memory for each process.</li>
</ul>
<p><strong>Page Fault Service Time :</strong><br/>
The time taken to service the page fault is called as page fault service time. The page fault service time includes the time taken to perform all the above six steps.</p>
<pre>

Let Main memory access time is: m

Page fault service time is: s

Page fault rate is : p

Then, Effective memory access time = (p*s) + (1-p)*m

</pre>
<p><strong>Swapping:</strong></p>
<p>Swapping a process out means removing all of its pages from memory, or marking them so that they will be removed by the normal page replacement process. Suspending a process ensures that it is not runnable while it is swapped out. At some later time, the system swaps back the process from the secondary storage to main memory. When a process is busy swapping pages in and out then this situation is called thrashing.</p>
<p><a href="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-2.png"><img alt="swaping" class="alignnone size-full wp-image-32437" src="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-2.png"/></a></p>
<p>
<strong>Thrashing :</strong><br/>
<a href="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-3.png"><img alt="virtual_mem_2" class="alignnone size-full wp-image-31020" src="https://media.geeksforgeeks.org/wp-content/uploads/VirtualDiagram-3.png"/></a><br/>
At any given time, only few pages of any process are in main memory and therefore more processes can be maintained in memory. Furthermore time is saved because unused pages are not swapped in and out of memory. However, the OS must be clever about how it manages this scheme. In the steady state practically, all of main memory will be occupied with process’s pages, so that the processor and OS has direct access to as many processes as possible. Thus when the OS brings one page in, it must throw another out. If it throws out a page just before it is used, then it will just have to get that page again almost immediately. Too much of this leads to a condition called Thrashing. The system spends most of its time swapping pages rather than executing instructions. So a good page replacement algorithm is required.<br/>
<br/>
In the given diagram, initial degree of multi programming upto some extent of point(lamda), the CPU utilization is very high and the system resources are utilized 100%. But if we further increase the degree of multi programming the CPU utilization will drastically fall down and the system will spent more time only in the page replacement and the time taken to complete the execution of the process will increase. This situation in the system is called as thrashing.<br/>
<br/>
<strong>Causes of Thrashing :</strong></p>
<ol>
<li><strong>High degree of multiprogramming </strong>: If the number of processes keeps on increasing in the memory than number of frames allocated to each process will be decreased. So, less number of frames will be available to each process. Due to this, page fault will occur more frequently and more CPU time will be wasted in just swapping in and out of pages and the utilization will keep on decreasing.
<p>For example:<br/>
Let free frames = 400<br/>
<strong>Case 1</strong>: Number of process = 100<br/>
Then, each process will get 4 frames.</p>
<p><strong>Case 2</strong>: Number of process = 400<br/>
Each process will get 1 frame.<br/>
Case 2 is a condition of thrashing, as the number of processes are increased,frames per process are decreased. Hence CPU time will be consumed in just swapping pages.
</p></li>
<li><strong>Lacks of Frames</strong>:If a process has less number of frames then less pages of that process will be able to reside in memory and hence more frequent swapping in and out will be required. This may lead to thrashing. Hence sufficient amount of frames must be allocated to each process in order to prevent thrashing.</li>
</ol>
<p>
<strong>Recovery of Thrashing :</strong></p>
<ul>
<li>Do not allow the system to go into thrashing by instructing the long term scheduler not to bring the processes into memory after the threshold.</li>
<li>If the system is already in thrashing then instruct the mid term schedular to suspend some of the processes so that we can recover the system from thrashing.</li>
</ul>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-142479 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-os-process-synchronization" id="post-142479">
<header class="entry-header">
<h1 class="entry-title">Inter Process Communication</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>A process can be of two type:</p>
<ul>
<li> Independent process.</li>
<li>Co-operating process.</li>
</ul>
<p>An independent process is not affected by the execution of other processes while a co-operating process can be affected by other executing processes. Though one can think that those processes, which are running independently, will execute very efficiently but in practical, there are many situations when co-operative nature can be utilised for increasing computational speed, convenience and modularity. Inter process communication (IPC) is a mechanism which allows processes to communicate each other and synchronize their actions. The communication between these processes can be seen as a method of co-operation between them. Processes can communicate with each other using these two ways:<br/>
</p>
<ol>
<li>Shared Memory</li>
<li>Message passing</li>
</ol>
<p>The Figure 1 below shows a basic structure of communication between processes via shared memory method and via message passing.</p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p>An operating system can implement both method of communication. First, we will discuss the shared memory method of communication and then message passing. Communication between processes using shared memory requires processes to share some variable and it completely depends on how programmer will implement it. One way of communication using shared memory can be imagined like this: Suppose process1 and process2 are executing simultaneously and they share some resources or use some information from other process, process1 generate information about certain computations or resources being used and keeps it as a record in shared memory. When process2 need to use the shared information, it will check in the record stored in shared memory and take note of the information generated by process1 and act accordingly. Processes can use shared memory for extracting information as a record from other process as well as for delivering any specific information to other process. <br/>
Let’s discuss an example of communication between processes using shared memory method.</p>
<p><img alt="" class="aligncenter size-full" height="304" src="https://media.geeksforgeeks.org/wp-content/uploads/1-76.png" width="538"/></p>
<p align="center"><strong>i) Shared Memory Method</strong></p>
<p><strong>Ex: Producer-Consumer problem  </strong><br/>
There are two processes: Producer and Consumer. Producer produces some item and Consumer consumes that item. The two processes shares a common space or memory location known as buffer where the item produced by Producer is stored and from where the Consumer consumes the item if needed. There are two version of this problem: first one is known as unbounded buffer problem in which Producer can keep on producing items and there is no limit on size of buffer, the second one is known as bounded buffer problem in which producer can produce up to a certain amount of item and after that it starts waiting for consumer to consume it. We will discuss the bounded buffer problem. First, the Producer and the Consumer will share some common memory, then producer will start producing items. If the total produced item is equal to the size of buffer, producer will wait to get it consumed by the Consumer. Sim-<br/>
ilarly, the consumer first check for the availability of the item and if no item is available, Consumer will wait for producer to produce it. If there are items available, consumer will consume it. The pseudo code are given below:</p></div></article><hr style="border: 2px dashed black;" /><article class="post-138460 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization" id="post-138460">
<header class="entry-header">
<h1 class="entry-title">Peterson’s Algorithm for Mutual Exclusion | Set 2 (CPU Cycles and Memory Fence)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Problem:</strong> Given 2 process i and j, you need to write a program that can guarantee mutual exclusion between the two without any additional hardware support.</p>
<p>We strongly recommend to refer below basic solution discussed in previous article.<br/>
</p>
<p>We would be resolving 2 issues in the previous algorithm.</p>
<h4> Wastage of CPU clock cycles </h4>
<p>In layman terms, when a thread was waiting for its turn, it ended in a long while loop which tested the condition millions of times per second thus doing unnecessary computation. There is a better way to wait, and it is known as <i>“yield”</i>.</p>
<p>To understand what it does, we need to dig deep into how the Process scheduler works in Linux. The idea mentioned here is a simplified version of the scheduler, the actual implementation has lots of complications.</p>
<p>Consider the following example,<br/>
There are three processes, P1, P2 and P3. Process P3 is such that it has a while loop similar to the one in our code, doing not so useful computation, and it exists from the loop only when P2 finishes its execution. The scheduler puts all of them in a round robin queue. Now, say the clock speed of processor is 1000000/sec, and it allocates 100 clocks to each process in each iteration. Then, first P1 will be run for 100 clocks (0.0001 seconds), then P2(0.0001 seconds) followed by P3(0.0001 seconds), now since there are no more processes, this cycle repeats untill P2 ends and then followed by P3’s execution and eventually its termination.</p>
<p>This is a complete waste of the 100 CPU clock cycles. To avoid this, we mutually give up the CPU time slice, i.e. yield, which essentially ends this time slice and the scheduler picks up the next process to run. Now, we test our condition once, then we give up the CPU. Considering our test takes 25 clock cycles, we save 75% of our computation in a time slice. To put this graphically,</p>
<p><img alt="" class="aligncenter size-medium wp-image-178095" sizes="(max-width: 772px) 100vw, 772px" src="https://www.geeksforgeeks.org/wp-content/uploads/peterson.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/peterson.png 772w, https://www.geeksforgeeks.org/wp-content/uploads/peterson-300x160.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/peterson-768x410.png 768w, https://www.geeksforgeeks.org/wp-content/uploads/peterson-660x352.png 660w"/></p>
<p>Considering the processor clock speed as 1MHz this is a lot of saving!.<br/>
Different distributions provide different function to achieve this functionality. Linux provides <b>sched_yield()</b>.</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-138451 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization tag-system-programming" id="post-138451">
<header class="entry-header">
<h1 class="entry-title">Peterson’s Algorithm for Mutual Exclusion | Set 1 (Basic C implementation)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>Problem:</strong> Given 2 process i and j, you need to write a program that can guarantee mutual exclusion between the two without any additional hardware support.</p>
<p><strong>Solution:</strong> There can be multiple ways to solve this problem, but most of them require additional hardware support. The simplest and the most popular way to do this is by using Peterson Algorithm for mutual Exclusion. It was developed by Peterson in 1981 though the initial work in this direction by done by Theodorus Jozef Dekker who came up with <b>Dekker’s algorithm</b> in 1960, which was later refined by Peterson and came to be known as <b>Peterson’s Algorithm</b>.</p>
<p>Basically, Peterson’s algorithm provides guaranteed mutual exclusion by using only the shared memory. It uses two ideas in the algorithm, </p>
<ol>
<li>Willingness to acquire lock.</li>
<li>Turn to acquire lock.</li>
</ol>
<p>Prerequisite : <a href="https://www.geeksforgeeks.org/multithreading-c-2/">Multithreading in C</a></p>
<h4>Explanation:</h4>
<p>The idea is that first a thread expresses its desire to acquire lock and sets <b> flag[self] = 1</b> and then gives the other thread a chance to acquire the lock. If the thread desires to acquire the lock, then, it gets the lock and then passes the chance to the 1st thread. If it does not desire to get the lock then the while loop breaks and the 1st thread gets the chance.</p>
<p><strong>Implementation in C language</strong></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-138422 post type-post status-publish format-standard hentry category-java category-operating-systems tag-os-process-synchronization" id="post-138422">
<header class="entry-header">
<h1 class="entry-title">Producer-Consumer solution using threads in Java</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In computing, the producer–consumer problem (also known as the bounded-buffer problem) is a classic example of a multi-process synchronization problem. The problem describes two processes, the producer and the consumer, which share a common, fixed-size buffer used as a queue. </p>
<ul>
<li>The producer’s job is to generate data, put it into the buffer, and start again.</li>
<li> At the same time, the consumer is consuming the data (i.e. removing it from the buffer), one piece at a time. </li>
</ul>
<p><strong>Problem</strong><br/>
To make sure that the producer won’t try to add data into the buffer if it’s full and that the consumer won’t try to remove data from an empty buffer.</p>
<p><strong>Solution </strong><br/>
The producer is to either go to sleep or discard data if the buffer is full. The next time the consumer removes an item from the buffer, it notifies the producer, who starts to fill the buffer again. In the same way, the consumer can go to sleep if it finds the buffer to be empty. The next time the producer puts data into the buffer, it wakes up the sleeping consumer.<br/>
An inadequate solution could result in a deadlock where both processes are waiting to be awakened. </p>
<p><strong>Recommended Reading-</strong> <a href="http://quiz.geeksforgeeks.org/multithreading-in-java/">Multithreading in JAVA</a>, <a href="http://quiz.geeksforgeeks.org/synchronized-in-java/">Synchronized in JAVA</a> , <a href="https://www.geeksforgeeks.org/inter-thread-communication-java/">Inter-thread Communication</a></p>
<p><strong>Implementation of Producer Consumer Class</strong></p>
<ul>
<li>A <strong>LinkedList list</strong> – to store list of jobs in queue.</li>
<li><strong>A Variable Capacity</strong> – to check for if the list is full or not</li>
<li>A mechanism to control the insertion and extraction from this list so that we do not insert into list if it is full or remove from it if it is empty.</li>
</ul>
<p><em><br/>
Note: It is recommended to test the below program on a offline IDE as infinite loops and sleep method may lead to it time out on any online IDE<br/>
</em></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-142478 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-memory-management" id="post-142478">
<header class="entry-header">
<h1 class="entry-title">Operating System | Segmentation</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>A process is divided into Segments. The chunks that a program is divided into which are not necessarily all of the same sizes are called segments. Segmentation gives user’s view of the process which paging does not give. Here the user’s view is mapped to physical memory.<br/>
There are types of segmentation:</p>
<ol>
<li><b>Virtual memory segmentation –</b><br/>
Each process is divided into a number of segments, not all of which are resident at any one point in time.
</li>
<li><b>Simple segmentation –</b><br/>
Each process is divided into a number of segments, all of which are loaded into memory at run time, though not necessarily contiguously.
</li>
</ol>
<p>There is no simple relationship between logical addresses and physical addresses in segmentation. A table stores the information about all such segments and is called Segment Table.</p>
<p><b>Segment Table –</b> It maps two-dimensional Logical address into one-dimensional Physical address. It’s each table entry has:</p>
<ul>
<li><b>Base Address: </b>It<b> </b>contains the starting physical address where the segments reside in memory.</li>
<li><b>Limit:</b> It specifies the length of the segment.</li>
</ul>
<p><img alt="" class="aligncenter size-full" height="500" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/02/segmentation.png" width="650"/></p>
<p>Translation of Two dimensional Logical Address to one dimensional Physical Address.</p>
<p><img alt="" class="aligncenter size-full" height="500" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/02/Translation.png" width="650"/></p>
<p>Address generated by the CPU is divided into:</p>
<ul>
<li><b>Segment number (s):</b> Number of bits required to represent the segment.</li>
<li><b>Segment offset (d):</b> Number of bits required to represent the size of the segment.</li>
</ul>
<p><b>Advantages of Segmentation –</b></p>
<ul>
<li>No Internal fragmentation.</li>
<li>Segment Table consumes less space in comparison to Page table in paging.</li>
</ul>
<p><b>Disadvantage of Segmentation –</b></p>
<ul>
<li>As processes are loaded and removed from the memory, the free memory space is broken into little pieces, causing External fragmentation.</li>
</ul>
<p>This article has been contributed by . Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142477 post type-post status-publish format-standard hentry category-operating-systems" id="post-142477">
<header class="entry-header">
<h1 class="entry-title">Last Minute Notes – Operating Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>See Last Minute Notes for all subjects <a href="http://quiz.geeksforgeeks.org/lmns/">all subjects here</a>.</p>
<p><strong>Operating Systems: </strong>It is the interface between the user and the computer hardware.</p>
<p><a href="https://www.geeksforgeeks.org/operating-system-types-operating-systems-awaiting-author/"><strong>Types of Operating System (OS):</strong></a></p>
<ol>
<li><strong>Batch OS –</strong>  A set of similar jobs are stored in the main memory for execution. A job gets assigned to the CPU, only when the execution of the previous job completes.</li>
<li><strong>Multiprogramming OS –</strong>  The main memory consists of jobs waiting for CPU time. The OS selects one of the processes and assigns it to the CPU. Whenever the executing process needs to wait for any other operation (like I/O), the OS selects another process from the job queue and assigns it to the CPU. This way, the CPU is never kept idle and the user gets the flavor of getting multiple tasks done at once.</li>
<li><strong>Multitasking OS –</strong>  Multitasking OS combines the benefits of Multiprogramming OS and CPU scheduling to perform quick switches between jobs. The switch is so quick that the user can interact with each program as it runs</li>
<li><strong>Time Sharing OS –</strong>  Time-sharing systems require interaction with the user to instruct the OS to perform various tasks. The OS responds with an output. The instructions are usually given through an input device like the keyboard.</li>
<li><strong>Real Time OS –</strong>  Real-Time OS are usually built for dedicated systems to accomplish a specific set of tasks within deadlines.</li>
</ol>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><a href="https://www.geeksforgeeks.org/operating-system-threads-types/"> <strong>Threads:</strong></a><br/>
A thread is a lightweight process and forms the basic unit of CPU utilization. A process can perform more than one task at the same time by including multiple threads.</p>
<ul>
<li>A thread has its own program counter, register set, and stack</li>
<li>A thread shares resources with other threads of the same process the code section, the data section, files and signals.</li>
</ul>
<p>A new thread, or a child process of a given process, can be introduced by using the fork() system call. A process with n fork() system calls generates 2<sup>n</sup> – 1 child processes.<br/>
There are two types of threads:</p>
<ul>
<li>User threads</li>
<li>Kernel threads</li>
</ul>
<p><i>Example:</i> Java thread, POSIX threads.Example : Window Solaris.</p>
<p> </p>
<table style="width:80%">
<tbody>
<tr>
<th style="font-size: 15px"><strong>User level thread</strong></th>
<th style="font-size: 15px"><strong>Kernel level thread</strong></th>
</tr>
<tr>
<td>User threads are implemented by users.</td>
<td>kernel threads are implemented by OS.</td>
</tr>
<tr>
<td>OS doesn’t recognize user level threads.</td>
<td>Kernel threads are recognized by OS.</td>
</tr>
<tr>
<td>Implementation of User threads is easy.</td>
<td>Implementation of Kernel thread is complicated.</td>
</tr>
<tr>
<td>Context switch time is less.</td>
<td>Context switch time is more.</td>
</tr>
<tr>
<td>Context switch requires no hardware support.</td>
<td>Hardware support is needed.</td>
</tr>
<tr>
<td>If one user level thread performs blocking operation then entire process will be blocked.</td>
<td>If one kernel thread performs blocking operation then another thread can continue execution.</td>
</tr>
</tbody>
</table>
<p> <br/>
<a href="https://www.geeksforgeeks.org/gate-notes-operating-system-process-management-introduction/"><strong>Process:</strong></a><br/>
A process is a program under execution. The value of program counter (PC) indicates the address of the next  instruction of the process being executed. Each process is represented by a Process Control Block (PCB).</p>
<p><a href="https://www.geeksforgeeks.org/gate-notes-operating-system-process-scheduling/"><strong>Process Scheduling:</strong></a> Below are different times with respect to a process.</p>
<ol>
<li><strong>Arrival Time –</strong> Time at which the process arrives in the ready queue.
</li>
<li><strong>Completion Time –</strong> Time at which process completes its execution.
</li>
<li><strong>Burst Time –</strong> Time required by a process for CPU execution.
</li>
<li><strong>Turn Around Time –</strong> Time Difference between completion time and arrival time.
<pre>Turn Around Time = Completion Time - Arrival Time </pre>
</li>
<li><strong>Waiting Time (WT) –</strong> Time Difference between turn around time and burst time.
<pre>Waiting Time = Turn Around Time - Burst Time </pre>
</li>
</ol>
<p><strong>Why do we need scheduling?</strong><br/>
A typical process involves both I/O time and CPU time. In a uniprogramming system like MS-DOS, time spent waiting for I/O is wasted and CPU is free during this time. In multiprogramming systems, one process can use CPU while another is waiting for I/O. This is possible only with process scheduling.</p>
<p><strong>Objectives of Process Scheduling Algorithm:</strong></p>
<ul>
<li>Max CPU utilization (Keep CPU as busy as possible)
</li>
<li>Fair allocation of CPU.
</li>
<li>Max throughput (Number of processes that complete their execution per time unit)
</li>
<li>Min turnaround time (Time taken by a process to finish execution)
</li>
<li>Min waiting time (Time for which a process waits in ready queue)
</li>
<li>Min response time (Time when a process produces first response)
</li>
</ul>
<p><strong>Different Scheduling Algorithms:</strong></p>
<ol>
<li><a href="https://www.geeksforgeeks.org/program-fcfs-scheduling-set-1/"><strong>First Come First Serve (FCFS) </strong></a>: Simplest scheduling algorithm that schedules according to arrival times of processes.
</li>
<li><a href="https://www.geeksforgeeks.org/program-shortest-job-first-sjf-scheduling-set-1-non-preemptive/"><strong>Shortest Job First (SJF)</strong></a>: Process which have the shortest burst time are scheduled first.
</li>
<li><a href="https://www.geeksforgeeks.org/program-shortest-job-first-scheduling-set-2srtf-make-changesdoneplease-review/"><strong>Shortest Remaining Time First (SRTF)</strong></a>: It is preemptive mode of SJF algorithm in which jobs are scheduled according to the shortest remaining time.
</li>
<li><a href="https://www.geeksforgeeks.org/program-round-robin-scheduling-set-1/"><strong>Round Robin (RR) Scheduling</strong></a>: Each process is assigned a fixed time, in cyclic way.</li>
<li><a href="https://www.geeksforgeeks.org/program-priority-scheduling-set-1/"><strong>Priority Based scheduling (Non Preemptive)</strong></a>:  In this scheduling, processes are scheduled according to their priorities, i.e., highest priority process is schedule first. If priorities of two processes match, then scheduling is according to the arrival time.
</li>
<li><a href="https://www.geeksforgeeks.org/operating-system-highest-response-ratio-next-hrrn-scheduling/"><strong>Highest Response Ratio Next (HRRN)</strong></a>:  In this scheduling, processes with highest response ratio is scheduled. This algorithm avoids starvation.
<pre>Response Ratio = (Waiting Time + Burst time) / Burst time</pre>
</li>
<li><a href="https://www.geeksforgeeks.org/operating-system-multilevel-queue-scheduling/"><strong>Multilevel Queue Scheduling (MLQ)</strong></a>:  According to the priority of process, processes are placed in the different queues. Generally high priority process are placed in the top level queue. Only after completion of processes from top level queue, lower level queued processes are scheduled.
</li>
<li><a href="https://www.geeksforgeeks.org/multilevel-feedback-queue-scheduling/"><strong>Multi level Feedback Queue (MLFQ) Scheduling</strong></a>:  It allows the process to move in between queues. The idea is to separate processes according to the characteristics of their CPU bursts. If a process uses too much CPU time, it is moved to a lower-priority queue.
</li>
</ol>
<p><strong>Some useful facts about Scheduling Algorithms:</strong></p>
<ol>
<li>FCFS can cause long waiting times, especially when the first job takes too much CPU time.
</li>
<li>Both SJF and Shortest Remaining time first algorithms may cause starvation. Consider a situation when a long process is there in the ready queue and shorter processes keep coming.
</li>
<li>If time quantum for Round Robin scheduling is very large, then it behaves same as FCFS scheduling.
</li>
<li>SJF is optimal in terms of average waiting time for a given set of processes. SJF gives minimum average waiting time, but problems with SJF is how to know/predict the time of next job.
</li>
</ol>
<p><b>The Critical Section Problem:</b></p>
<ol>
<li><b>Critical Section –</b>  The portion of the code in the program where shared variables are accessed and/or updated.
</li>
<li><b>Remainder Section –</b>  The remaining portion of the program excluding the Critical Section.
</li>
<li><b>Race around Condition –</b>  The final output of the code depends on the order in which the variables are accessed. This is termed as the race around condition.
</li>
</ol>
<p>A solution for the critical section problem must satisfy the following three conditions:</p>
<ol>
<li><strong>Mutual Exclusion –</strong> If a process Pi is executing in its critical section, then no other process is allowed to enter into the critical section. </li>
<li><strong>Progress –</strong>  If no process is executing in the critical section, then the decision of a process to enter a critical section cannot be made by any other process that is executing in its remainder section. The selection of the process cannot be postponed indefinitely. </li>
<li><strong>Bounded Waiting –</strong>  There exists a bound on the number of times other processes can enter into the critical section after a process has made request to access the critical section and before the requested is granted.
</li>
</ol>
<p> <br/>
<strong>Synchronization Tools:</strong><br/>
A <b>Semaphore</b> is an integer variable that is accessed only through two atomic operations, wait () and signal (). An atomic operation is executed in a single CPU time slice without any pre-emption. Semaphores are of two types:</p>
<ol>
<li><strong>Counting Semaphore –</strong> A counting semaphore is an integer variable whose value can range over an unrestricted domain.</li>
<li><strong>Mutex –</strong> Binary Semaphores are called Mutex. These can have only two values, 0 or 1. The operations wait () and signal () operate on these in a similar fashion.
</li>
</ol>
<p><a href="https://www.geeksforgeeks.org/operating-system-process-management-deadlock-introduction/"><strong>Deadlock</strong></a>:<br/>
A situation where a set of processes are blocked because each process is holding a resource and waiting for another resource acquired by some other process. Deadlock can arise if following four conditions hold simultaneously (Necessary Conditions):</p>
<ol>
<li><strong>Mutual Exclusion –</strong> One or more than one resource are non-sharable (Only one process can use at a time).
</li>
<li><strong>Hold and Wait –</strong> A process is holding at least one resource and waiting for resources.
</li>
<li><strong>No Preemption –</strong> A resource cannot be taken from a process unless the process releases the resource.
</li>
<li><strong>Circular Wait –</strong> A set of processes are waiting for each other in circular form.
</li>
</ol>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><strong>Methods for handling deadlock:</strong> There are three ways to handle deadlock</p>
<ol>
<li><a href="https://www.geeksforgeeks.org/deadlock-prevention/"><b>Deadlock prevention or avoidance</b></a>: The idea is to not let the system into deadlock state.
</li>
<li><a href="https://www.geeksforgeeks.org/deadlock-detection-recovery/"><b>Deadlock detection and recovery</b></a> : Let deadlock occur, then do preemption to handle it once occurred.
</li>
<li><b>Ignore the problem all together –</b> : If deadlock is very rare, then let it happen and reboot the system. This is the approach that both Windows and UNIX take.
</li>
</ol>
<p><a href="https://www.geeksforgeeks.org/operating-system-bankers-algorithm/"><strong>Banker’s Algorithm:</strong></a><br/>
This algorithm handles multiple instances of the same resource. </p>
<p><strong>Memory Management:</strong><br/>
These techniques allow the memory to be shared among multiple processes.</p>
<ul>
<li><b>Overlays –</b> The memory should contain only those instructions and data that are required at a given time.
</li>
<li><b>Swapping –</b> In multiprogramming, the instructions that have used the time slice are swapped out from the memory.
</li>
</ul>
<p><a href="https://www.geeksforgeeks.org/operating-system-memory-management-partition-allocation-method/"><strong>Memory Management Techniques:</strong></a></p>
<p><strong>(a) Single Partition Allocation Schemes –</strong><br/>
The memory is divided into two parts. One part is kept to be used by the OS and the other is kept to be used by the users.</p>
<p><strong>(b) Multiple Partition Schemes –</strong></p>
<ol>
<li><b>Fixed Partition –</b> The memory is divided into fixed size partitions.
</li>
<li><b>Variable Partition –</b> The memory is divided into variable sized partitions.
</li>
</ol>
<p>Variable partition allocation schemes: </p>
<ol>
<li><b>First Fit –</b> The arriving process is allotted the first hole of memory in which it fits completely.
</li>
<li><b>Best Fit –</b> The arriving process is allotted the hole of memory in which it fits the best by leaving the minimum memory empty.
</li>
<li><b>Worst Fit –</b> The arriving process is allotted the hole of memory in which it leaves the maximum gap.
</li>
</ol>
<p><b>Note:</b> </p>
<ul>
<li>Best fit does not necessarily give the best results for memory allocation.</li>
<li>The cause of external fragmentation is the condition in Fixed partitioning and Variable partitioning saying that entire process should be allocated in a contiguous memory location.Therefore <strong>Paging</strong> is used.</li>
</ul>
<ol>
<li><strong>Paging –</strong><br/>
The physical memory is divided into equal sized frames. The main memory is divided into fixed size pages. The size of a physical memory frame is equal to the size of a virtual memory frame.
</li>
<li><strong>Segmentation –</strong><br/>
Segmentation is implemented to give users view of memory. The logical address space is a collection of segments. Segmentation can be implemented with or without the use of paging.
</li>
</ol>
<p><a href="https://www.geeksforgeeks.org/operating-system-page-fault-handling/"><strong>Page Fault:</strong><br/></a><br/>
A page fault is a type of interrupt, raised by the hardware when a running program accesses a memory page that is mapped into the virtual address space, but not loaded in physical memory.</p>
<p><a href="https://www.geeksforgeeks.org/page-replacement-algorithms-in-operating-systems/"><strong>Page Replacement Algorithms:</strong></a></p>
<ol>
<li><strong>First In First Out (FIFO) –</strong><br/>
This is the simplest page replacement algorithm. In this algorithm, operating system keeps track of all pages in the memory in a queue, oldest page is in the front of the queue. When a page needs to be replaced page in the front of the queue is selected for removal.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-136777 post type-post status-publish format-standard hentry category-guestblogs category-operating-systems tag-os-processes-threads" id="post-136777">
<header class="entry-header">
<h1 class="entry-title">What exactly Spooling is all about?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p style="text-align: justify;">
<p style="text-align: justify;">SPOOL is an acronym for <strong>simultaneous peripheral operations on-line</strong>.  It is a kind of buffering mechanism or a process in which data is temporarily held to be used and executed by a device, program or the system. Data is sent to and stored in memory or other volatile storage until the program or computer requests it for execution.</p>
<p style="text-align: justify;">In a computer system peripheral equipments, such as printers and punch card readers etc (batch processing), are very slow relative to the performance of the rest of the system. Getting input and output from the system was quickly seen to be a bottleneck. Here comes the need for spool.</p>
<p style="text-align: justify;">Spooling works like a typical request queue where data, instructions and processes from multiple sources are accumulated for execution later on. Generally, it is maintained on computer’s physical memory, buffers or the I/O device-specific interrupts. The spool is processed in FIFO manner i.e. whatever first instruction is there in the queue will be popped and executed.</p>
<p style="text-align: justify;"><strong><u>Applications/Implementations of Spool:</u></strong></p>
<p style="text-align: justify;">1) The most common can be found in I/O devices like keyboard printers and mouse. For example, In printer, the documents/files that are sent to the printer are first stored in the memory or the printer spooler. Once the printer is ready, it fetches the data from the spool and prints it.</p>
<p style="text-align: justify;">Even experienced a situation when suddenly for some seconds your mouse or keyboard stops working? Meanwhile, we usually click again and again here and there on the screen to check if its working or not. When it actually starts working, what and wherever we pressed during its hang state gets executed very fast because all the instructions got stored in the respective device’s spool.</p>
<p style="text-align: justify;">2) A batch processing system uses spooling to maintain a queue of ready-to-run jobs which can be started as soon as the system has the resources to process them.</p>
<p style="text-align: justify;">3) Spooling is capable of overlapping I/O operation for one job with processor operations for another job. i.e. multiple processes can write documents to a print queue without waiting and resume with their work.</p>
<p style="text-align: justify;">4) E-mail: an email is delivered by a MTA (Mail Transfer Agent) to a temporary storage area where it waits to be picked up by the MA (Mail User Agent)</p>
<p style="text-align: justify;">5) Can also be used for generating Banner pages (these are the pages used in computerized printing in order to separate documents from each other and to identify e.g. the originator of the print request by username, an account number or a bin for pickup. Such pages are used in office environments where many people share the small number of available resources).</p>
<p style="text-align: justify;">
<p style="text-align: justify;"><span style="color: #008000;">About the Author: </span></p>
<p style="text-align: justify;"><span style="color: #008000;">Ekta is a  very active contributor on Geeksforgeeks. Currently studying at Delhi Technological University.She has also made a Chrome extention for   to practice MCQs  randomly.She can be reached at  <a href="https://github.com/Ekta1994" style="color: #008000;">github.com/Ekta1994</a></span></p>
<p><strong>If you also wish to showcase your blog here, please see for guest blog writing on GeeksforGeeks.</strong></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-142476 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization" id="post-142476">
<header class="entry-header">
<h1 class="entry-title">Operating System | Banker’s Algorithm</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div></div>
<p>The banker’s algorithm is a resource allocation and deadlock avoidance algorithm that tests for safety by simulating the allocation for predetermined maximum possible amounts of all resources, then makes an “s-state” check to test for possible activities, before deciding whether allocation should be allowed to continue.</p>
<p>Following <strong>Data structures</strong> are used to implement the Banker’s Algorithm:</p>
<p>Let <strong>‘n’ </strong>be the number of processes in the system and <strong>‘m’ </strong>be the number of resources types.</p>
<p><strong>Available : </strong></p>
<ul>
<li>It is a 1-d array of size <strong>‘m’</strong> indicating the number of available resources of each type.</li>
<li>Available[ j ] = k means there are <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
</ul>
<p><strong>Max :</strong></p>
<ul>
<li>It is a 2-d array of size ‘<strong>n*m’ </strong>that defines the maximum demand of each process in a system.</li>
<li>Max[ i, j ] = k means process <strong>P<sub>i</sub></strong> may request at most <strong>‘k’</strong> instances of resource type <strong>R<sub>j.</sub></strong></li>
</ul>
<p><strong>Allocation :</strong></p>
<ul>
<li>It is a 2-d array of size<strong> ‘n*m’ </strong>that defines the number of resources of each type currently allocated to each process.</li>
<li>Allocation[ i, j ] = k means process <strong>P<sub>i</sub></strong> is currently allocated <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
</ul>
<p><strong>Need :</strong></p>
<ul>
<li> It is a 2-d array of size <strong>‘n*m’</strong> that indicates the remaining resource need of each process.</li>
<li>Need [ i,   j ] = k means process <strong>P<sub>i</sub></strong> currently need <strong>‘k’</strong> instances of resource type <strong>R<sub>j</sub></strong></li>
<p> for its execution.</p>
<li>Need [ i,   j ] = Max [ i,   j ] – Allocation [ i,   j ]</li>
</ul>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p>Allocation<sub>i</sub> specifies the resources currently allocated to process P<sub>i</sub> and Need<sub>i</sub> specifies the additional resources that process P<sub>i</sub> may still request to complete its task.</p>
<p>Banker’s algorithm consists of Safety algorithm and Resource request algorithm</p>
<p><b><span style="font-family: arial, helvetica, sans-serif">Safety Algorithm</span></b></p>
<p>The algorithm for finding out whether or not a system is in a safe state can be described as follows:</p>
<blockquote><p>
1) Let Work and Finish be vectors of length ‘m’ and ‘n’ respectively.<br/>
Initialize: Work = Available<br/>
Finish[i] = false; for i=1, 2, 3, 4….n</p>
<p></p>
<p>2) Find an i such that both<br/>
a) Finish[i] = false<br/>
b) Need<sub>i</sub> &lt;= Work<br/>
if no such i exists goto step (4)</p>
<p></p>
<p>3) Work = Work + Allocation[i]<br/>
Finish[i] = true<br/>
goto step (2)</p>
<p></p>
<p>4) if Finish [i] = true for all i<br/>
then the system is in a safe state
</p></blockquote>
<p></p>
<p><strong>Resource-Request Algorithm</strong></p>
<p>Let Request<sub>i</sub> be the request array for process P<sub>i</sub>. Request<sub>i </sub>[j] = k means process P<sub>i</sub> wants k instances of resource type R<sub>j</sub>. When a request for resources is made by process P<sub>i</sub>, the following actions are taken:</p>
<blockquote>
<p>1) If Request<sub>i</sub> &lt;= Need<sub>i</sub><br/>
Goto step (2) ; otherwise, raise an error condition, since the process has exceeded its maximum claim.</p>
<p></p>
<p>2) If Request<sub>i</sub> &lt;= Available<br/>
Goto step (3); otherwise, P<sub>i</sub> must wait, since the resources are not available.</p>
<p></p>
<p>3) Have the system pretend to have allocated the requested resources to process Pi by modifying the state as<br/>
follows:<br/>
Available = Available – Requesti<br/>
Allocation<sub>i</sub> = Allocation<sub>i</sub> + Request<sub>i</sub><br/>
Need<sub>i</sub> = Need<sub>i</sub>– Request<sub>i</sub></p>
</blockquote>
<p></p>
<p><strong>Example:</strong></p>
<p><strong>Considering a system with five processes P<sub>0</sub> through P<sub>4</sub> and three resources of type A, B, C. Resource type A has 10 instances, B has 5 instances and type C has 7 instances. Suppose at time t<sub>0</sub> following snapshot of the system has been taken:</strong></p>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/safety.png"><img alt="safety" class="alignnone size-full wp-image-22841" height="220" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/safety.png" width="472"/></a></p>
<p><strong>Question1. What will be the content of the Need matrix?</strong></p>
<p>Need [i, j] = Max [i, j] – Allocation [i, j]</p>
<p>So, the content of Need Matrix is:</p>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/unnamed.png"><img alt="unnamed" class="alignnone size-full wp-image-22842" height="211" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/unnamed.png" width="228"/></a></p>
<p><strong>Question2.  Is the system in a safe state? If Yes, then what is the safe sequence?</strong></p>
<p>Applying the Safety algorithm on the given system,</p>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/questionsolved.png"><img alt="questionsolved" class="alignnone size-large wp-image-22843" height="410" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/questionsolved-1024x632.png" width="665"/></a></p>
<p><strong>Question3. What will happen if process P<sub>1 </sub>requests one additional instance of resource type A and two instances of resource type C?</strong></p>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/Allocation.png"><img alt="allocation" class="aligncenter size-full wp-image-28365" height="394" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/Allocation.png" width="770"/></a></p>
<p>We must determine whether this new system state is safe. To do so, we again execute Safety algorithm on the above data structures.</p>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/Q31.png"><img alt="Q31" class="alignnone size-large wp-image-22845" height="413" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2016/01/Q31-1024x636.png" width="665"/></a></p>
<p>Hence the new system state is safe, so we can immediately grant the request for process <strong> P<sub>1 .</sub></strong><br/>
<br/>
Code for Banker’s Algorithm<br/>
<div class="responsive-tabs">
<h2 class="tabtitle">C/C++</h2>
<div class="tabcontent">
</div></div></p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-142475 post type-post status-publish format-standard hentry category-operating-systems tag-os-memory-management" id="post-142475">
<header class="entry-header">
<h1 class="entry-title">Operating System | Paging</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Paging is a memory management scheme that eliminates the need for contiguous allocation of physical memory. This scheme permits the physical address space of a process to be non – contiguous.</p>
<ul>
<li>Logical Address or Virtual Address (represented in bits): An address generated by the CPU</li>
<li>Logical Address Space or Virtual Address Space( represented in words or bytes): The set of all logical addresses generated by a program</li>
<li>Physical Address (represented in bits): An address actually available on memory unit</li>
<li>Physical Address Space (represented in words or bytes): The set of all physical addresses corresponding to the logical addresses</li>
</ul>
<p><strong>Example: </strong></p>
<ul>
<li>If Logical Address = 31 bit, then Logical Address Space = 2<sup>31</sup> words = 2 G words (1 G = 2<sup>30</sup>)</li>
<li>If Logical Address Space = 128 M words = 2<sup>7</sup> * 2<sup>20</sup> words, then Logical Address = log<sub>2</sub> 2<sup>27</sup> = 27 bits</li>
<li>If Physical Address = 22 bit, then Physical Address Space = 2<sup>22</sup> words = 4 M words (1 M = 2<sup>20</sup>)</li>
<li>If Physical Address Space = 16 M words = 2<sup>4</sup> * 2<sup>20</sup> words, then Physical Address = log<sub>2</sub> 2<sup>24</sup> = 24 bits</li>
</ul>
<p>The mapping from virtual to physical address is done by the memory management unit (MMU) which is a hardware device and this mapping is known as paging technique.</p>
<ul>
<li>The Physical Address Space is conceptually divided into a number of fixed-size blocks, called <strong>frames</strong>.
<li>The Logical address Space is also splitted into fixed-size blocks, called <strong>pages</strong>.
<li>Page Size = Frame Size</li>
</li></li></ul>
<p>Let us consider an example:</p>
<ul>
<li>Physical Address = 12 bits, then Physical Address Space = 4 K words</li>
<li>Logical Address = 13 bits, then Logical Address Space = 8 K words</li>
<li>Page size = frame size = 1 K words (assumption)</li>
</ul>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging.jpg"><img alt="size" class="aligncenter size-full wp-image-22773" height="533" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging.jpg" width="918"/></a></p>
<p> </p>
<p>Address generated by CPU is divided into</p>
<ul>
<li><strong>Page number(p):</strong> Number of bits required to represent the pages in Logical Address Space or Page number</li>
<li><strong>Page offset(d):</strong> Number of bits required to represent particular word in a page or page size of Logical Address Space or word number of a page or page offset.</li>
</ul>
<p>Physical Address is divided into</p>
<ul>
<li><strong>Frame number(f):</strong> Number of bits required to represent the frame of Physical Address Space or Frame number.</li>
<li><strong>Frame offset(d):</strong> Number of bits required to represent particular word in a frame or frame size of Physical Address Space or word number of a frame or frame offset.</li>
</ul>
<p> </p>
<p>The hardware implementation of page table can be done by using dedicated registers. But the usage of register for the page table is satisfactory only if page table is small. If page table contain large number of entries then we can use TLB(translation Look-aside buffer), a special, small, fast look up hardware cache.</p>
<ul>
<li>The TLB is associative, high speed memory.</li>
<li>Each entry in TLB consists of two parts: a tag and a value.</li>
<li>When this memory is used, then an item is compared with all tags simultaneously.If the item is found, then corresponding value is returned.</li>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging-2.jpg"><img alt="Size1" class="aligncenter size-full wp-image-22774" height="484" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging-2.jpg" width="849"/></a></p>
<p> </p>
<p>Main memory access time = m<br/>
If page table are kept in main memory,<br/>
Effective access time = m(for page table) + m(for particular page in page table)</p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging-3.jpg"><img alt="save2" class="aligncenter size-full wp-image-22775" height="225" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/paging-3.jpg" width="588"/></a></p>
<p> </p>
<p>Questions asked in GATE on Paging:<br/>
</p>
<p> </p>
<p>This article has been contributed by <a href="https://www.quora.com/profile/Vikash-Kumar-164">Vikash Kumar</a>. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</ul></div></article><hr style="border: 2px dashed black;" /><article class="post-142812 post type-post status-publish format-standard hentry category-computer-organization-architecture category-gate-cs category-operating-systems tag-operating-systems-memory-management" id="post-142812">
<header class="entry-header">
<h1 class="entry-title">Computer Organization | Cache Memory</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><b>Cache Memory</b> is a special very high-speed memory. It is used to speed up and synchronizing with high-speed CPU. Cache memory is costlier than main memory or disk memory but economical than CPU registers. Cache memory is an extremely fast memory type that acts as a buffer between RAM and the CPU. It holds frequently requested data and instructions so that they are immediately available to the CPU when needed. </p>
<p>Cache memory is used to reduce the average time to access data from the Main memory. The cache is a smaller and faster memory which stores copies of the data from frequently used main memory locations. There are various different independent caches in a CPU, which stored instruction and data.</p>
<p><img class="aligncenter size-full" height="230" src="https://media.geeksforgeeks.org/wp-content/uploads/cache.png" width="828"/></p>
<p><b>Levels of memory:</b></p>
<ul>
<li><b>Level 1 or Register –</b><br/>
It is a type of memory in which data is stored and accepted that are immediately stored in CPU. Most commonly used register is accumulator, Program counter, address register etc. </li>
<li><b>Level 2 or Cache memory –</b><br/>
It is the fastest memory which has faster access time where data is temporarily stored for faster access.</li>
<li><b>Level 3 or Main Memory –</b><br/>
It is memory on which computer works currently it is small in size and once power is off data no longer stays in this memory</li>
<li><b>Level 4 or Secondary Memory –</b><br/>
It is external memory which is not fast as main memory but data stays permanently in this memory</li>
</ul>
<p><strong>Cache Performance:</strong><br/>
When the processor needs to read or write a location in main memory, it first checks for a corresponding entry in the cache.</p>
<ul>
<li>If the processor finds that the memory location is in the cache, a <strong>cache hit</strong> has occurred and data is read from cache</li>
<li style="text-align: justify">If the processor <strong>does not</strong> find the memory location in the cache, a <strong>cache miss</strong> has occurred. For a cache miss, the cache allocates a new entry and copies in data from main memory, then the request is fulfilled from the contents of the cache.</li>
</ul>
<p>The performance of cache memory is frequently measured in terms of a quantity called <strong>Hit ratio.</strong></p>
<pre>Hit ratio = hit / (hit + miss) =  no. of hits/total accesses</pre>
<p>We can improve Cache performance using higher cache block size, higher associativity, reduce miss rate, reduce miss penalty, and reduce Reduce the time to hit in the cache.</p>
<p><b>Cache Mapping:</b><br/>
There are three different types of mapping used for the purpose of cache memory which are as follows: Direct mapping, Associative mapping, and Set-Associative mapping. These are explained as following below.</p>
<ol>
<li><strong>Direct Mapping –</strong><br/>
 The simplest technique, known as direct mapping, maps each block of main memory into only one possible cache line. or<br/>
In Direct mapping, assigned each memory block to a specific line in the cache. If a line is previously taken up by a memory block when a new block needs to be loaded, the old block is trashed. An address space is split into two parts index field and a tag field. The cache is used to store the tag field whereas the rest is stored in the main memory. Direct mapping`s performance is directly proportional to the Hit ratio.</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-142474 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization" id="post-142474">
<header class="entry-header">
<h1 class="entry-title">Readers-Writers Problem | Set 1 (Introduction and Readers Preference Solution)</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Consider a situation where we have a file shared between many people.</p>
<ul>
<li>If one of the people tries editing the file, no other person should be reading or writing at the same time, otherwise changes will not be visible to him/her.</li>
<li>However if some person is reading the file, then others may read it at the same time.</li>
</ul>
<p>Precisely in OS we call this situation as the <strong>readers-writers problem</strong></p>
<p>Problem parameters:</p>
<ul>
<li>One set of data is shared among a number of processes</li>
<li>Once a writer is ready, it performs its write. Only one writer may write at a time</li>
<li>If a process is writing, no other process can read it</li>
<li>If at least one reader is reading, no other process can write</li>
<li>Readers may not write and only read</li>
</ul>
<p style="text-align: center"><strong>Solution when Reader has the Priority over Writer</strong></p>
<p>Here priority means, no reader should wait if the share is currently opened for reading.</p>
<p>Three variables are used: <strong>mutex, wrt, readcnt</strong> to implement solution</p>
<ol>
<li><strong>semaphore</strong> mutex, wrt; // semaphore <strong>mutex</strong> is used to ensure mutual exclusion when <strong>readcnt</strong> is updated i.e. when any reader enters or exit from the critical section and semaphore <strong>wrt</strong> is used by both readers and writers</li>
<li><strong>int</strong> readcnt;  //    <strong>readcnt</strong> tells the number of processes performing read in the critical section, initially 0</li>
</ol>
<p><strong>Functions for sempahore :</strong></p>
<p>– wait() : decrements the semaphore value.</p>
<p>– signal() : increments the semaphore value.</p>
<p><strong>Writer process:</strong></p>
<ol>
<li>Writer requests the entry to critical section.</li>
<li>If allowed i.e. wait() gives a true value, it enters and performs the write. If not allowed, it keeps on waiting.</li>
<li>It exits the critical section.</li>
</ol>
<pre>do {

    // writer requests for critical section

    wait(wrt);  

   

    // performs the write



    // leaves the critical section

    signal(wrt);



} while(true);</pre>
<p><strong>Reader process:</strong></p>
<ol>
<li>Reader requests the entry to critical section.</li>
<li>If allowed:
<ul>
<li style="text-align: left">it increments the count of number of readers inside the critical section. If this reader is the first reader entering, it locks the <strong>wrt</strong> semaphore to restrict the entry of writers if any reader is inside.</li>
<li style="text-align: left">It then, signals mutex as any other reader is allowed to enter while others are already reading.</li>
<li style="text-align: left">After performing reading, it exits the critical section. When exiting, it checks if no more reader is inside, it signals the semaphore “wrt” as now, writer can enter the critical section.</li>
</ul>
</li>
<li>If not allowed, it keeps on waiting.</li>
</ol>
<pre>do {

    

   // Reader wants to enter the critical section

   wait(mutex);



   // The number of readers has now increased by 1

   readcnt++;                          



   // there is atleast one reader in the critical section

   <strong>// this ensure no writer can enter if there is even one reader</strong>

   <strong>// thus we give preference to readers here</strong>

   if (readcnt==1)     

      wait(wrt);                    



   // other readers can enter while this current reader is inside 

   // the critical section

   signal(mutex);                   



   // current reader performs reading here

   wait(mutex);   // a reader wants to leave



   readcnt--;



   // that is, no reader is left in the critical section,

   if (readcnt == 0) 

       signal(wrt);         // writers can enter



   signal(mutex); // reader leaves



} while(true);</pre>
<p>Thus, the semaphore ‘<strong>wrt</strong>‘ is queued on both readers and writers in a manner such that preference is given to readers if writers are also there. Thus, no reader is waiting simply because a writer has requested to enter the critical section.</p>
<p>Article contributed by <a href="https://www.linkedin.com/pub/ekta-goel/75/12a/3a6">Ekta Goel</a>. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/Ankit Kumar Singh 2/">Ankit Kumar Singh 2</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142473 post type-post status-publish format-standard hentry category-operating-systems tag-os-file-disk-management" id="post-142473">
<header class="entry-header">
<h1 class="entry-title">Disk Scheduling Algorithms</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p><strong>Disk scheduling </strong>is done by operating systems to schedule I/O requests arriving for the disk. Disk scheduling is also known as I/O scheduling.</p>
<p>Disk scheduling is important because:</p>
<ul>
<li>Multiple I/O requests may arrive by different processes and only one I/O request can be served at a time by the disk controller. Thus other I/O requests need to wait in the waiting queue and need to be scheduled.</li>
<li>Two or more request may be far from each other so can result in greater disk arm movement.</li>
<li>Hard drives are one of the slowest parts of the computer system and thus need to be accessed in an efficient manner.</li>
</ul>
<p>There are many Disk Scheduling Algorithms but before discussing them let’s have a quick look at some of the important terms:</p>
<ul>
<li><strong><u>Seek Time</u></strong><strong>:</strong>Seek time is the time taken to locate the disk arm to a specified track where the data is to be read or write. So the disk scheduling algorithm that gives minimum average seek time is better.</li>
<li><strong><u>Rotational Latency:</u></strong> Rotational Latency is the time taken by the desired sector of disk to rotate into a position so that it can access the read/write heads. So the disk scheduling algorithm that gives minimum rotational latency is better.</li>
<li><strong><u>Transfer Time:</u></strong> Transfer time is the time to transfer the data. It depends on the rotating speed of the disk and number of bytes to be transferred.</li>
<li><strong><u>Disk Access Time:</u></strong> Disk Access Time is:</li>
</ul>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<pre>             

      Disk Access Time = Seek Time + 

                         Rotational Latency + 

                         Transfer Time</pre>
<p style="text-align: left"><a href="https://media.geeksforgeeks.org/wp-content/uploads/disc-scheduling-algorithms.png"><img alt="os1" class="aligncenter size-full wp-image-19567" height="207" src="https://media.geeksforgeeks.org/wp-content/uploads/disc-scheduling-algorithms.png" width="702"/></a></p>
<ul>
<li style="text-align: left"><strong><u>Disk Response Time: </u></strong>Response Time is the average of time spent by a request waiting to perform its I/O operation. <em>Average Response time </em>is the response time of the all requests. <em>Variance Response Time </em>is measure of how individual request are serviced with respect to average response time. So the disk scheduling algorithm that gives minimum variance response time is better.</li>
</ul>
<p><strong><u>Disk Scheduling Algorithms</u></strong></p>
<ol>
<li><strong><u>FCFS: </u></strong>FCFS is the simplest of all the Disk Scheduling Algorithms. In FCFS, the requests are addressed in the order they arrive in the disk queue.</li>
</ol>
<p>Advantages:</p>
<ul>
<li>Every request gets a fair chance</li>
<li>No indefinite postponement</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Does not try to optimize seek time</li>
<li>May not provide the best possible service</li>
</ul>
<ol start="2">
<li><strong><u>SSTF:</u></strong> In SSTF (Shortest Seek Time First), requests having shortest seek time are executed first. So, the seek time of every request is calculated in advance in the queue and then they are scheduled according to their calculated seek time. As a result, the request near the disk arm will get executed first. SSTF is certainly an improvement over FCFS as it decreases the average response time and increases the throughput of system.</li>
</ol>
<p>Advantages:</p>
<ul>
<li>Average Response Time decreases</li>
<li>Throughput increases</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Overhead to calculate seek time in advance</li>
<li>Can cause Starvation for a request if it has higher seek time as compared to incoming requests</li>
<li>High variance of response time as SSTF favours only some requests</li>
</ul>
<ol start="3">
<li><strong><u>SCAN: </u></strong>In SCAN algorithm the disk arm moves into a particular direction and services the requests coming in its path and after reaching the end of disk, it reverses its direction and again services the request arriving in its path. So, this algorithm works as an elevator and hence also known as <strong>elevator algorithm. </strong>As a result, the requests at the midrange are serviced more and those arriving behind the disk arm will have to wait.</li>
</ol>
<p>Advantages:</p>
<ul>
<li>High throughput</li>
<li>Low variance of response time</li>
<li>Average response time</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>Long waiting time for requests for locations just visited by disk arm</li>
</ul>
<ol start="4">
<li><strong><u>CSCAN</u></strong>: In SCAN algorithm, the disk arm again scans the path that has been scanned, after reversing its direction. So, it may be possible that too many requests are waiting at the other end or there may be zero or few requests pending at the scanned area.</li>
</ol>
<p>These situations are avoided in <em>CSCAN </em>algorithm in which the disk arm instead of reversing its direction goes to the other end of the disk and starts servicing the requests from there. So, the disk arm moves in a circular fashion and this algorithm is also similar to SCAN algorithm and hence it is known as C-SCAN (Circular SCAN).</p>
<p>Advantages:</p>
<ul>
<li>Provides more uniform wait time compared to SCAN</li>
</ul>
<ol start="5">
<li><strong><u>LOOK:</u></strong> It is similar to the SCAN disk scheduling algorithm except for the difference that the disk arm in spite of going to the end of the disk goes only to the last request to be serviced in front of the head and then reverses its direction from there only. Thus it prevents the extra delay which occurred due to unnecessary traversal to the end of the disk.</li>
</ol>
<ol start="6">
<li><strong><u>CLOOK:</u></strong> As LOOK is similar to SCAN algorithm, in similar way, CLOOK is similar to CSCAN disk scheduling algorithm. In CLOOK, the disk arm in spite of going to the end goes only to the last request to be serviced in front of the head and then from there goes to the other end’s last request. Thus, it also prevents the extra delay which occurred due to unnecessary traversal to the end of the disk.</li>
</ol>
<p>Each algorithm is unique in its own way. Overall Performance depends on the number and type of requests.<br/>
<strong>Note:</strong>Average Rotational latency is generally taken as 1/2(Rotational latency).<br/>
Exercise</p>
<p><strong>1)</strong> Suppose a disk has 201 cylinders, numbered from 0 to 200. At some time the disk arm is at cylinder 100, and there is a queue of disk access requests for cylinders 30, 85, 90, 100, 105, 110, 135 and 145. If Shortest-Seek Time First (SSTF) is being used for scheduling the disk access, the request for cylinder 90 is serviced after servicing ____________ number of requests. (GATE CS 2014<br/>
(A) 1<br/>
(B) 2<br/>
(C) 3<br/>
(D) 4<br/>
See <a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-29/">this</a> for solution.</p>
<p><strong>2)</strong> Consider an operating system capable of loading and executing a single sequential user process at a time. The disk head scheduling algorithm used is First Come First Served (FCFS). If FCFS is replaced by Shortest Seek Time First (SSTF), claimed by the vendor to give 50% better benchmark results, what is the expected improvement in the I/O performance of user programs? (GATE CS 2004)<br/>
(A) 50%<br/>
(B) 40%<br/>
(C) 25%<br/>
(D) 0%<br/>
See <a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2004-question-12/">this</a> for solution.</p>
<p><strong>3) </strong> Suppose the following disk request sequence (track numbers) for a disk with 100 tracks is given: 45, 20, 90, 10, 50, 60, 80, 25, 70. Assume that the initial position of the R/W head is on track 50. The additional distance that will be traversed by the R/W head when the Shortest Seek Time First (SSTF) algorithm is used compared to the SCAN (Elevator) algorithm (assuming that SCAN algorithm moves towards 100 when it starts execution) is _________ tracks<br/>
(A) 8<br/>
(B) 9<br/>
(C) 10<br/>
(D) 11<br/>
See <a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2015-set-1-question-40/">this</a> for solution.</p>
<p><strong>4)</strong> Consider a typical disk that rotates at 15000 rotations per minute (RPM) and has a transfer rate of 50 × 10^6 bytes/sec. If the average seek time of the disk is twice the average rotational delay and the controller’s transfer time is 10 times the disk transfer time, the average time (in milliseconds) to read or write a 512 byte sector of the disk is _____________<br/>
See <a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2015-set-2-question-59/">this</a> for solution.</p>
<p>This article is contributed by <strong>Ankit Mittal</strong>. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a>, <a href="https://auth.geeksforgeeks.org/user/SachinNegi688/">SachinNegi688</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142274 post type-post status-publish format-standard hentry category-difference-between category-operating-systems tag-os-process-synchronization" id="post-142274">
<header class="entry-header">
<h1 class="entry-title">What’s difference between Priority Inversion and Priority Inheritance ?</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p style="text-align: justify">Both of these concepts come under Priority scheduling in Operating System. But are they same ?</p>
<p style="text-align: justify">In one line, <em>Priority Inversion</em> is a <strong>problem</strong> while <em>Priority Inheritance</em> is a <strong>solution</strong>. Literally, <em>Priority Inversion</em> means that priority of tasks get inverted and <em>Priority Inheritance</em> means that priority of tasks get inherited. Both of these phenomena happen in priority scheduling. Basically, in <em>Priority Inversion</em>, higher priority task (H) ends up waiting for middle priority task (M) when H is sharing critical section with lower priority task (L) and L is already in critical section. Effectively, H waiting for M results in inverted priority i.e. Priority Inversion. One of the solution for this problem is <em>Priority Inheritance</em>. In <em>Priority Inheritance</em>, when L is in critical section, L inherits priority of H at the time when H starts pending for critical section. By doing so, M doesn’t interrupt L and H doesn’t wait for M to finish. Please note that inheriting of priority is done temporarily i.e. L goes back to its old priority when L comes out of critical section.</p>
<p style="text-align: justify">More details on these can be found <a href="https://www.geeksforgeeks.org/priority-inversion-what-the-heck/">here</a>.</p>
<p style="text-align: justify"> <span style="font-weight: 400">Please do Like/Tweet/G+1 if you find the above useful. Also, please do leave us comment for further clarification or info. We would love to help and learn 🙂</span></p>
<p style="text-align: justify">
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</p></div></article><hr style="border: 2px dashed black;" /><article class="post-135525 post type-post status-publish format-standard hentry category-articles category-operating-systems tag-os-process-synchronization" id="post-135525">
<header class="entry-header">
<h1 class="entry-title">Priority Inversion : What the heck !</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p style="text-align: justify">Let us first put ‘priority inversion’ in the context of the Big Picture i.e. where does this come from. <!--more--></p>
<p style="text-align: justify">In Operating System, one of the important concepts is Task Scheduling. There are several Scheduling methods such as First Come First Serve, Round Robin, Priority-based scheduling, etc. Each scheduling method has its pros and cons. As you might have guessed, Priority Inversion comes under Priority based Scheduling. Basically, it’s a problem which arises sometimes when Priority based scheduling is used by OS. In Priority based scheduling, different tasks are given different priority so that higher priority tasks can intervene in lower priority tasks if possible. </p>
<p>So, in a priority based scheduling, if lower priority task (L) is running and if a higher priority task (H) also needs to run, the lower priority task (L) would be preempted by higher priority task (H). Now, suppose both lower and higher priority tasks need to share a common resource (say access to the same file or device) to achieve their respective work. In this case, since there’s resource sharing and task synchronization is needed, several methods/techniques can be used for handling such scenarios. For sake of our topic on Priority Inversion, let us mention a synchronization method say mutex. Just to recap on the mutex, a task acquires mutex before entering critical section (CS) and releases mutex after exiting critical section (CS). While running in CS, task access this common resource. More details on this can be referred <a href="https://www.geeksforgeeks.org/g-fact-70/">here</a>. Now, say both L and H shares a common Critical Section (CS) i.e. the same mutex is needed for this CS.</p>
<p style="text-align: justify">Coming to our discussion of priority inversion, let us examine some scenarios.<br/>
1) L is running but not in CS; H needs to run; H preempts L; H starts running; H relinquishes or releases control; L resumes and starts running<br/>
2) L is running in CS; H needs to run but not in CS; H preempts L; H starts running; H relinquishes control; L resumes and starts running.<br/>
3) L is running in CS; H also needs to run in CS; H waits for L to come out of CS; L comes out of CS; H enters CS and starts running</p>
<p style="text-align: justify">Please note that the above scenarios don’t show the problem of any Priority Inversion (not even scenario 3). Basically, so long as lower priority task isn’t running in shared CS, higher priority task can preempt it. But if L is running in shared CS and H also needs to run in CS, H waits until L comes out of CS. The idea is that CS should be small enough so that it doesn’t result in H waiting for a long time while L was in CS. That’s why writing a CS code requires careful consideration. In any of the above scenarios, priority inversion (i.e. reversal of priority) didn’t occur because the tasks are running as per the design.</p>
<p style="text-align: justify">Now let us add another task of middle priority say M. Now the task priorities are in the order of L &lt; M &lt; H. In our example, M doesn’t share the same Critical Section (CS). In this case, the following sequence of task running would result in ‘Priority Inversion’ problem.</p>
<p style="text-align: justify">4) L is running in CS ; H also needs to run in CS ; H waits for L to come out of CS ; M interrupts L and starts running ; M runs till completion and relinquishes control ; L resumes and starts running till the end of CS ; H enters CS and starts running.<br/>
Note that neither L nor H share CS with M.</p>
<p style="text-align: justify">Here, we can see that running of M has delayed the running of both L and H. Precisely speaking, H is of higher priority and doesn’t share CS with M; but H had to wait for M. This is where Priority based scheduling didn’t work as expected because priorities of M and H got inverted in spite of not sharing any CS. This problem is called Priority Inversion. This is what the heck was Priority Inversion! In a system with priority based scheduling, higher priority tasks can face this problem and it can result in unexpected behavior/result. In general purpose OS, it can result in slower performance. In RTOS, it can result in more severe outcomes. The most famous ‘Priority Inversion’ problem was what happened at Mars Pathfinder.</p>
<p style="text-align: justify">If we have a problem, there has to be solution for this. For Priority Inversion as well, there’re different solutions such as Priority Inheritance, etc. This is going to be our next article 🙂</p>
<p> But for the inpatients, <a href="https://www.geeksforgeeks.org/whats-difference-priority-inversion-priority-inheritance/">this</a> can be referred for time being.</p>
<p style="text-align: justify">Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p style="text-align: justify">
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/Akanksha_Rai/">Akanksha_Rai</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></p></div></article><hr style="border: 2px dashed black;" /><article class="post-142471 post type-post status-publish format-standard hentry category-operating-systems tag-os-processes-threads" id="post-142471">
<header class="entry-header">
<h1 class="entry-title">Multi threading models</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Many operating systems support kernel thread and user thread in a combined way. Example of such system is Solaris. Multi threading model are of three types.</p>
<pre>Many to many model.

Many to one model.

one to one model.</pre>
<p><strong>Many to Many Model</strong></p>
<p>In this model, we have multiple user threads multiplex to same or lesser number of kernel level threads. Number of kernel level threads are specific to the machine, advantage of this model is if a user thread is blocked we can schedule others user thread to other kernel thread. Thus, System doesn’t block if a particular thread is blocked.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many1.jpg"><img alt="many_to_many" class="alignnone size-medium wp-image-18011" height="200" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many1-300x200.jpg" width="300"/></a></p>
<p><strong>Many to One Model</strong></p>
<p>In this model, we have multiple user threads mapped to one kernel thread. In this model when a user thread makes a blocking system call entire process blocks. As we have only one kernel thread and only one user thread can access kernel at a time, so multiple threads are not able access multiprocessor at the same time. </p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many2.jpg"><img alt="many_to_many" class="alignnone size-medium wp-image-18013" height="200" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many2-300x200.jpg" width="300"/></a></p>
<p><strong>One to One Model</strong><br/>
In this model, one to one relationship between kernel and user thread. In this model multiple thread can run on multiple processor. Problem with this model is that creating a user thread requires the corresponding kernel thread.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many3.jpg"><img alt="many_to_many" class="alignnone size-medium wp-image-18014" height="200" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/07/many_to_many3-300x200.jpg" width="300"/></a></p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-142472 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-memory-management" id="post-142472">
<header class="entry-header">
<h1 class="entry-title">Page Replacement Algorithms in Operating Systems</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In an operating system that uses paging for memory management, a page replacement algorithm is needed to decide which page needs to be replaced when new page comes in. </p>
<p><strong>Page Fault –</strong> A page fault happens when a running program accesses a memory page that is mapped into the virtual address space, but not loaded in physical memory.</p>
<p>Since actual physical memory is much smaller than virtual memory, page faults happen. In case of page fault, Operating System might have to replace one of the existing pages with the newly needed page.  Different page replacement algorithms suggest different ways to decide which page to replace. The target for all algorithms is to reduce the number of page faults.</p>
<p><strong>Page Replacement Algorithms :</strong></p>
<ul>
<li><strong>First In First Out (FIFO) –</strong><br/>
This is the simplest page replacement algorithm. In this algorithm, the operating system keeps track of all pages in the memory in a queue, the oldest page is in the front of the queue. When a page needs to be replaced page in the front of the queue is selected for removal.</li></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-142470 post type-post status-publish format-standard hentry category-operating-systems tag-os-processes-threads" id="post-142470">
<header class="entry-header">
<h1 class="entry-title">Operating System | Thread</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div></div>
<p><strong>What is a Thread?</strong><br/>
A thread is a path of execution within a process. A process can contain multiple threads. <!--more--><br/>
<strong>Why Multithreading?</strong><br/>
A thread is also known as lightweight process. The idea is to achieve parallelism by dividing a process into multiple threads. For example, in a browser, multiple tabs can be different threads. MS Word uses multiple threads: one thread to format the text, another thread to process inputs, etc. More advantages of multithreading are discussed below<br/>
<strong>Process vs Thread?</strong><br/>
The primary difference is that threads within the same process run in a shared memory space, while processes run in separate memory spaces.<br/>
Threads are not independent of one another like processes are, and as a result threads share with other threads their code section, data section, and OS resources (like open files and signals). But, like process, a thread has its own program counter (PC), register set, and stack space.<br/>
<em><strong>Advantages of Thread over Process</strong></em><br/>
<em>1. Responsiveness: </em> If the process is divided into multiple threads, if one thread completes its execution, then its output can be immediately returned.</p>
<p><em>2. Faster context switch: </em>Context switch time between threads is lower compared to process context switch. Process context switching requires more overhead from the CPU.</p>
<p><em>3. Effective utilization of multiprocessor system: </em> If we have multiple threads in a single process, then we can schedule multiple threads on multiple processor. This will make process execution faster.</p>
<p><em>4. Resource sharing: </em> Resources like code, data, and files can be shared among all threads within a process.<br/>
Note: stack and registers can’t be shared among the threads. Each thread has its own stack and registers.</p>
<p><em>5. Communication: </em>Communication between multiple threads is easier, as the threads shares common address space. while in process we have to follow some specific communication technique for communication between two process.</p>
<p><em>6. Enhanced throughput of the system: </em> If a process is divided into multiple threads, and each thread function is considered as one job, then the number of jobs completed per unit of time is increased, thus increasing the throughput of the system.<br/>
<strong>Types of Threads</strong><br/>
There are two types of threads.<br/>
User Level Thread<br/>
Kernel Level Thread<br/>
Refer  for more details.</p>
<p>Below are previous years’ gate questions on threads:<br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2011-question-16/">http://quiz.geeksforgeeks.org/gate-gate-cs-2011-question-16/</a><br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2007-question-17/">http://quiz.geeksforgeeks.org/gate-gate-cs-2007-question-17/</a><br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-30/">http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-30/</a></p>
<p><strong>Reference:</strong><br/>
<a href="https://www.geeksforgeeks.org/multithreading-c-2/">Multithreading in C</a></p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/chrismaher37/">chrismaher37</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142469 post type-post status-publish format-standard hentry category-operating-systems tag-memory-management" id="post-142469">
<header class="entry-header">
<h1 class="entry-title">Operating System | Memory Management | Partition Allocation Method</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>In the operating system, the following are four common memory management techniques.<!--more--></p>
<p><strong>Single contiguous allocation:</strong>  Simplest allocation method used by MS-DOS. All memory (except some reserved for OS) is available to a process.</p>
<p><strong>Partitioned allocation:</strong> Memory is divided in different blocks or partitions.Each process is allocated accroding to the requirment.</p>
<p><strong>Paged memory management:</strong> Memory is divided into fixed sized units called page frames, used in a virtual memory environment.</p>
<p><strong>Segmented memory management:</strong> Memory is divided in different segments (a segment is a logical grouping of the process’ data or code).In this management, allocated memory doesn’t have to be contiguous.</p>
<p>Most of the operating systems (for example Windows and Linux) use Segmentation with Paging.  A process is divided into segments and individual segments have pages.  </p>
<p>In <strong>Partition Allocation</strong>, when there is more than one partition freely available to accommodate a process’s request, a partition must be selected.  To choose a particular partition, a partition allocation method is needed. A partition allocation method is considered better if it avoids internal fragmentation.</p>
<p>Below are the various partition allocation schemes :</p>
<p><strong>1. First Fit</strong>: In the first fit, the partition is allocated which is first sufficient block from the top of Main Memory.</p>
<p><strong>2. Best Fit </strong> Allocate the process to the partition which is the first smallest sufficient partition among the free available partition.</p>
<p><strong>3. Worst Fit </strong> Allocate the process to the partition which is the largest sufficient among the freely available partitions available in the main memory. </p>
<p><strong>4. Next Fit</strong> Next fit is similar to the first fit but it will search for the first sufficient partition from the last allocation point.</p>
<p><strong>Is Best-Fit really best?</strong><br/>
Although best fit minimizes the wastage space, it consumes a lot of processor time for searching the block which is close to the required size.  Also, Best-fit may perform poorer than other algorithms in some cases.  For example, see below exercise.</p>
<p> </p>
<p><strong>Exercise: </strong>Consider the requests from processes in given order 300K, 25K, 125K and 50K. Let there be two blocks of memory available of size 150K followed by a block size 350K.<br/>
Which of the following partition allocation schemes can satisfy above requests?<br/>
A) Best fit but not first fit.<br/>
B) First fit but not best fit.<br/>
C) Both First fit &amp; Best fit.<br/>
D) neither first fit nor best fit.</p>
<p>Solution: Let us try all options.<br/>
Best Fit:<br/>
300K is allocated from block of size 350K.  50 is left in the block.<br/>
25K is allocated from the remaining 50K block.  25K is left in the block.<br/>
125K is allocated from 150 K block. 25K is left in this block also.<br/>
50K can’t be allocated even if there is 25K + 25K space available.</p>
<p>First Fit:<br/>
300K request is allocated from 350K block, 50K is left out.<br/>
25K is be allocated from 150K block, 125K is  left out.<br/>
Then 125K and 50K are allocated to remaining left out partitions.<br/>
So, first fit can handle requests.</p>
<p>So option B is the correct choice.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142269 post type-post status-publish format-standard hentry category-operating-systems tag-os-processes-threads" id="post-142269">
<header class="entry-header">
<h1 class="entry-title">Operating System | User Level thread Vs Kernel Level thread</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<table style="font-size:20px">
<tr>
<th style="font-size:20px"> <strong>User level thread</strong> </th>
<th style="font-size:20px"> <strong>Kernel level thread</strong> </th>
</tr>
<tr>
<td>User thread are implemented by users.</td>
<td>kernel threads are implemented by OS. </td>
</tr>
<tr>
<td>OS doesn’t recognized user level threads.</td>
<td>Kernel threads are recognized by OS. </td>
</tr>
<tr>
<td>Implementation of User threads is easy.</td>
<td>Implementation of Kernel thread is complicated.</td>
</tr>
<tr>
<td>Context switch time is less.</td>
<td>Context switch time is more.</td>
</tr>
<tr>
<td>Context switch requires no hardware support.</td>
<td>Hardware support is needed.</td>
</tr>
<tr>
<td> If one user level thread perform blocking operation then entire process will be blocked.</td>
<td> If one kernel thread perform blocking operation then another thread can continue execution.</td>
</tr>
<td>Example : Java thread, POSIX threads.</td>
<td>Example : Window Solaris.</td>
</table></div></article><hr style="border: 2px dashed black;" /><article class="post-142468 post type-post status-publish format-standard hentry category-operating-systems tag-os-process-synchronization" id="post-142468">
<header class="entry-header">
<h1 class="entry-title">Process Synchronization | Monitors</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Monitor is one of the ways to achieve Process synchronization. Monitor is supported by programming languages to achieve mutual exclusion between processes. For example Java Synchronized methods. Java provides wait() and notify() constructs. <!--more--></p>
<p>1. It is the collection of condition variables and procedures combined together in a special kind of module or a package.<br/>
2. The processes running outside the monitor can’t access the internal variable of monitor but can call procedures of the monitor.<br/>
3. Only one process at a time can execute code inside monitors.</p>
<p><strong>Syntax of Monitor</strong></p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/monitors.png"><img alt="monitors" class="alignnone size-medium wp-image-17763" height="255" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/monitors-300x255.png" width="300"/></a></p>
<p><strong>Condition Variables</strong></p>
<p>Two different operations are performed on the condition variables of the monitor.</p>
<pre>Wait.

signal.</pre>
<p>let say we have 2 condition variables<br/>
<strong>condition x, y; //Declaring variable</strong></p>
<p> </p>
<p><strong>Wait operation</strong><br/>
x.wait() : Process performing wait operation on any condition variable are suspended. The suspended processes are placed in block queue of that condition variable.</p>
<p><strong>Note:</strong> Each condition variable has its unique block queue.</p>
<p> </p>
<p><strong>Signal operation</strong><br/>
x.signal(): When a process performs signal operation on condition variable, one of the blocked processes is given chance.</p>
<pre>If (x block queue empty)

  // Ignore signal

else

  // Resume a process from block queue.</pre>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-142467 post type-post status-publish format-standard hentry category-operating-systems tag-os-deadlocks" id="post-142467">
<header class="entry-header">
<h1 class="entry-title">Deadlock Detection And Recovery</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>In the previous post, we have discussed . In this post, Deadlock Detection and Recovery technique to handle deadlock is discussed. </p>
<p><strong>Deadlock Detection</strong></p>
<p><strong></strong></p>
<ol>
<li></li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-142267 post type-post status-publish format-standard hentry category-articles-gq category-operating-systems tag-os-deadlocks" id="post-142267">
<header class="entry-header">
<h1 class="entry-title">Deadlock Prevention And Avoidance</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p><strong>Deadlock Characteristics</strong><br/>
As discussed in the <a href="http://quiz.geeksforgeeks.org/operating-system-process-management-deadlock-introduction/">previous post</a>, deadlock has following characteristics.<!--more--></p>
<ol>
<li>Mutual Exclusion</li>
<li>Hold and Wait</li>
<li>No preemption</li>
<li>Circular wait</li>
</ol>
<p> </p>
<p><strong>Deadlock Prevention</strong></p>
<p>We can prevent Deadlock by eliminating any of the above four conditions.</p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><strong>Eliminate Mutual Exclusion </strong><br/>
It is not possible to dis-satisfy the mutual exclusion because some resources, such as the tap drive and printer, are inherently non-shareable.</p>
<p> </p>
<p><strong>Eliminate Hold and wait</strong></p>
<ol>
<li> Allocate all required resources to the process before the start of its execution, this way hold and wait condition is eliminated but it will lead to low device utilization. for example, if a process requires printer at a later time and we have allocated printer before the start of its execution printer will remain blocked till it has completed its execution.
<li> The process will make a new request for resources after releasing the current set of resources. This solution may lead to starvation.</li></li></ol>
<p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2015/06/holdnwait.png"><img alt="holdnwait" class="alignnone size-medium wp-image-17733" height="183" src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2015/06/holdnwait-300x183.png" width="300"/></a></p>
<p><strong>Eliminate No Preemption</strong><br/>
Preempt resources from the process when resources required by other high priority processes.</p>
<p> </p>
<p><strong>Eliminate Circular Wait</strong><br/>
Each resource will be assigned with a numerical number. A process can request the resources increasing/decreasing. order of numbering.<br/>
For Example, if P1 process is allocated R5 resources, now next time if P1 ask for R4, R3 lesser than R5 such request will not be granted, only request for resources more than R5 will be granted.</p>
<p> </p>
<p> </p>
<p><strong>Deadlock Avoidance</strong></p>
<p>Deadlock avoidance can be done with Banker’s Algorithm.</p>
<p><strong>Banker’s Algorithm</strong></p>
<p>Bankers’s Algorithm is resource allocation and deadlock avoidance algorithm which test all the request made by processes for resources, it checks for the safe state, if after granting request system remains in the safe state it allows the request and if there is no safe state it doesn’t allow the request made by the process.</p>
<p><strong>Inputs to Banker’s Algorithm:</strong></p>
<ol>
<li>Max need of resources by each process.
<li>Currently allocated resources by each process.
<li>Max free available resources in the system.</li></li></li></ol>
<p><strong>The request will only be granted under the below condition:</strong></p>
<ol>
<li>If the request made by the process is less than equal to max need to that process.
<li>If the request made by the process is less than equal to the freely available resource in the system.</li></li></ol>
<p><strong>Example:</strong></p>
<pre>Total resources in system:

A B C D

6 5 7 6</pre>
<pre>Available system resources are:

A B C D

3 1 1 2</pre>
<pre>Processes (currently allocated resources):

    A B C D

P1  1 2 2 1

P2  1 0 3 3

P3  1 2 1 0</pre>
<pre>Processes (maximum resources):

    A B C D

P1  3 3 2 2

P2  1 2 3 4

P3  1 3 5 0</pre>
<pre>Need = maximum resources - currently allocated resources.

Processes (need resources):

    A B C D

P1  2 1 0 1

P2  0 2 0 1

P3  0 1 4 0</pre>
<p><strong>Note:</strong>Deadlock prevention is more strict that Deadlock Avoidance.</p>
<p>Following are Gate Previous Year Question<br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-41/">http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-41/</a><br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-3-question-41/">http://quiz.geeksforgeeks.org/gate-gate-cs-2014-set-3-question-41/</a><br/>
<a href="http://quiz.geeksforgeeks.org/gate-gate-cs-2010-question-46/">http://quiz.geeksforgeeks.org/gate-gate-cs-2010-question-46/</a></p>
<p><strong>References</strong><br/>
</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142466 post type-post status-publish format-standard hentry category-operating-systems tag-os-deadlocks" id="post-142466">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Management | Deadlock Introduction</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div></div>
<p>A process in operating systems uses different resources and uses resources in following way.<br/>
1) Requests a resource<br/>
2) Use the resource<!--more--><br/>
2) Releases the resource</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-142465 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-os-process-synchronization" id="post-142465">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Synchronization | Introduction</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div hidead="auto"></div>
<p>On the basis of synchronization, processes are categorized as one of the following two types:</p>
<ul>
<li><strong>Independent Process</strong> : Execution of one process does not affects the execution of other processes.</li>
<li><strong>Cooperative Process</strong> : Execution of one process affects the execution of other processes.</li>
</ul>
<p>Process synchronization problem arises in the case of Cooperative process also because resources are shared in Cooperative processes.<br/>
 <br/>
<strong>Race Condition</strong><br/>
Several processes access and process the manipulations over the same data concurrently, then the outcome depends on the particular order in which the access takes place.<br/>
 <br/>
<strong>Critical Section Problem</strong></p>
<p>Critical section is a code segment that can be accessed by only one process at a time. Critical section contains shared variables which need to be synchronized to maintain consistency of data variables.<br/>
<a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/critical-section-problem.png"><img alt="critical section problem" class="aligncenter size-full wp-image-24619" height="386" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/critical-section-problem.png" width="345"/></a></p>
<p>In the entry section, the process requests for entry in the <strong>Critical Section.</strong></p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p>Any solution to the critical section problem must satisfy three requirements:</p>
<ul>
<li><strong>Mutual Exclusion</strong> : If a process is executing in its critical section, then no other process is allowed to execute in the critical section.</li>
<li><strong>Progress</strong> : If no process is executing in the critical section and other processes are waiting outside the critical section, then only those processes that are not executing in their remainder section can participate in deciding which will enter in the critical section next, and the selection can not be postponed indefinitely.</li>
<li><strong>Bounded Waiting</strong> :  A bound must exist on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted.</li>
</ul>
<p> <br/>
<strong>Peterson’s Solution</strong><br/>
Peterson’s Solution is a classical software based solution to the critical section problem.</p>
<p>In Peterson’s solution, we have two shared variables:</p>
<ul>
<li>boolean flag[i] :Initialized to FALSE, initially no one is interested in entering the critical section</li>
<li>int turn : The process whose turn is to enter the critical section.</li>
</ul>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/peterson.png"><img alt="peterson" class="aligncenter size-full wp-image-24623" height="478" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/peterson.png" width="492"/></a><br/>
 <br/>
Peterson’s Solution preserves all three conditions :</p>
<ul>
<li>Mutual Exclusion is assured as only one process can access the critical section at any time.</li>
<li>Progress is also assured, as a process outside the critical section does not block other processes from entering the critical section.</li>
<li>Bounded Waiting is preserved as every process gets a fair chance.</li>
<p> <br/>
Disadvantages of Peterson’s Solution</p>
<ul>
<li>It involves Busy waiting</li>
<li>It is limited to 2 processes.</li>
</ul>
<p> </p>
<p><strong>TestAndSet</strong><br/>
TestAndSet is a hardware solution to the synchronization problem. In TestAndSet, we have a shared lock variable which can take either of the two values, 0 or 1.</p>
<pre>0 Unlock

1 Lock

</pre>
<p>Before entering into the critical section, a process inquires about the lock. If it is locked, it keeps on waiting till it becomes free and if it is not locked, it takes the lock and executes the critical section.</p>
<p>In TestAndSet, Mutual exclusion and progress are preserved but bounded waiting cannot be preserved.<br/>
 <br/>
<strong>Question :</strong> The enter_CS() and leave_CS() functions to implement critical section of a process are realized using test-and-set instruction as follows:</p>
<pre>

int TestAndSet(int &amp;lock) {

    int initial = lock;

    lock = 1;

    return initial;

}



void enter_CS(X)

{

  while test-and-set(X) ;

}



void leave_CS(X)

{

  X = 0;

}

</pre>
<p>In the above solution, X is a memory location associated with the CS and is initialized to 0. Now, consider the following statements:<br/>
I. The above solution to CS problem is deadlock-free<br/>
II. The solution is starvation free.<br/>
III. The processes enter CS in FIFO order.<br/>
IV. More than one process can enter CS at the same time.<br/>
 <br/>
Which of the above statements is TRUE?<br/>
(A) I<br/>
(B) II and III<br/>
(C) II and IV<br/>
(D) IV</p>
<p>.<br/>
 true<br/>
<strong>Semaphores</strong></p>
<p>A Semaphore is an integer variable, which can be accessed only through two operations <em>wait()</em> and <em>signal()</em>.<br/>
There are two types of semaphores : Binary Semaphores and Counting Semaphores</p>
<ul>
<li>Binary Semaphores : They can only be either 0 or 1. They are also known as mutex locks, as the locks can provide mutual exclusion. All the processes can share the same mutex semaphore that is initialized to 1. Then, a process has to wait until the lock becomes 0. Then, the process can make the mutex semaphore 1 and start its critical section. When it completes its critical section, it can reset the value of mutex semaphore to 0 and some other process can enter its critical section.</li>
<li>Counting Semaphores: They can have any value and are not restricted over a certain domain. They can be used to control access to a resource that has a limitation on the number of simultaneous accesses. The semaphore can be initialized to the number of instances of the resource. Whenever a process wants to use that resource, it checks if the number of remaining instances is more than zero, i.e., the process has an instance available. Then, the process can enter its critical section thereby decreasing the value of the counting semaphore by 1. After the process is over with the use of the instance of the resource, it can leave the critical section thereby adding 1 to the number of available instances of the resource.</li>
</ul>
<p>true</p>
<p> </p>
<p><strong>References</strong><br/>
www.csee.wvu.edu/~jdmooney/classes/cs550/notes/tech/mutex/Peterson.html<br/>
<a href="http://iit.qau.edu.pk/books/OS_8th_Edition.pdf">http://iit.qau.edu.pk/books/OS_8th_Edition.pdf</a><br/>
 <br/>
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/AmishRanjan/">AmishRanjan</a>, <a href="https://auth.geeksforgeeks.org/user/vaishnavipandey/">vaishnavipandey</a>, <a href="https://auth.geeksforgeeks.org/user/shreyashagrawal/">shreyashagrawal</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></ul></div></article><hr style="border: 2px dashed black;" /><article class="post-142464 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-142464">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Management | CPU Scheduling</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Scheduling of processes/work is done to finish the work on time.</p>
<p>Below are different time with respect to a process.</p>
<pre><strong>Arrival Time: </strong>      Time at which the process arrives in the ready queue.

<strong>Completion Time:</strong>    Time at which process completes its execution.<!--more-->

<strong>Burst Time: </strong>        Time required by a process for CPU execution.

<strong>Turn Around Time: </strong>  Time Difference between completion time and arrival time.          

     Turn Around Time = Completion Time - Arrival Time



<strong>Waiting Time(W.T):</strong> Time Difference between turn around time and burst time.

     Waiting Time = Turn Around Time - Burst Time</pre>
<p> </p>
<p><strong>Why do we need scheduling?</strong><br/>
A typical process involves both I/O time and CPU time. In a uni programming system like MS-DOS, time spent waiting for I/O is wasted and CPU is free during this time. In multi programming systems, one process can use CPU while another is waiting for I/O. This is possible only with process scheduling.</p>
<p> </p>
<p><strong>Objectives of Process Scheduling Algorithm</strong></p>
<pre>Max CPU utilization [Keep CPU as busy as possible]

Fair allocation of CPU.

Max throughput [Number of processes that complete their execution per time unit]

Min turnaround time [Time taken by a process to finish execution]

Min waiting time [Time a process waits in ready queue]

Min response time [Time when a process produces first response]</pre>
<p> </p>
<h2><strong>Different Scheduling Algorithms</strong></h2>
<p><em><strong>First Come First Serve (FCFS):</strong></em> Simplest scheduling algorithm that schedules according to arrival times of processes. First come first serve scheduling algorithm states that the process that requests the CPU first is allocated the CPU first. It is implemented by using the FIFO queue. When a process enters the ready queue, its PCB is linked onto the tail of the queue. When the CPU is free, it is allocated to the process at the head of the queue. The running process is then removed from the queue. FCFS is a non-preemptive scheduling algorithm.</p>
<p><strong>Note:</strong>First come first serve suffers from .</p>
<p><em><strong>Shortest Job First(SJF):</strong></em> Process which have the shortest burst time are scheduled first.If two processes have the same bust time then FCFS is used to break the tie. It is a non-preemptive scheduling algorithm.</p>
<p><em><strong>Longest Job First(LJF):</strong></em> It is similar to SJF scheduling algorithm. But, in this scheduling algorithm, we give priority to the process having the longest burst time. This is non-preemptive in nature i.e., when any process starts executing, can’t be interrupted before complete execution.</p>
<p><em><strong>Shortest Remaining Time First(SRTF):</strong></em> It is preemptive mode of SJF algorithm in which jobs are schedule according to shortest remaining time.</p>
<p><em><strong>Longest Remaining Time First(LRTF):</strong></em> It is preemptive mode of LJF algorithm in which we give priority to the process having largest burst time remaining.</p>
<p><em><strong>Round Robin Scheduling:</strong></em> Each process is assigned a fixed time(Time Quantum/Time Slice) in cyclic way.It is designed especially for the time-sharing system. The ready queue is treated as a circular queue. The CPU scheduler goes around the ready queue, allocating the CPU to each process for a time interval of up to 1-time quantum. To implement Round Robin scheduling, we keep the ready queue as a FIFO queue of processes. New processes are added to the tail of the ready queue. The CPU scheduler picks the first process from the ready queue, sets a timer to interrupt after 1-time quantum, and dispatches the process. One of two things will then happen. The process may have a CPU burst of less than 1-time quantum. In this case, the process itself will release the CPU voluntarily. The scheduler will then proceed to the next process in the ready queue. Otherwise, if the CPU burst of the currently running process is longer than 1-time quantum, the timer will go off and will cause an interrupt to the operating system. A context switch will be executed, and the process will be put at the tail of the ready queue. The CPU scheduler will then select the next process in the ready queue.</p>
<p><em><strong>Priority Based scheduling (Non-Preemptive):</strong></em> In this scheduling, processes are scheduled according to their priorities, i.e., highest priority process is scheduled first. If priorities of two processes match, then schedule according to arrival time. Here starvation of process is possible.</p>
<p><em><strong>Highest Response Ratio Next (HRRN)</strong></em> In this scheduling, processes with highest response ratio is scheduled. This algorithm avoids starvation.</p>
<pre>Response Ratio = (Waiting Time + Burst time) / Burst time</pre>
<p><em><strong>Multilevel Queue Scheduling:</strong> </em>According to the priority of process, processes are placed in the different queues. Generally high priority process are placed in the top level queue. Only after completion of processes from top level queue, lower level queued processes are scheduled. It can suffer from starvation.</p>
<p><em><strong>Multi level Feedback Queue Scheduling: </strong></em> It allows the process to move in between queues. The idea is to separate processes according to the characteristics of their CPU bursts. If a process uses too much CPU time, it is moved to a lower-priority queue.</p>
<p> </p>
<p><strong>Some useful facts about Scheduling Algorithms:</strong><br/>
<strong></strong></p>
<ol>
<li></li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-142463 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-142463">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Management | Introduction</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<div></div>
<p><strong>Program vs Process</strong><br/>
A process is a program in execution. For example, when we write a program in C or C++ and compile it, the compiler creates binary code. The original code and binary code are both programs. When we actually run the binary code, it becomes a process.</p>
<p><!--more--> A process is an ‘active’ entity, as opposed to a program, which is considered to be a ‘passive’ entity. A single program can create many processes when run multiple times; for example, when we open a .exe or binary file multiple times, multiple instances begin (multiple processes are created).</p>
<p><strong>What does a process look like in memory?</strong><br/>
<a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/process.png"><img alt="process" class="alignnone size-full wp-image-17196" height="347" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/process.png" width="212"/></a></p>
<p><em><strong>Text Section</strong>:</em>A Process, sometimes known as the Text Section, also includes the current activity represented by the value of the <em><strong>Program Counter</strong></em>.<br/>
<em><strong>Stack</strong>:</em> The Stack contains the temporary data, such as function parameters, returns addresses, and local variables.<br/>
<em><strong>Data Section</strong>:</em> Contains the global variable.<br/>
<em><strong>Heap Section</strong>:</em> Dynamically allocated memory to process during its run time.<br/>
Refer <a href="https://www.geeksforgeeks.org/memory-layout-of-c-program/">this </a>for more details on sections.</p>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_top_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="4501693235" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<p><strong>Attributes or Characteristics of a Process</strong><br/>
A process has following attributes.</p>
<pre><strong>1. Process Id:</strong>    A unique identifier assigned by the operating system

<strong>2. Process State:</strong> Can be ready, running, etc.

<strong>3. CPU registers:</strong> Like the Program Counter (CPU registers must be saved and 

                  restored when a process is swapped in and out of CPU)

<strong>5. Accounts information:</strong>

<strong>6. I/O status information:</strong> For example, devices allocated to the process, 

                           open files, etc

<strong>8. CPU scheduling information:</strong> For example, Priority (Different processes 

                               may have different priorities, for example

                               a short process may be assigned a low priority

                               in the shortest job first scheduling)</pre>
<p>All of the above attributes of a process are also known as the<em><strong>context of the process</strong></em>.<br/>
Every process has its own (PCB), i.e each process will have a unique PCB. All of the above attributes are part of the PCB.</p>
<p> </p>
<p><strong>States of Process:</strong><br/>
A process is in one of the following states:</p>
<pre><strong>1. New:</strong> Newly Created Process (or) being-created process.



<strong>2. Ready:</strong> After creation process moves to Ready state, i.e. the 

          process is ready for execution.



<strong>3. Run:</strong> Currently running process in CPU (only one process at

        a time can be under execution in a single processor).



<strong>4. Wait (or Block):</strong> When a process requests I/O access.



<strong>5. Complete (or Terminated):</strong> The process completed its execution.



<strong>6. Suspended Ready:</strong> When the ready queue becomes full, some processes 

                    are moved to suspended ready state



<strong>7. Suspended Block:</strong> When waiting queue becomes full.</pre>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/process-states1.png"><img alt="process-states" class="alignnone size-full wp-image-17199" height="301" src="https://www.geeksforgeeks.org/wp-content/uploads/gq/2015/06/process-states1.png" width="411"/></a></p>
<p><strong>Context Switching</strong><br/>
The process of saving the context of one process and loading the context of another process is known as Context Switching. In simple terms, it is like loading and unloading the process from running state to ready state.</p>
<p><strong>When does context switching happen?</strong><br/>
1. When a high-priority process comes to ready state (i.e. with higher priority than the running process)<br/>
2. An Interrupt occurs<br/>
3. User and kernel mode switch (It is not necessary though)<br/>
4. Preemptive CPU scheduling used.</p>
<p><strong>Context Switch vs Mode Switch</strong><br/>
A mode switch occurs when CPU privilege level is changed, for example when a system call is made or a fault occurs. The kernel works in more a privileged mode than a standard user task. If a user process wants to access things which are only accessible to the kernel, a mode switch must occur. The currently executing process need not be changed during a mode switch.<br/>
A mode switch typically occurs for a process context switch to occur. Only the kernel can cause a context switch.</p>
<p><strong>CPU-Bound vs I/O-Bound Processes:</strong><br/>
A CPU-bound process requires more CPU time or spends more time in the running state.<br/>
An I/O-bound process requires more I/O time and less CPU time. An I/O-bound process spends more time in the waiting state.</p>
<p> </p>
<p><strong>Exercise:</strong><br/>
<strong>1.</strong> Which of the following need not necessarily be saved on a context switch between processes? (GATE-CS-2000)<br/>
(A) General purpose registers<br/>
(B) Translation lookaside buffer<br/>
(C) Program counter<br/>
(D) All of the above</p>
<p><strong>Answer (B)</strong></p>
<p><strong>Explanation:</strong><br/>
In a process context switch, the state of the first process must be saved somehow, so that when the scheduler gets back to the execution of the first process, it can restore this state and continue. The state of the process includes all the registers that the process may be using, especially the program counter, plus any other operating system-specific data that may be necessary. A translation look-aside buffer (TLB) is a CPU cache that memory management hardware uses to improve virtual address translation speed. A TLB has a fixed number of slots that contain page table entries, which map virtual addresses to physical addresses. On a context switch, some TLB entries can become invalid, since the virtual-to-physical mapping is different. The simplest strategy to deal with this is to completely flush the TLB.</p>
<p><strong>2.</strong> The time taken to switch between user and kernel modes of execution is t1 while the time taken to switch between two processes is t2. Which of the following is TRUE? (GATE-CS-2011)<br/>
(A) t1 &gt; t2<br/>
(B) t1 = t2<br/>
(C) t1 &lt; t2<br/>
(D) nothing can be said about the relation between t1 and t2.</p>
<p><strong>Answer: (C)</strong><br/>
<b>Explanation:</b> Process switching involves mode switch. Context switching can occur only in kernel mode.</p>
<p><a href="http://quiz.geeksforgeeks.org/operating-systems/process-synchronization/">Quiz on Process Management</a></p>
<p><strong>References:</strong><br/>
<a href="http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html">http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html</a><br/>
<a href="http://cs.nyu.edu/courses/spring11/G22.2250-001/lectures/lecture-04.html">http://cs.nyu.edu/courses/spring11/G22.2250-001/lectures/lecture-04.html</a></p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/Nilesh Singh 2/">Nilesh Singh 2</a>, <a href="https://auth.geeksforgeeks.org/user/chrismaher37/">chrismaher37</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-142462 post type-post status-publish format-standard hentry category-operating-systems tag-cpu-scheduling" id="post-142462">
<header class="entry-header">
<h1 class="entry-title">Operating System | Process Scheduler</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>There are three types of process scheduler.</p>
<p><strong></strong></p>
<ol>
<li>Long Term or job scheduler</li></ol></div></article><hr style="border: 2px dashed black;" /><article class="post-145174 post type-post status-publish format-standard hentry category-operating-systems tag-gate-cs-2015-set-2 tag-gate-gate-cs-2015-set-2" id="post-145174">
<header class="entry-header">
<h1 class="entry-title">GATE | GATE-CS-2015 (Set 2) | Question 65</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>A computer system implements a 40 bit virtual address, page size of 8 kilobytes, and a 128-entry translation look-aside buffer (TLB) organized into 32 sets each having four ways. Assume that the TLB tag does not store any process id. The<br/>
minimum length of the TLB tag in bits is _________<br/>
<b>(A)</b> 20<br/>
<b>(B)</b> 10<br/>
<b>(C)</b> 11<br/>
<b>(D)</b> 22<br/>
<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-142461 post type-post status-publish format-standard hentry category-operating-systems" id="post-142461">
<header class="entry-header">
<h1 class="entry-title">Commonly Asked Operating Systems Interview Questions | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>What is a process and process table? What are different states of process</strong><br/>
A <em>process </em>is an instance of program in execution.<!--more--> For example a Web Browser is a process, a shell (or command prompt) is a process.<br/>
The operating system is responsible for managing all the processes that are running on a computer and allocated each process a certain amount of time to use the processor. In addition, the operating system also allocates various other resources that processes will need such as computer memory or disks. To keep track of the state of all the processes, the operating system maintains a table known as the <em>process table</em>. Inside this table, every process is listed along with the resources the processes is using and the current state of the process.<br/>
<em>Processes can be in one of three states: running, ready, or waiting</em>. The running state means that the process has all the resources it need for execution and it has been given permission by the operating system to use the processor. Only one process can be in the running state at any given time. The remaining processes are either in a waiting state (i.e., waiting for some external event to occur such as user input or a disk access) or a ready state (i.e., waiting for permission to use the processor). In a real operating system, the waiting and ready states are implemented as queues which hold the processes in these states. The animation below shows a simple representation of the life cycle of a process (Source: )</p>
<p><strong>What is a Thread? What are the differences between process and thread?</strong><br/>
A thread is a single sequence stream within in a process. Because threads have some of the properties of processes, they are sometimes called <i>lightweight processes</i>. Threads are popular way to improve application through parallelism. For example, in a browser, multiple tabs can be different threads. MS word uses multiple threads, one thread to format the text, other thread to process inputs, etc.<br/>
A thread has its own program counter (PC), a register set, and a stack space. Threads are not independent of one other like processes as a result threads shares with other threads their code section, data section and OS resources like open files and signals. See  for more details.</p>
<p><strong>What is deadlock? </strong><br/>
Deadlock is a situation when two or more processes wait for each other to finish and none of them ever finish.  Consider an example when two trains are coming toward each other on same track and there is only one track, none of the trains can move once they are in front of each other.  Similar situation occurs in operating systems when there are two or more processes hold some resources and wait for resources held by other(s).</p>
<p><strong>What are the necessary conditions for deadlock?</strong><br/>
<em>Mutual Exclusion:</em> There is a resource that cannot be shared.<br/>
<em>Hold and Wait: </em>A process is holding at least one resource and waiting for another resource which is with some other process.<br/>
<em>No Preemption:</em> The operating system is not allowed to take a resource back from a process until process gives it back.<br/>
<em>Circular Wait:  </em>A set of processes are waiting for each other in circular form.</p>
<p><strong>What is Virtual Memory? How is it implemented?</strong><br/>
Virtual memory creates an illusion that each user has one or more contiguous address spaces, each beginning at address zero. The sizes of such virtual address spaces is generally very high.<br/>
The idea of virtual memory is to use disk space to extend the RAM. Running processes don’t need to care whether the memory is from RAM or disk. The illusion of such a large amount of memory is created by subdividing the virtual memory into smaller pieces, which can be loaded into physical memory whenever they are needed by a process.</p>
<p><strong>What is Thrashing?</strong><br/>
Thrashing is a situation when the performance of a computer degrades or collapses. Thrashing occurs when a system spends more time processing page faults than executing transactions. While processing page faults is necessary to in order to appreciate the benefits of virtual memory, thrashing has a negative affect on the system. As the page fault rate increases, more transactions need processing from the paging device. The queue at the paging device increases, resulting in increased service time for a page fault (Source: h)</p>
<p><strong style="font-size: 14px;line-height: 1.5em">What is Belady’s Anomaly?</strong><br/>
Bélády’s anomaly is an anomaly with some page replacement policies where increasing the number of page frames results in an increase in the number of page faults. It occurs with First in First Out page replacement is used. See for an example and more details.</p>
<p><strong>Differences between mutex and semphore?</strong><br/>
See </p>
<ul>
<li>Practice  on Operating System topics</li>
<li> – OS </li>
<li>OS </li>
</ul>
<p><a href="https://www.geeksforgeeks.org/last-minute-notes-operating-systems/"><strong>Last Minute Notes – Operating Systems</strong></a></p>
<p>We will soon be covering more Operating System questions. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-119330 post type-post status-publish format-standard hentry category-operating-systems tag-os-memory-management tag-system-programming" id="post-119330">
<header class="entry-header">
<h1 class="entry-title">Working with Shared Libraries | Set 2</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>We have covered basic information about shared libraries in the . In the current article we will learn how to create shared libraries on Linux.<!--more--></p>
<p>Prior to that we need to understand how a program is loaded into memory, various (basic) steps involved in the process.</p>
<p>Let us see a typical “Hello World” program in C. Simple Hello World program screen image is given below.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/Hello-World.png"><img alt="Hello World" class="aligncenter size-medium wp-image-119828" height="119" sizes="(max-width: 300px) 100vw, 300px" src="https://www.geeksforgeeks.org/wp-content/uploads/Hello-World-300x119.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/Hello-World-300x119.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/Hello-World.png 744w" width="300"/></a></p>
<p>We were compiling our code using the command “<strong>gcc -o sample shared.c</strong>” When we compile our code, the compiler won’t resolve implementation of the function <strong>printf()</strong>. It only verifies the syntactical checking. The tool chain leaves a stub in our application which will be filled by dynamic linker. Since printf is standard function the compiler implicitly invoking its shared library. More details down.</p>
<p>We are using <em>ldd</em> to list dependencies of our program binary image. In the screen image, we can see our sample program depends on three binary files namely, <em>linux-vdso.so.1</em>, <em>libc.so.6</em> and <em>/lib64/ld-linux-x86-64.so.2</em>.</p>
<p>The file VDSO is fast implementation of system call interface and some other stuff, it is not our focus (on some older systems you may see different file name in liue of *.vsdo.*). Ignore this file. We have interest in the other two files.</p>
<p>The file <strong>libc.so.6</strong> is C implementation of various standard functions. It is the file where we see <em>printf</em> definition needed for our <em>Hello World</em>. It is the shared library needed to be loaded into memory to run our Hello World program.</p>
<p>The third file /lib64/ld-linux-x86-64.so.2 is infact an executable that runs when an application is invoked. When we invoke the program on bash terminal, typically the bash forks itself and replaces its address space with image of program to run (so called fork-exec pair). The kernel verifies whether the libc.so.6 resides in the memory. If not, it will load the file into memory and does the relocation of libc.so.6 symbols. It then invokes the dynamic linker (/lib64/ld-linux-x86-64.so.2) to resolve unresolved symbols of application code (printf in the present case). Then the control transfers to our program <em>main</em>. (I have intensionally omitted many details in the process, our focus is to understand basic details).</p>
<p><strong>Creating our own shared library:</strong></p>
<p>Let us work with simple shared library on Linux. Create a file <strong>library.c</strong> with the following content.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/library.png"><img alt="library" class="aligncenter size-medium wp-image-119830" height="164" sizes="(max-width: 300px) 100vw, 300px" src="https://www.geeksforgeeks.org/wp-content/uploads/library-300x164.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/library-300x164.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/library.png 835w" width="300"/></a></p>
<p>The file library.c defines a function <em><strong>signum</strong></em> which will be used by our application code. Compile the file library.c file using the following command.</p>
<p><strong>gcc -shared -fPIC -o liblibrary.so library.c</strong></p>
<p>The flag <em>-shared</em> instructs the compiler that we are building a shared library. The flag <em>-fPIC</em> is to generate position independent code (ignore for now). The command generates a shared library <em>liblibrary.so</em> in the current working directory. We have our shared object file (shared library name in Linux) ready to use.</p>
<p>Create another file <strong>application.c</strong> with the following content.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/application.png"><img alt="application" class="aligncenter size-medium wp-image-119831" height="125" sizes="(max-width: 300px) 100vw, 300px" src="https://www.geeksforgeeks.org/wp-content/uploads/application-300x125.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/application-300x125.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/application.png 659w" width="300"/></a></p>
<p>In the file <strong>application.c</strong> we are invoking the function signum which was defined in a shared library. Compile the application.c file using the following command.</p>
<p><strong>gcc application.c -L /home/geetanjali/coding/ -llibrary -o sample</strong></p>
<p>The flag <em>-llibrary</em> instructs the compiler to look for symbol definitions that are not available in the current code (signum function in our case). The option <em>-L</em> is hint to the compiler to look in the directory followed by the option for any shared libraries (during link time only). The command generates an executable named as “<strong>sample</strong>“.</p>
<p>If you invoke the executable, the dynamic linker will not be able to find the required shared library. By default it won’t look into current working directory. You have to explicitly instruct the tool chain to provide proper paths. The dynamic linker searches standard paths available in the LD_LIBRARY_PATH and also searches in system cache (for details explore the command <strong><em>ldconfig</em></strong>). We have to add our working directory to the LD_LIBRARY_PATH environment variable. The following command does the same.</p>
<p><strong>export LD_LIBRARY_PATH=/home/geetanjali/coding/:$LD_LIBRARY_PATH</strong></p>
<p>You can now invoke our executable as shown.</p>
<p><strong>./sample</strong></p>
<p>Sample output on my system is shown below.</p>
<p><a href="https://www.geeksforgeeks.org/wp-content/uploads/output.png"><img alt="output" class="aligncenter size-medium wp-image-119832" height="28" sizes="(max-width: 300px) 100vw, 300px" src="https://www.geeksforgeeks.org/wp-content/uploads/output-300x28.png" srcset="https://www.geeksforgeeks.org/wp-content/uploads/output-300x28.png 300w, https://www.geeksforgeeks.org/wp-content/uploads/output.png 933w" width="300"/></a></p>
<p><strong>Note:</strong> <em>The path <strong>/home/geetanjali/coding/</strong> is working directory path on my machine. You need to use your working directory path where ever it is being used in the above commands.</em></p>
<p>Stay tuned, we haven’t even explored 1/3rd of shared library concepts. More advanced concepts in the later articles.</p>
<p><strong>Exercise:</strong></p>
<p>It is workbook like article. You won’t gain much unless you practice and do some research.</p>
<p>1. Create similar example and write your won function in the shared library. Invoke the function in another application.</p>
<p>2. Is (Are) there any other tool(s) which can list dependent libraries?</p>
<p>3. What is position independent code (PIC)?</p>
<p>4. What is system cache in the current context? How does the directory /etc/ld.so.conf.d/* related in the current context?</p>
<p>— <strong></strong>. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-117461 post type-post status-publish format-standard hentry category-operating-systems tag-os-memory-management tag-system-programming" id="post-117461">
<header class="entry-header">
<h1 class="entry-title">Working with Shared Libraries | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>This article is not for those algo geeks. If you are interested in systems related stuff, just read on…<!--more--></p>
<p>Shared libraries are useful in sharing code which is common across many applications. For example, it is more economic to pack all the code related to TCP/IP implementation in a shared library. However, data can’t be shared as every application needs its own set of data. Applications like, browser, ftp, telnet, etc… make use of the shared ‘network’ library to elevate specific functionality.</p>
<p>Every operating system has its own representation and tool-set to create shared libraries. More or less the concepts are same. On Windows every object file (*.obj, *.dll, *.ocx, *.sys, *.exe etc…) follow a format called Portalbe Executable. Even shared libraries (called as Dynamic Linked Libraries or DLL in short) are also represented in PE format. The tool-set that is used to create these libraries need to understand the binary format. Linux variants follow a format called Executable and Linkable Format (ELF). The ELF files are position independent (PIC) format. Shared libraries in Linux are referred as shared objects (generally with extension *.so). These are similar to DLLs in Windows platform. Even shared object files follow the ELF binary format.</p>
<p>Remember, the file extensions (*.dll, *.so, *.a, *.lib, etc…) are just for programmer convenience. They don’t have any significance. All these are binary files. You can name them as you wish. Yet ensure you provide absolute paths in building applications.</p>
<p>In general, when we compile an application the steps are simple. Compile, Link and Load. However, it is not simple. These steps are more versatile on modern operating systems.</p>
<p>When you link your application against static library, the code is part of your application. There is no dependency. Even though it causes the application size to increase, it has its own advantages. The primary one is speed as there will be no symbol (a program entity) resolution at runtime. Since every piece of code part of the binary image, such applications are independent of version mismatch issues. However, the cost is on fixing an issue in library code. If there is any bug in library code, entire application need to be recompiled and shipped to the client. In case of dynamic libraries, fixing or upgrading the libraries is easy. You just need to ship the updated shared libraries. The application need not to recompile, it only need to re-run. You can design a mechanism where we don’t need to restart the application.</p>
<p>When we link an application against a shared library, the linker leaves some stubs (unresolved symbols) to be filled at application loading time. These stubs need to be filled by a tool called, <em>dynamic linker</em> at run time or at application loading time. Again loading of a library is of two types, static loading and dynamic loading. Don’t confuse between <strong><em>static loading</em></strong> vs <strong><em>static linking</em></strong> and <strong><em>dynamic loading</em></strong> vs <strong><em>dynamic linking</em></strong>.</p>
<p>For example, you have built an application that depends on <em>libstdc++.so</em> which is a shared object (dynamic libary). How does the application become aware of required shared libraries? (If you are interested, explore the tools <em>tdump</em> from Borland tool set, <em>objdump</em> or <em>nm</em> or <em>readelf</em> tools on Linux).</p>
<p>Static loading:</p>
<ul>
<li>In static loading, all of those dependent shared libraries are loaded into memory even before the application starts execution. If loading of any shared library fails, the application won’t run.</li>
<li><span>A dynamic loader examines application’s dependency on shared libraries. If these libraries are already loaded into the memory, the library address space is mapped to application virtual address space (VAS) and the dynamic linker does relocation of unresolved symbols.</span></li>
<li><span>If these libraries are not loaded into memory (perhaps your application might be first to invoke the shared library), the loader searches in standard library paths and loads them into memory, then maps and resolves symbols. Again loading is big process, if you are interested write your own loader :). </span></li>
<li>While resolving the symbols, if the dynamic linker not able to find any symbol (may be due to older version of shared library), the application can’t be started.</li>
</ul>
<p>Dynamic Loading:</p>
<ul>
<li>As the name indicates, dynamic loading is about loading of library on demand.</li>
<li><span>For example, if you want a small functionality from a shared library. Why should it be loaded at the application load time and sit in the memory? You can invoke loading of these shared libraries dynamically when you need their functionality. This is called dynamic loading. In this case, the programmer aware of situation ‘when should the library be loaded’. The tool-set and relevant kernel provides API to support dynamic loading, and querying of symbols in the shared library.</span></li>
</ul>
<p>More details in later articles.</p>
<p><em>Note: If you come across terms like loadable modules or equivalent terms, don’t mix them with shared libraries. They are different from shared libraries  The kernels provide framework to support loadable modules.</em><strong></strong></p>
<p><a href="https://www.geeksforgeeks.org/working-with-shared-libraries-set-2/">Working with Shared Libraries | Set 2</a></p></div></article><hr style="border: 2px dashed black;" /><article class="post-115799 post type-post status-publish format-standard hentry category-operating-systems tag-memory-management tag-system-programming" id="post-115799">
<header class="entry-header">
<h1 class="entry-title">Static and Dynamic Libraries | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>When a C program is compiled, the compiler generates object code. After generating the object code, the compiler also invokes linker. One of the main tasks for linker is to make code of library functions (eg printf(), scanf(), sqrt(), ..etc) available to your program. <!--more-->A linker can accomplish this task in two ways, by copying the code of library function to your object code, or by making some arrangements so that the complete code of library functions is not copied, but made available at run-time. </p>
<p><strong>Static Linking and Static Libraries</strong> is the result of the linker making copy of all used library functions to the executable file.  Static Linking creates larger binary files, and need more space on disk and main memory. Examples of static libraries (libraries which are statically linked) are, <strong><em>.a</em></strong> files in Linux and <strong><em>.lib </em></strong>files in Windows. </p>
<p><strong>Steps to create a static library</strong> Let us create and use a Static Library in UNIX or UNIX like OS.<br/>
<strong>1.</strong> Create a C file that contains functions in your library.</p>
<div class="code-block">
<div class="code-gutter">
<div class="editor-buttons-container">
<div class="editor-buttons">
<div class="editor-buttons-div" title="Run and Edit">
<i class="material-icons code-sidebar-button copy-code-button" id="copy-code-button" title="Copy Code">filter_none</i></div></div></div></div></div></div></article><hr style="border: 2px dashed black;" /><article class="post-9102 post type-post status-publish format-standard hentry category-articles category-operating-systems tag-os-process-synchronization" id="post-9102">
<header class="entry-header">
<h1 class="entry-title">Mutex vs Semaphore</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>What are the differences between Mutex vs Semaphore? When to use mutex and when to use semaphore?<!--more--></p>
<p>Concrete understanding of Operating System concepts is required to design/develop smart applications. Our objective is to educate the reader on these concepts and learn from other expert geeks.</p>
<p>As per operating system terminology, mutex and semaphore are kernel resources that provide synchronization services (also called as <em>synchronization primitives</em>). <em>Why do we need such synchronization primitives? Won’t be only one sufficient? </em>To answer these questions, we need to understand few keywords. Please read the posts on  and . We will illustrate with examples to understand these concepts well, rather than following usual OS textual description.</p>
<p><strong>The  problem:</strong></p>
<p><em>Note that the content is generalized explanation. Practical details vary with implementation.</em></p>
<p>Consider the standard producer-consumer problem. Assume, we have a buffer of 4096 byte length. A producer thread collects the data and writes it to the buffer. A consumer thread processes the collected data from the buffer. Objective is, both the threads should not run at the same time.</p>
<p><strong>Using Mutex:</strong></p>
<p>A mutex provides mutual exclusion, either producer or consumer can have the key (mutex) and proceed with their work. As long as the buffer is filled by producer, the consumer needs to wait, and vice versa.</p>
<p>At any point of time, only one thread can work with the <em>entire</em> buffer. The concept can be generalized using semaphore.</p>
<p><strong>Using Semaphore:</strong></p>
<p>A semaphore is a generalized mutex. In lieu of single buffer, we can split the 4 KB buffer into four 1 KB buffers (identical resources). A semaphore can be associated with these four buffers. The consumer and producer can work on different buffers at the same time.</p>
<p><strong>Misconception:</strong></p>
<p>There is an ambiguity between <em>binary semaphore</em> and <em>mutex</em>. We might have come across that a mutex is binary semaphore. <em>But they are not</em>! The purpose of mutex and semaphore are different. May be, due to similarity in their implementation a mutex would be referred as binary semaphore.</p>
<p>Strictly speaking, a mutex is <strong><span style="color: #0000ff">locking mechanism</span></strong> used to synchronize access to a resource. Only one task (can be a thread or process based on OS abstraction) can acquire the mutex. It means there is ownership associated with mutex, and only the owner can release the lock (mutex).</p>
<p>Semaphore is <span style="color: #0000ff"><strong>signaling mechanism</strong></span> (“I am done, you can carry on” kind of signal). For example, if you are listening songs (assume it as one task) on your mobile and at the same time your friend calls you, an interrupt is triggered upon which an interrupt service routine (ISR) signals the call processing task to wakeup.</p>
<p><strong>General Questions:</strong></p>
<p><em>1. Can a thread acquire more than one lock (Mutex)?</em></p>
<p>Yes, it is possible that a thread is in need of more than one resource, hence the locks. If any lock is not available the thread will wait (block) on the lock.</p>
<p><em>2. Can a mutex be locked more than once?</em></p>
<p>A mutex is a lock. Only one state (locked/unlocked) is associated with it. However, a <em>recursive mutex</em> can be locked more than once (POSIX complaint systems), in which a count is associated with it, yet retains only one state (locked/unlocked). The programmer must unlock the mutex as many number times as it was locked.</p>
<p><em>3. What happens if a non-recursive mutex is locked more than once.</em></p>
<p>Deadlock. If a thread which had already locked a mutex, tries to lock the mutex again, it will enter into the waiting list of that mutex, which results in deadlock. It is because no other thread can unlock the mutex. An operating system implementer can exercise care in identifying the owner of mutex and return if it is already locked by same thread to prevent deadlocks.</p>
<p><em>4. Are binary semaphore and mutex same?</em></p>
<p>No. We suggest to treat them separately, as it is explained signalling vs locking mechanisms. But a binary semaphore may experience the same critical issues (e.g. priority inversion) associated with mutex. We will cover these in later article.</p>
<p>A programmer can prefer mutex rather than creating a semaphore with count 1.</p>
<p><em>5. What is a mutex and critical section?</em></p>
<p>Some operating systems use the same word <em>critical section</em> in the API. Usually a mutex is costly operation due to protection protocols associated with it. At last, the objective of mutex is atomic access. There are other ways to achieve atomic access like disabling interrupts which can be much faster but ruins responsiveness. The alternate API makes use of disabling interrupts.</p>
<p><em>6. What are events?</em></p>
<p>The semantics of mutex, semaphore, event, critical section, etc… are same. All are synchronization primitives. Based on their cost in using them they are different. We should consult the OS documentation for exact details.</p>
<p><em>7. Can we acquire mutex/semaphore in an Interrupt Service Routine?</em></p>
<p>An ISR will run asynchronously in the context of current running thread. It is <strong>not recommended</strong> to query (blocking call) the availability of synchronization primitives in an ISR. The ISR are meant be short, the call to mutex/semaphore may block the current running thread. However, an ISR can signal a semaphore or unlock a mutex.</p>
<p><em>8. What we mean by “thread blocking on mutex/semaphore” when they are not available?</em></p>
<p>Every synchronization primitive has a waiting list associated with it. When the resource is not available, the requesting thread will be moved from the running list of processor to the waiting list of the synchronization primitive. When the resource is available, the higher priority thread on the waiting list gets the resource (more precisely, it depends on the scheduling policies).</p>
<p><em>9. Is it necessary that a thread must block always when resource is not available?</em></p>
<p>Not necessary. If the design is sure ‘<em>what has to be done when resource is not available</em>‘, the thread can take up that work (a different code branch). To support application requirements the OS provides non-blocking API.</p>
<p>For example POSIX pthread_mutex_trylock() API. When mutex is not available the function returns immediately whereas the API pthread_mutex_lock() blocks the thread till resource is available.</p>
<p><strong>References:</strong></p>
<p><strong><a href="http://www.netrino.com/node/202">http://www.netrino.com/node/202</a></strong></p>
<p><strong><a href="http://doc.trolltech.com/4.7/qsemaphore.html">http://doc.trolltech.com/4.7/qsemaphore.html</a></strong></p>
<p>Also compare mutex/semaphores with Peterson’s algorithm and Dekker’s algorithm. A good reference is the <em>Art of Concurrency </em>book. Also explore reader locks and writer locks in Qt documentation.</p>
<p><strong>Exercise:</strong></p>
<p>Implement a program that prints a message “An instance is running” when executed more than once in the same session. For example, if we observe word application or Adobe reader in Windows, we can see only one instance in the task manager. How to implement it?</p>
<p>Article compiled by <strong>Venki</strong>. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-9180 post type-post status-publish format-standard hentry category-gate-cs category-operating-systems tag-os-process-synchronization" id="post-9180">
<header class="entry-header">
<h1 class="entry-title">Operating System | Critical Section</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p><strong>:</strong></p>
<p>In simple terms a critical section is group of instructions/statements or region of code that need to be executed atomically ( for atomicity), such as accessing a resource (file, input or output port, global data, etc.).<!--more--></p>
<p>In concurrent programming, if one thread tries to change the value of shared data at the same time as another thread tries to read the value (i.e. data race across threads), the result is unpredictable.</p>
<p>The access to such shared variable (shared memory, shared files, shared port, etc…) to be synchronized. Few programming languages have built-in support for synchronization.</p>
<p>It is critical to understand the importance of race condition while writing kernel mode programming (a device driver, kernel thread, etc.). since the programmer can directly access and modifying kernel data structures.</p>
<p><img alt="" class="alignnone size-medium wp-image-996473" src="https://media.geeksforgeeks.org/wp-content/uploads/20190409154423/os2.png"/></p>
<p>A simple solution to the critical section can be thought as shown below,</p>
<pre>acquireLock();

Process Critical Section

releaseLock();</pre>
<p>A thread must acquire a lock prior to executing a critical section. The lock can be acquired by only one thread. There are various ways to implement locks in the above pseudo code. Let us discuss them in future articles.</p>
<p>Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<div id="improvedBy"><br/><b>Improved By : </b> <a href="https://auth.geeksforgeeks.org/user/VaibhavRai3/">VaibhavRai3</a></div><br/><script>jQuery('#showMoreImprove').click(function(){ jQuery(this).hide(); jQuery('#improvedByMore').css('display', 'inline'); });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br>
<br>
<!-- .entry-meta -->
</br></br></div></article><hr style="border: 2px dashed black;" /><article class="post-1495 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems" id="post-1495">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 1</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS exam. <!--more--></p>
<p><strong>1. Which of the following is NOT a valid deadlock prevention scheme? (GATE CS 2000)</strong><br/>
(a) Release all resources before requesting a new resource<br/>
(b) Number the resources uniquely and never request a lower numbered resource than the last one requested.<br/>
(c) Never request a resource after releasing any resource<br/>
(d) Request and all required resources be allocated before execution.</p>
<p><strong>Answer:</strong> (c)<br/>
<strong>References:</strong><br/>
<a href="http://www.cs.jhu.edu/~yairamir/cs418/os4/sld013.htm">http://www.cs.jhu.edu/~yairamir/cs418/os4/sld013.htm</a><br/>
<a href="http://en.wikipedia.org/wiki/Deadlock">http://en.wikipedia.org/wiki/Deadlock</a></p>
<p><strong><br/>
2. Let m[0]…m[4] be mutexes (binary semaphores) and P[0] …. P[4] be processes.<br/>
Suppose each process P[i] executes the following:</strong></p>
<pre>

  wait (m[i]); wait(m[(i+1) mode 4]);</pre></div></article><hr style="border: 2px dashed black;" /><article class="post-1531 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems" id="post-1531">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 2</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS exam.<br/>
<!--more--><br/>
<strong>1. Consider a machine with 64 MB physical memory and a 32-bit virtual address space. If the page size is 4KB, what is the approximate size of the page table? (GATE 2001)<br/>
</strong>(a)  16 MB<br/>
(b)  8 MB<br/>
(c) 2 MB<br/>
(d) 24 MB </p>
<p><strong>Answer:</strong> (c)<br/>
<strong>Explanation:</strong><br/>
A page entry is used to get address of physical memory. Here we assume that single level of Paging is happening. So the resulting page table will contain entries for all the pages of the Virtual address space.</p>
<pre>

Number of entries in page table = 

                    (virtual address space size)/(page size)  

</pre>
<p>Using above formula we can say that there will be 2^(32-12) = 2^20 entries in page table.<br/>
No. of bits required to address the 64MB Physical memory = 26.<br/>
So there will be 2^(26-12) = 2^14 page frames in the physical memory. And page table needs to store the address of all these 2^14 page frames. Therefore, each page table entry will contain 14 bits address of the page frame and 1 bit for valid-invalid bit.<br/>
Since memory is byte addressable. So we take that each page table entry is 16 bits i.e. 2 bytes long.</p>
<pre>

Size of page table = 

  (total number of page table entries) *(size of a page table entry) 

   = (2^20 *2) = 2MB

</pre>
<p>For the clarity of the concept, please see the following figure. As per our question, here p = 20, d = 12 and f = 14.</p>
<p><img alt="Paging" class="aligncenter size-full wp-image-1726" height="453" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Operating-system.jpg" title="Paging" width="612"/></p>
<p><strong><br/>
2. Consider Peterson’s algorithm for mutual exclusion between two concurrent processes i and j. The program executed by process is shown below. </strong></p>
<pre>

   repeat   

      flag [i] = true; 

      turn = j; 

      while ( P ) do no-op; 

      Enter critical section, perform actions, then exit critical 

      section 

      flag [ i ] = false; 

      Perform other non-critical section actions. 

   until false; </pre>
<p>For the program to guarantee mutual exclusion, the predicate P in the while loop should be (GATE 2001)</p></div></article><hr style="border: 2px dashed black;" /><article class="post-1929 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems" id="post-1929">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 3</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS exam.<br/>
<!--more--><br/>
<strong>1. Suppose the time to service a page fault is on the average 10 milliseconds, while a memory access takes 1 microsecond. Then a 99.99% hit ratio results in average memory access time of (GATE CS 2000)</strong><br/>
(a) 1.9999 milliseconds<br/>
(b) 1 millisecond<br/>
(c) 9.999 microseconds<br/>
(d) 1.9999 microseconds</p>
<p><strong>Answer:</strong> (d)<br/>
<strong>Explanation:</strong></p>
<pre>

Average memory access time =

      [(% of page miss)*(time to service a page fault) +

                  (% of page hit)*(memory access time)]/100

</pre>
<p>So, average memory access time in microseconds is.<br/>
(99.99*1 + 0.01*10*1000)/100 = (99.99+100)/1000 = 199.99/1000 =1.9999 µs</p>
<p><strong><br/>
2. Which of the following need not necessarily be saved on a context switch between processes? (GATE CS 2000)</strong><br/>
(a) General purpose registers<br/>
(b) Translation look-aside buffer<br/>
(c) Program counter<br/>
(d) All of the above</p>
<p><strong>Answer:</strong> (b)<br/>
<strong>Explanation:</strong><br/>
In a process context switch, the state of the first process must be saved somehow, so that, when the scheduler gets back to the execution of the first process, it can restore this state and continue.</p>
<p>The state of the process includes all the registers that the process may be using, especially the program counter, plus any other operating system specific data that may be necessary.</p>
<p>A Translation lookaside buffer (TLB) is a CPU cache that memory management hardware uses to improve virtual address translation speed. A TLB has a fixed number of slots that contain page table entries, which map virtual addresses to physical addresses. On a context switch, some TLB entries can become invalid, since the virtual-to-physical mapping is different. The simplest strategy to deal with this is to completely flush the TLB.<br/>
<strong>References:</strong><br/>
<a href="http://en.wikipedia.org/wiki/Context_switch">http://en.wikipedia.org/wiki/Context_switch</a><br/>
<a href="http://en.wikipedia.org/wiki/Translation_lookaside_buffer#Context_switch">http://en.wikipedia.org/wiki/Translation_lookaside_buffer#Context_switch</a></p>
<p><strong><br/>
3. Where does the swap space reside ? (GATE 2001)</strong><br/>
(a) RAM<br/>
(b) Disk<br/>
(c) ROM<br/>
(d) On-chip cache<br/>
<strong>Answer:</strong> (b)<br/>
<strong>Explanation:</strong><br/>
Swap space is an area on disk that temporarily holds a process memory image. When physical memory demand is sufficiently low, process memory images are brought back into physical memory from the swap area. Having sufficient swap space enables the system to keep some physical memory free at all times.<br/>
<strong>References:</strong><br/>
<a href="http://docs.hp.com/en/B2355-90672/ch06s02.html">http://docs.hp.com/en/B2355-90672/ch06s02.html</a></p>
<p><strong><br/>
4. Which of the following does not interrupt a running process? </strong> (GATE CS 2001)<br/>
(a) A device<br/>
(b) Timer<br/>
(c) Scheduler process<br/>
(d) Power failure </p>
<p><strong>Answer:</strong> (c)<br/>
<strong>Explanation:</strong><br/>
Scheduler process doesn’t interrupt any process, it’s Job is to select the processes for following three purposes.<br/>
<em>Long-term scheduler</em>(or job scheduler) –selects which processes should be brought into the ready queue<br/>
<em>Short-term scheduler</em>(or CPU scheduler) –selects which process should be executed next and allocates CPU.<br/>
<em>Mid-term Scheduler</em> (Swapper)- present in all systems with virtual memory, temporarily removes processes from main memory and places them on secondary memory (such as a disk drive) or vice versa. The mid-term scheduler may decide to swap out a process which has not been active for some time, or a process which has a low priority, or a process which is page faulting frequently, or a process which is taking up a large amount of memory in order to free up main memory for other processes, swapping the process back in later when more memory is available, or when the process has been unblocked and is no longer waiting for a resource.</p>
<p><strong><br/>
5. Which of the following scheduling algorithms is non-preemptive? (GATE CS 2002)<br/>
</strong><br/>
a)	Round Robin<br/>
b)	First-In First-Out<br/>
c)	Multilevel Queue Scheduling<br/>
d)	Multilevel Queue Scheduling with Feedback </p>
<p><strong>Answer: </strong>(b)</p>
<p></p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-4036 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems" id="post-4036">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 4</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS exam. <!--more--></p>
<p><strong>1. Using a larger block size in a fixed block size file system leads to (GATE CS 2003)</strong><br/>
a)	better disk throughput but poorer disk space utilization<br/>
b)	better disk throughput and better disk space utilization<br/>
c)	poorer disk throughput but better disk space utilization<br/>
d)	poorer disk throughput and poorer disk space utilization </p>
<p>Answer (a)<br/>
If block size is large then seek time is less (fewer blocks to seek) and disk performance is improved, but remember larger block size also causes waste of disk space.</p>
<p><strong>2. Consider the following statements with respect to user-level threads and kernel supported threads<br/>
i.	context switch is faster with kernel-supported threads<br/>
ii.	for user-level threads, a system call can block the entire process<br/>
iii.	Kernel supported threads can be scheduled independently<br/>
iv.	User level threads are transparent to the kernel</strong></p>
<p>Which of the above statements are true? (GATE CS 2004)</p></div></article><hr style="border: 2px dashed black;" /><article class="post-18261 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2012" id="post-18261">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 5</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2012 exam. <!--more--></p>
<p><strong>1. A process executes the code</strong></p>
<pre>

  fork ();

  fork ();

  fork ();

</pre>
<p><strong>The total number of child processes created is</strong><br/>
(A) 3<br/>
(B) 4<br/>
(C) 7<br/>
(D) 8</p>
<p>Answer (C)</p>
<p>Let us put some label names for the three lines</p>
<pre>

  fork ();    // Line 1

  fork ();   // Line 2

  fork ();   // Line 3



       L1       // There will be 1 child process created by line 1

    /     \

  L2      L2    // There will be 2 child processes created by line 2

 /  \    /  \

L3  L3  L3  L3  // There will be 4 child processes created by line 3

</pre>
<p>We can also use direct formula to get the number of child processes. With n fork statements, there are always 2^n – 1 child processes. Also see <a href="https://www.geeksforgeeks.org/fork-and-binary-tree/">this </a>post for more details.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-19913 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2011" id="post-19913">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 6</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2011 CS exam.<!--more--></p>
<p><strong>1) A thread is usually defined as a ‘light weight process’ because an operating system (OS) maintains smaller data structures for a thread than for a process. In relation to this, which of the followings is TRUE?</strong><br/>
(A) On per-thread basis, the OS maintains only CPU register state<br/>
(B) The OS does not maintain a separate stack for each thread<br/>
(C) On per-thread basis, the OS does not maintain virtual memory state<br/>
(D) On per thread basis, the OS maintains only scheduling and accounting information.</p>
<p>Answer (C)<br/>
Threads share address space of Process. Virtually memory is concerned with processes not with Threads. </p>
<p><strong>2) Let the page fault service time be 10ms in a computer with average memory access time being 20ns. If one page fault is generated for every 10^6 memory accesses, what is the effective access time for the memory?</strong><br/>
(A) 21ns<br/>
(B) 30ns<br/>
(C) 23ns<br/>
(D) 35ns</p>
<p>Answer (B)</p>
<pre>Let P be the page fault rate

Effective Memory Access Time = p * (page fault service time) + 

                               (1 - p) * (Memory access time)

                             = ( 1/(10^6) )* 10 * (10^6) ns +

                               (1 - 1/(10^6)) * 20 ns

                             = 30 ns (approx)    

</pre>
<p><strong>3) An application loads 100 libraries at startup. Loading each library requires exactly one disk access. The seek time of the disk to a random location is given as 10ms. Rotational speed of disk is 6000rpm. If all 100 libraries are loaded from random locations on the disk, how long does it take to load all libraries? (The time to transfer data from the disk block once the head has been positioned at the start of the block may be neglected)</strong><br/>
(A) 0.50s<br/>
(B) 1.50s<br/>
(C) 1.25s<br/>
(D) 1.00s</p>
<p>Answer (B)<br/>
Since transfer time can be neglected, the average access time is sum of average seek time and average rotational latency. Average seek time for a random location time is given as 10 ms. The average rotational latency is half of the time needed for complete rotation. It is given that 6000 rotations need 1 minute. So one rotation will take 60/6000 seconds which is 10 ms. Therefore average rotational latency is half of 10 ms, which is 5ms.</p>
<pre>Average disk access time = seek time + rotational latency 

                         = 10 ms + 5 ms 

                         = 15 ms

For 100 libraries, the average disk access time will be 15*100 ms

</pre>
<p><strong>4. Consider the following table of arrival time and burst time for three processes P0, P1 and P2.</strong></p>
<pre>Process   Arrival time   Burst Time

P0            0 ms          9 ms

P1            1 ms          4 ms

P2            2 ms          9 ms

</pre>
<p><strong>The pre-emptive shortest job first scheduling algorithm is used. Scheduling is carried out only at arrival or completion of processes. What is the average waiting time for the three processes?</strong><br/>
(A) 5.0 ms<br/>
(B) 4.33 ms<br/>
(C) 6.33 ms<br/>
(D) 7.33 ms</p>
<p>Answer: – (A)<br/>
Process P0 is allocated processor at 0 ms as there is no other process in ready queue. P0 is preempted after 1 ms as P1 arrives at 1 ms and burst time for P1 is less than remaining time of P0. P1 runs for 4ms. P2 arrived at 2 ms but P1 continued as burst time of P2 is longer than P1. After P1 completes, P0 is scheduled again as the remaining time for P0 is less than the burst time of P2.<br/>
P0 waits for 4 ms, P1 waits for 0 ms amd P2 waits for 11 ms. So average waiting time is (0+4+11)/3 = 5.</p>
<p><strong>Please see <a href="http://geeksquiz.com/gate-corner-2/">GATE Corner</a> for all previous year paper/solutions/explanations, syllabus, important dates, notes, etc.</strong></p>
<p>Please write comments if you find any of the answers/explanations incorrect, or you want to share more information about the topics discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" /><article class="post-19949 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2010 tag-gate-cs-2011" id="post-19949">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 7</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS exam.<!--more--><br/>
<strong><br/>
1) Let the time taken to switch between user and kernel modes of execution be t1 while the time taken to switch between two processes be t2. Which of the following is TRUE? (GATE CS 2011) </strong><br/>
(A) t1 &gt; t2<br/>
(B) t1 = t2<br/>
(C) t1 &lt; t2
(D) Nothing can be said about the relation between t1 and t2

Answer: - (C)
Process switching involves mode switch. Context switching can occur only in kernel mode.

<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-19980 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2009" id="post-19980">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 8</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2009 CS exam.<!--more--></p>
<p><strong>1) In which one of the following page replacement policies, Belady’s anomaly may occur? </strong><br/>
(A) FIFO<br/>
(B) Optimal<br/>
(C) LRU<br/>
(D) MRU</p>
<p>Answer (A)<br/>
Belady’s anomaly proves that it is possible to have more page faults when increasing the number of page frames while using the First in First Out (FIFO) page replacement algorithm.<br/>
See the <a href="http://en.wikipedia.org/wiki/B%C3%A9l%C3%A1dy's_anomaly">wiki page</a> for an example of increasing page faults with number of page frames.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20001 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2009" id="post-20001">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 9</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2009 CS exam.<!--more--></p>
<p><strong>1) In the following process state transition diagram for a uniprocessor system, assume that there are always some processes in the ready state: Now consider the following statements:<br/>
<a href="https://www.geeksforgeeks.org/wp-content/uploads/gate2009.png"><img alt="" class="aligncenter size-full wp-image-19987" height="150" src="https://www.geeksforgeeks.org/wp-content/uploads/gate2009.png" title="gate2009" width="400"/></a><br/>
 I. If a process makes a transition D, it would result in another process making transition A immediately.<br/>
 II. A process P2 in blocked state can make transition E while another process P1 is in running state.<br/>
 III. The OS uses preemptive scheduling.<br/>
 IV. The OS uses non-preemptive scheduling.<br/>
Which of the above statements are TRUE? </strong><br/>
(A) I and II<br/>
(B) I and III<br/>
(C) II and III<br/>
(D) II and IV </p>
<p>Answer (C)<br/>
I is false. If a process makes a transition D, it would result in another process making transition B, not A.<br/>
II is true. A process can move to ready state when I/O completes irrespective of other process being in running state or not.<br/>
III is true because there is a transition from running to ready state.<br/>
IV is false as the OS uses preemptive scheduling.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20091 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2008" id="post-20091">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 10</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2008 CS exam. <!--more--></p>
<p><strong>1) The data blocks of a very large file in the Unix file system are allocated using </strong><br/>
 (A) contiguous allocation<br/>
 (B) linked allocation<br/>
 (C) indexed allocation<br/>
 (D) an extension of indexed allocation</p>
<p>Answer (D)<br/>
The Unix file system uses an extension of indexed allocation. It uses direct blocks, single indirect blocks, double indirect blocks and triple indirect blocks. Following diagram shows implementation of Unix file system. </p>
<p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operatingsystem.png"><img alt="" class="aligncenter size-full wp-image-20099" height="620" src="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/operatingsystem.png" title="ufs" width="580"/></a><br/>
<br/></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20116 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2008" id="post-20116">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 11</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE 2008 CS exam.<!--more--></p>
<p><strong>1) A process executes the following code </strong></p>
<pre>

  for (i = 0; i &lt; n; i++) fork(); </pre>
<p><strong>The total number of child processes created is </strong><br/>
(A) n<br/>
(B) 2^n - 1<br/>
(C) 2^n<br/>
(D) 2^(n+1) - 1; </p>
<p>Answer (B)</p>
<pre>

         F0       // There will be 1 child process created by first fork

      /     \

    F1      F1    // There will be 2 child processes created by second fork

   /  \    /  \

 F2   F2  F2   F2  // There will be 4 child processes created by third fork

/ \   / \ / \  / \

 ...............   // and so on

</pre>
<p>If we sum all levels of above tree for i = 0 to n-1, we get 2^n - 1. So there will be 2^n – 1 child processes. Also see <a href="https://www.geeksforgeeks.org/fork-and-binary-tree/">this </a> post for more details.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20165 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2007" id="post-20165">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 12</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS 2007 exam. <!--more--></p>
<p><strong>1) Consider a disk pack with 16 surfaces, 128 tracks per surface and 256 sectors per track. 512 bytes of data are stored in a bit serial manner in a sector. The capacity of the disk pack and the number of bits required to specify a particular sector in the disk are respectively:</strong><br/>
(A) 256 Mbyte, 19 bits<br/>
(B) 256 Mbyte, 28 bits<br/>
(C) 512 Mbyte, 20 bits<br/>
(D) 64 Gbyte, 28 bits</p>
<p>Answer (A)<br/>
Capacity of the disk = 16 surfaces  X 128 tracks X 256 sectors X 512 bytes  =  256 Mbytes.<br/>
To calculate number of bits required to access a sector, we need to know total number of sectors. Total number of sectors = 16 surfaces X 128 tracks X 256 sectors = 2^19<br/>
So the number of bits required to access a sector is 19.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20170 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2007" id="post-20170">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 13</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS 2007 exam.<!--more--></p>
<p><strong>1) A virtual memory system uses First In First Out (FIFO) page replacement policy and allocates a fixed number of frames to a process. Consider the following statements:<br/>
P: Increasing the number of page frames allocated to a process sometimes increases the page fault rate.<br/>
Q: Some programs do not exhibit locality of reference. Which one of the following is TRUE?</strong><br/>
(A) Both P and Q are true, and Q is the reason for P<br/>
(B) Both P and Q are true, but Q is not the reason for P.<br/>
(C) P is false, but Q is true<br/>
(D) Both P and Q are false.</p>
<p>Answer (B)<br/>
P is true. Increasing the number of page frames allocated to process may increases the no. of page faults (See <a href="http://en.wikipedia.org/wiki/B%C3%A9l%C3%A1dy's_anomaly">Belady’s Anomaly</a>).<br/>
Q is also true, but Q is not the reason for-P as Belady’s Anomaly occurs for some specific patterns of page references.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20342 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2006" id="post-20342">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 14</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS 2006 exam.<!--more--></p>
<p><strong>1) Consider three CPU-intensive processes, which require 10, 20 and 30 time units  and arrive at times 0, 2 and 6, respectively. How many context switches are  needed if the operating system implements a shortest remaining time first  scheduling algorithm? Do not count the context switches at time zero and at the end.<br/>
</strong>(A) 1<br/>
(B) 2<br/>
(C) 3<br/>
(D) 4 </p>
<p>Answer (B)<br/>
Let three process be P0, P1 and P2 with arrival times 0, 2 and 6 respectively and CPU burst times 10, 20 and 30 respectively. At time 0, P0 is the only available process so it  runs. At time 2, P1 arrives, but P0 has the shortest remaining time, so it continues. At time 6, P2 arrives, but P0 has the shortest remaining time, so it continues. At time 10,   P1 is scheduled as it is the shortest remaining time process. At time 30, P2 is scheduled. Only two context switches are needed. P0 to P1 and P1 to P2.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20359 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2006" id="post-20359">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 15</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS 2006 exam.<!--more--></p>
<p><strong>1) Consider three processes (process id 0, 1, 2 respectively) with compute time  bursts 2, 4 and 8 time units. All processes arrive at time zero. Consider the longest remaining time first (LRTF) scheduling algorithm. In LRTF ties are broken by giving priority to the process with the lowest process id. The average turn around time is:</strong><br/>
(A) 13 units<br/>
(B) 14 units<br/>
(C) 15 units<br/>
(D) 16 units</p>
<p>Answer (A)<br/>
Let the processes be p0, p1 and p2. These processes will be executed in following order.</p>
<pre>

  p2  p1  p2  p1  p2  p0  p1   p2   p0   p1   p2

0   4   5   6   7   8   9   10    11   12   13   14 

</pre>
<p>Turn around time of a process is total time between submission of the process and its completion.<br/>
Turn around time of p0  = 12  (12-0)<br/>
Turn around time of p1  = 13  (13-0)<br/>
Turn around time of p2  = 14  (14-0)</p>
<p>Average turn around time is (12+13+14)/3  = 13.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-20758 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2005" id="post-20758">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 16</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following questions have been asked in GATE CS 2005 exam.<!--more--></p>
<p><strong>1) Normally user programs are prevented from handling I/O directly by I/O instructions in them. For CPUs having explicit I/O instructions, such I/O protection is ensured by having the I/O instructions privileged. In a CPU with memory mapped I/O, there is no explicit I/O instruction. Which one of the following is true for a CPU with memory mapped I/O?</strong><br/>
(a) I/O protection is ensured by operating system routine(s)<br/>
(b) I/O protection is ensured by a hardware trap<br/>
(c) I/O protection is ensured during system configuration<br/>
(d) I/O protection is not possible</p>
<p>Answwer (a)<br/>
Memory mapped I/O means, accessing I/O via general memory access as opposed to specialized IO instructions. An example,</p>
<pre>

  unsigned int volatile const *pMappedAddress const = (unsigned int *)0x100;

</pre>
<p>So, the programmer can directly access any memory location directly. To prevent such an access, the OS (kernel) will divide the address space into kernel space and user space. An user application can easily access user application. To access kernel space, we need system calls (traps).<br/>
Thanks to Venki for providing the above explanation.</p>
<p></p></div></article><hr style="border: 2px dashed black;" /><article class="post-26987 post type-post status-publish format-standard hentry category-gate-cs category-multiple-choice-question category-operating-systems tag-gate-cs-2012" id="post-26987">
<header class="entry-header">
<h1 class="entry-title">Operating Systems | Set 17</h1>
</header><!-- .entry-header -->
<div class="entry-content">
<p>Following question has been asked in GATE 2012 CS exam. <!--more--></p>
<p><strong>Fetch_And_Add(X,i) is an atomic Read-Modify-Write instruction that reads the value of memory location X, increments it by the value i, and returns the old value of X. It is used in the pseudocode shown below to implement a busy-wait lock. L is an unsigned integer shared variable initialized to 0. The value of 0 corresponds to lock being available, while any non-zero value corresponds to the lock being not available.<br/>
</strong></p>
<pre>

  AcquireLock(L){

         while (Fetch_And_Add(L,1))

               L = 1;

   }

  ReleaseLock(L){

         L = 0;

   } </pre>
<p><strong>This implementation</strong><br/>
(A) fails as L can overflow<br/>
(B) fails as L can take on a non-zero value when the lock is actually available<br/>
(C) works correctly but may starve some processes<br/>
(D) works correctly without starvation</p>
<p>Answer (B)<br/>
Take closer look the below while loop.</p>
<pre>

     while (Fetch_And_Add(L,1))

               L = 1;  // A waiting process can be here just after 

                       // the lock is released, and can make L = 1.

</pre>
<p>Consider a situation where a process has just released the lock and made L = 0. Let there be one more process waiting for the lock, means executing the AcquireLock() function. Just after the L was made 0, let the waiting processes executed the line L = 1. Now, the lock is available and L = 1.  Since L is 1, the waiting process (and any other future coming processes) can not come out of the while loop.</p>
<p>The above problem can be resolved by changing the AcuireLock() to following.  </p>
<pre>

  AcquireLock(L){

         while (Fetch_And_Add(L,1))

         { // Do Nothing }

   }

</pre>
<p>Please see <a href="http://geeksquiz.com/gate-corner-2/">GATE Corner</a> for all previous year paper/solutions/explanations, syllabus, important dates, notes, etc.</p>
<p>Please write comments if you find any of the answers/explanations incorrect, or you want to share more information about the topics discussed above.</p>
<p></p>
<br/><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
<br/>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- post_bottom_responsive -->
<ins class="adsbygoogle" data-ad-client="ca-pub-9465609616171866" data-ad-format="auto" data-ad-slot="8385097921" style="display:block"></ins>
<script>

      (adsbygoogle = window.adsbygoogle || []).push({});

    </script>
<br/>
<br/>
<!-- .entry-meta -->
</div></article><hr style="border: 2px dashed black;" />

